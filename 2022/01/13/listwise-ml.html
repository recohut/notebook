<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>List-wise Movie Recommendations using RL methods on ML-100k dataset | reconb</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="List-wise Movie Recommendations using RL methods on ML-100k dataset" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method." />
<meta property="og:description" content="Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method." />
<link rel="canonical" href="https://nb.recohut.com/2022/01/13/listwise-ml.html" />
<meta property="og:url" content="https://nb.recohut.com/2022/01/13/listwise-ml.html" />
<meta property="og:site_name" content="reconb" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-13T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="List-wise Movie Recommendations using RL methods on ML-100k dataset" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-01-13T00:00:00-06:00","datePublished":"2022-01-13T00:00:00-06:00","description":"Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method.","headline":"List-wise Movie Recommendations using RL methods on ML-100k dataset","mainEntityOfPage":{"@type":"WebPage","@id":"https://nb.recohut.com/2022/01/13/listwise-ml.html"},"url":"https://nb.recohut.com/2022/01/13/listwise-ml.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nb.recohut.com/feed.xml" title="reconb" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">reconb</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">List-wise Movie Recommendations using RL methods on ML-100k dataset</h1><p class="page-description">Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-13T00:00:00-06:00" itemprop="datePublished">
        Jan 13, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      73 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/recohut/notebook/tree/master/_notebooks/2022-01-13-listwise-ml.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/recohut/notebook/master?filepath=_notebooks%2F2022-01-13-listwise-ml.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/recohut/notebook/blob/master/_notebooks/2022-01-13-listwise-ml.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frecohut%2Fnotebook%2Fblob%2Fmaster%2F_notebooks%2F2022-01-13-listwise-ml.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-13-listwise-ml.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">tensorflow_version</span> <span class="mf">1.</span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow 1.x selected.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Download-data">Download data<a class="anchor-link" href="#Download-data"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Downloading Movielens dataset from official source</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">files</span><span class="o">.</span><span class="n">grouplens</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">movielens</span><span class="o">/</span><span class="n">ml</span><span class="o">-</span><span class="mi">100</span><span class="n">k</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">q</span> <span class="n">ml</span><span class="o">-</span><span class="mi">100</span><span class="n">k</span><span class="o">.</span><span class="n">zip</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="DataGenerator-class">DataGenerator <code>class</code><a class="anchor-link" href="#DataGenerator-class"> </a></h3><ol>
<li>Load the data into pandas dataframe</li>
<li>List down user's rating history in chronological order</li>
<li>Generate a sample of state-action pair</li>
<li>Split the data into train/test</li>
<li>Store the data back into csv file format</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">():</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datapath</span><span class="p">,</span> <span class="n">itempath</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Load data from the DB MovieLens</span>
<span class="sd">    List the users and the items</span>
<span class="sd">    List all the users histories</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">datapath</span><span class="p">,</span> <span class="n">itempath</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">users</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>   <span class="c1">#list of all users</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>   <span class="c1">#list of all items</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">histo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_history</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test</span>  <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datapath</span><span class="p">,</span> <span class="n">itempath</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Load the data and merge the name of each movie. </span>
<span class="sd">    A row corresponds to a rate given by a user to a movie.</span>

<span class="sd">     Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    datapath :  string</span>
<span class="sd">                path to the data 100k MovieLens</span>
<span class="sd">                contains usersId;itemId;rating </span>
<span class="sd">    itempath :  string</span>
<span class="sd">                path to the data 100k MovieLens</span>
<span class="sd">                contains itemId;itemName</span>
<span class="sd">     Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result :    DataFrame</span>
<span class="sd">                Contains all the ratings </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">datapath</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> 
                       <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">,</span> <span class="s1">&#39;itemId&#39;</span><span class="p">,</span> <span class="s1">&#39;rating&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span><span class="p">])</span>
    <span class="n">movie_titles</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">itempath</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">,</span> <span class="s1">&#39;itemName&#39;</span><span class="p">],</span>
                           <span class="n">usecols</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin-1&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">movie_titles</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="s1">&#39;itemId&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>


  <span class="k">def</span> <span class="nf">generate_history</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Group all rates given by users and store them from older to most recent.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result :    List(DataFrame)</span>
<span class="sd">                List of the historic for each user</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">historic_users</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">users</span><span class="p">):</span>
      <span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">u</span><span class="p">]</span>
      <span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;timestamp&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
      <span class="n">temp</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">historic_users</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">historic_users</span>

  <span class="k">def</span> <span class="nf">sample_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_histo</span><span class="p">,</span> <span class="n">action_ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="n">max_state</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_action</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[]):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    For a given history, make one or multiple sampling.</span>
<span class="sd">    If no optional argument given for nb_states and nb_actions, then the sampling</span>
<span class="sd">    is random and each sample can have differents size for action and state.</span>
<span class="sd">    To normalize sampling we need to give list of the numbers of states and actions</span>
<span class="sd">    to be sampled.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    user_histo :  DataFrame</span>
<span class="sd">                      historic of user</span>
<span class="sd">    delimiter :       string, optional</span>
<span class="sd">                      delimiter for the csv</span>
<span class="sd">    action_ratio :    float, optional</span>
<span class="sd">                      ratio form which movies in history will be selected</span>
<span class="sd">    max_samp_by_user: int, optional</span>
<span class="sd">                      Nulber max of sample to make by user</span>
<span class="sd">    max_state :       int, optional</span>
<span class="sd">                      Number max of movies to take for the &#39;state&#39; column</span>
<span class="sd">    max_action :      int, optional</span>
<span class="sd">                      Number max of movies to take for the &#39;action&#39; action</span>
<span class="sd">    nb_states :       array(int), optional</span>
<span class="sd">                      Numbers of movies to be taken for each sample made on user&#39;s historic</span>
<span class="sd">    nb_actions :      array(int), optional</span>
<span class="sd">                      Numbers of rating to be taken for each sample made on user&#39;s historic</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    states :         List(String)</span>
<span class="sd">                     All the states sampled, format of a sample: itemId&amp;rating</span>
<span class="sd">    actions :        List(String)</span>
<span class="sd">                     All the actions sampled, format of a sample: itemId&amp;rating</span>
<span class="sd">  </span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    States must be before(timestamp&lt;) the actions.</span>
<span class="sd">    If given, size of nb_states is the numbller of sample by user</span>
<span class="sd">    sizes of nb_states and nb_actions must be equals</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">user_histo</span><span class="p">)</span>
    <span class="n">sep</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">action_ratio</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">nb_sample</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nb_states</span><span class="p">:</span>
      <span class="n">nb_states</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sep</span><span class="p">),</span> <span class="n">max_state</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_sample</span><span class="p">)]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nb_actions</span><span class="p">:</span>
      <span class="n">nb_actions</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">sep</span><span class="p">),</span> <span class="n">max_action</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_sample</span><span class="p">)]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">nb_states</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">),</span> <span class="s1">&#39;Given array must have the same size&#39;</span>
    
    <span class="n">states</span>  <span class="o">=</span> <span class="p">[]</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># SELECT SAMPLES IN HISTORY</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nb_states</span><span class="p">)):</span>
      <span class="n">sample_states</span> <span class="o">=</span> <span class="n">user_histo</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">sep</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nb_states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">sample_actions</span> <span class="o">=</span> <span class="n">user_histo</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">sep</span><span class="p">):]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      
      <span class="n">sample_state</span> <span class="o">=</span>  <span class="p">[]</span>
      <span class="n">sample_action</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_states</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
        <span class="n">row</span>   <span class="o">=</span> <span class="n">sample_states</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="c1"># FORMAT STATE</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;&amp;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;rating&#39;</span><span class="p">])</span>
        <span class="n">sample_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
      
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
        <span class="n">row</span>    <span class="o">=</span> <span class="n">sample_actions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="c1"># FORMAT ACTION</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;&amp;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;rating&#39;</span><span class="p">])</span>
        <span class="n">sample_action</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

      <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_state</span><span class="p">)</span>
      <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_action</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span>

  <span class="k">def</span> <span class="nf">gen_train_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Shuffle the historic of users and separate it in a train and a test set.</span>
<span class="sd">    Store the ids for each set.</span>
<span class="sd">    An user can&#39;t be in both set.</span>

<span class="sd">     Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    test_ratio :  float</span>
<span class="sd">                  Ratio to control the sizes of the sets</span>
<span class="sd">    seed       :  float</span>
<span class="sd">                  Seed on the shuffle</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">random</span><span class="o">.</span><span class="n">Random</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">[:</span><span class="nb">int</span><span class="p">((</span><span class="n">test_ratio</span> <span class="o">*</span> <span class="n">n</span><span class="p">))]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">[</span><span class="nb">int</span><span class="p">((</span><span class="n">test_ratio</span> <span class="o">*</span> <span class="n">n</span><span class="p">)):]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_test</span>  <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">]</span>
    

  <span class="k">def</span> <span class="nf">write_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">histo_to_write</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">,</span> <span class="n">action_ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_state</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_action</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[]):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    From  a given historic, create a csv file with the format:</span>
<span class="sd">    columns : state;action_reward;n_state</span>
<span class="sd">    rows    : itemid&amp;rating1 | itemid&amp;rating2 | ... ; itemid&amp;rating3 | ... | itemid&amp;rating4; itemid&amp;rating1 | itemid&amp;rating2 | itemid&amp;rating3 | ... | item&amp;rating4</span>
<span class="sd">    at filename location.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename :        string</span>
<span class="sd">                      path to the file to be produced</span>
<span class="sd">    histo_to_write :  List(DataFrame)</span>
<span class="sd">                      List of the historic for each user</span>
<span class="sd">    delimiter :       string, optional</span>
<span class="sd">                      delimiter for the csv</span>
<span class="sd">    action_ratio :    float, optional</span>
<span class="sd">                      ratio form which movies in history will be selected</span>
<span class="sd">    max_samp_by_user: int, optional</span>
<span class="sd">                      Nulber max of sample to make by user</span>
<span class="sd">    max_state :       int, optional</span>
<span class="sd">                      Number max of movies to take for the &#39;state&#39; column</span>
<span class="sd">    max_action :      int, optional</span>
<span class="sd">                      Number max of movies to take for the &#39;action&#39; action</span>
<span class="sd">    nb_states :       array(int), optional</span>
<span class="sd">                      Numbers of movies to be taken for each sample made on user&#39;s historic</span>
<span class="sd">    nb_actions :      array(int), optional</span>
<span class="sd">                      Numbers of rating to be taken for each sample made on user&#39;s historic</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    if given, size of nb_states is the numbller of sample by user</span>
<span class="sd">    sizes of nb_states and nb_actions must be equals</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
      <span class="n">f_writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="n">delimiter</span><span class="p">)</span>
      <span class="n">f_writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="s1">&#39;state&#39;</span><span class="p">,</span> <span class="s1">&#39;action_reward&#39;</span><span class="p">,</span> <span class="s1">&#39;n_state&#39;</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">user_histo</span> <span class="ow">in</span> <span class="n">histo_to_write</span><span class="p">:</span>
        <span class="n">states</span><span class="p">,</span> <span class="n">actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_history</span><span class="p">(</span><span class="n">user_histo</span><span class="p">,</span> <span class="n">action_ratio</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="p">,</span> <span class="n">max_state</span><span class="p">,</span> <span class="n">max_action</span><span class="p">,</span> <span class="n">nb_states</span><span class="p">,</span> <span class="n">nb_actions</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)):</span>
          <span class="c1"># FORMAT STATE</span>
          <span class="n">state_str</span>   <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="c1"># FORMAT ACTION</span>
          <span class="n">action_str</span>  <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="c1"># FORMAT N_STATE</span>
          <span class="n">n_state_str</span> <span class="o">=</span> <span class="n">state_str</span> <span class="o">+</span> <span class="s1">&#39;|&#39;</span> <span class="o">+</span> <span class="n">action_str</span>
          <span class="n">f_writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="n">state_str</span><span class="p">,</span> <span class="n">action_str</span><span class="p">,</span> <span class="n">n_state_str</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="EmbeddingsGenerator-class">EmbeddingsGenerator <code>class</code><a class="anchor-link" href="#EmbeddingsGenerator-class"> </a></h3><ol>
<li>Load the data</li>
<li>Build a keras sequential model</li>
<li>Convert train and test set into required format</li>
<li>Train and evaluate the model</li>
<li>Generate item embeddings for each movie id</li>
<li>Save the embeddings into a csv file</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">EmbeddingsGenerator</span><span class="p">:</span>
  <span class="k">def</span>  <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_users</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_users</span> <span class="o">=</span> <span class="n">train_users</span>

    <span class="c1">#preprocess</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">])</span>
    <span class="c1">#make them start at 0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1">#list of rated movies by each user</span>
    <span class="k">for</span> <span class="n">userId</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_count</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">userId</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">userId</span> <span class="o">==</span> <span class="n">userId</span><span class="p">][</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">)))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">m</span>
  
  <span class="k">def</span> <span class="nf">generate_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Returns a context and a target for the user_id</span>
<span class="sd">    context: user&#39;s history with one random movie removed</span>
<span class="sd">    target: id of random removed movie</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">user_movies_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">])</span>
    <span class="c1">#picking random movie</span>
    <span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">user_movies_count</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># -1 avoids taking the last movie</span>
    <span class="c1">#setting target</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">))</span>
    <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">][</span><span class="n">random_index</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1">#setting context</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">))</span>
    <span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">][:</span><span class="n">random_index</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">][</span><span class="n">random_index</span><span class="o">+</span><span class="mi">1</span><span class="p">:]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">target</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_epochs</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Trains the model from train_users&#39;s history</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_epochs</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_epochs</span><span class="p">))</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_input</span><span class="p">(</span><span class="n">user_id</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_users</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
      <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
      <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_users</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Returns [loss, accuracy] on the test set</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">batch_test</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_input</span><span class="p">(</span><span class="n">user_id</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">test_users</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_test</span><span class="p">])</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_test</span><span class="p">])</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">save_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Generates a csv file containg the vector embedding for each movie.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">input</span>                                           <span class="c1"># input placeholder</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">layers</span><span class="p">]</span>          <span class="c1"># all layer outputs</span>
    <span class="n">functor</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="n">inp</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">learning_phase</span><span class="p">()],</span> <span class="n">outputs</span> <span class="p">)</span>   <span class="c1"># evaluation function</span>

    <span class="c1">#append embeddings to vectors</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">movie_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">):</span>
      <span class="n">movie</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">))</span>
      <span class="n">movie</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">movie_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">layer_outs</span> <span class="o">=</span> <span class="n">functor</span><span class="p">([</span><span class="n">movie</span><span class="p">])</span>
      <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">layer_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
      <span class="n">vector</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
      <span class="n">vectors</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">movie_id</span><span class="p">,</span> <span class="n">vector</span><span class="p">])</span>

    <span class="c1">#saves as a csv file</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;item_id&#39;</span><span class="p">,</span> <span class="s1">&#39;vectors&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">&#39;item_id&#39;</span><span class="p">:</span> <span class="s1">&#39;int32&#39;</span><span class="p">})</span>
    <span class="n">embeddings</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Embeddings-helper-class">Embeddings <code>helper class</code><a class="anchor-link" href="#Embeddings-helper-class"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Embeddings</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">item_embeddings</span>
  
  <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  
  <span class="k">def</span> <span class="nf">get_embedding_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span>
  
  <span class="k">def</span> <span class="nf">get_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_index</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">[</span><span class="n">item_index</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_list</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="read_file-helper-function">read_file <code>helper function</code><a class="anchor-link" href="#read_file-helper-function"> </a></h3><p>This function will read the stored data csv files into pandas dataframe</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">read_file</span><span class="p">(</span><span class="n">data_path</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39; Load data from train.csv or test.csv. &#39;&#39;&#39;</span>

  <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">,</span> <span class="s1">&#39;n_state&#39;</span><span class="p">,</span> <span class="s1">&#39;action_reward&#39;</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ee</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;&amp;&#39;</span><span class="p">)]</span> <span class="k">for</span> <span class="n">ee</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)])</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]]</span>
  <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">,</span> <span class="s1">&#39;n_state&#39;</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">l</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]]</span>

  <span class="n">data</span><span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;action_reward&#39;</span><span class="p">]]</span>
  <span class="n">data</span><span class="p">[</span><span class="s1">&#39;reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;action_reward&#39;</span><span class="p">]]</span>
  <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;action_reward&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="read_embeddings-helper-function">read_embeddings <code>helper function</code><a class="anchor-link" href="#read_embeddings-helper-function"> </a></h3><p>This function will read the stored embedding csv file into pandas dataframe and return as multi-dimensional array</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">read_embeddings</span><span class="p">(</span><span class="n">embeddings_path</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39; Load embeddings (a vector for each item). &#39;&#39;&#39;</span>
  
  <span class="n">embeddings</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">embeddings_path</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;;&#39;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)]</span>
                   <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">embeddings</span><span class="p">[</span><span class="s1">&#39;vectors&#39;</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Environment-class">Environment <code>class</code><a class="anchor-link" href="#Environment-class"> </a></h3><p>This is the simulator. It will help orchestrating the whole process of learning list recommendations by our actor-critic based MDP agent.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Environment</span><span class="p">():</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">fixed_length</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">item_id</span><span class="p">)</span> 
      <span class="k">for</span> <span class="n">item_id</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">]])</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">item_id</span><span class="p">)</span> 
      <span class="k">for</span> <span class="n">item_id</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">]])</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">&#39;reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;reward&#39;</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span> <span class="c1"># Î± (alpha) in Equation (1)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span> <span class="c1"># Î“ (Gamma) in Equation (4)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fixed_length</span> <span class="o">=</span> <span class="n">fixed_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_groups</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span>

  <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Compute reward and update state.</span>
<span class="sd">    Args:</span>
<span class="sd">      actions: embedded chosen items.</span>
<span class="sd">    Returns:</span>
<span class="sd">      cumulated_reward: overall reward.</span>
<span class="sd">      current_state: updated state.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># &#39;18: Compute overall reward r_t according to Equation (4)&#39;</span>
    <span class="n">simulated_rewards</span><span class="p">,</span> <span class="n">cumulated_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulate_rewards</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_state</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">actions</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

    <span class="c1"># &#39;11: Set s_t+1 = s_t&#39; &lt;=&gt; self.current_state = self.current_state</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">simulated_rewards</span><span class="p">)):</span> <span class="c1"># &#39;12: for k = 1, K do&#39;</span>
      <span class="k">if</span> <span class="n">simulated_rewards</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># &#39;13: if r_t^k &gt; 0 then&#39;</span>
        <span class="c1"># &#39;14: Add a_t^k to the end of s_t+1&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span> <span class="p">[</span><span class="n">actions</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_length</span><span class="p">:</span> <span class="c1"># &#39;15: Remove the first item of s_t+1&#39;</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cumulated_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span>

  <span class="k">def</span> <span class="nf">get_groups</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Calculate average state/action value for each group. Equation (3). &#39;&#39;&#39;</span>

    <span class="n">groups</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;reward&#39;</span><span class="p">]):</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
      <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
      <span class="n">groups</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="n">size</span><span class="p">,</span> <span class="c1"># N_x in article</span>
        <span class="s1">&#39;rewards&#39;</span><span class="p">:</span> <span class="n">rewards</span><span class="p">,</span> <span class="c1"># U_x in article (combination of rewards)</span>
        <span class="s1">&#39;average state&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">states</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="c1"># s_x^-</span>
        <span class="s1">&#39;average action&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">actions</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># a_x^-</span>
      <span class="p">})</span>
    <span class="k">return</span> <span class="n">groups</span>

  <span class="k">def</span> <span class="nf">simulate_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_state</span><span class="p">,</span> <span class="n">chosen_actions</span><span class="p">,</span> <span class="n">reward_type</span><span class="o">=</span><span class="s1">&#39;grouped cosine&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Calculate simulated rewards.</span>
<span class="sd">    Args:</span>
<span class="sd">      current_state: history, list of embedded items.</span>
<span class="sd">      chosen_actions: embedded chosen items.</span>
<span class="sd">      reward_type: from [&#39;normal&#39;, &#39;grouped average&#39;, &#39;grouped cosine&#39;].</span>
<span class="sd">    Returns:</span>
<span class="sd">      returned_rewards: most probable rewards.</span>
<span class="sd">      cumulated_reward: probability weighted rewards.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Equation (1)</span>
    <span class="k">def</span> <span class="nf">cosine_state_action</span><span class="p">(</span><span class="n">s_t</span><span class="p">,</span> <span class="n">a_t</span><span class="p">,</span> <span class="n">s_i</span><span class="p">,</span> <span class="n">a_i</span><span class="p">):</span>
      <span class="n">cosine_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s_t</span><span class="p">,</span> <span class="n">s_i</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">s_t</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">s_i</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="n">cosine_action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="n">a_i</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a_i</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">cosine_state</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">cosine_action</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>

    <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span>
      <span class="c1"># Calculate simulated reward in normal way: Equation (2)</span>
      <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[</span><span class="n">cosine_state_action</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">chosen_actions</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;state&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;grouped average&#39;</span><span class="p">:</span>
      <span class="c1"># Calculate simulated reward by grouped average: Equation (3)</span>
      <span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">])</span> <span class="o">*</span>\
        <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="s1">&#39;average state&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>\
        <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">chosen_actions</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="s1">&#39;average action&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">chosen_actions</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;grouped cosine&#39;</span><span class="p">:</span>
      <span class="c1"># Calculate simulated reward by grouped cosine: Equations (1) and (3)</span>
      <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[</span><span class="n">cosine_state_action</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">chosen_actions</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="s1">&#39;average state&#39;</span><span class="p">],</span> <span class="n">g</span><span class="p">[</span><span class="s1">&#39;average action&#39;</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">]</span>

    <span class="c1"># Normalize (sum to 1)</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>

    <span class="c1"># Get most probable rewards</span>
    <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span>
      <span class="n">returned_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)][</span><span class="s1">&#39;reward&#39;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;grouped average&#39;</span><span class="p">,</span> <span class="s1">&#39;grouped cosine&#39;</span><span class="p">]:</span>
      <span class="n">returned_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)][</span><span class="s1">&#39;rewards&#39;</span><span class="p">]</span>

    <span class="c1"># Equation (4)</span>
    <span class="k">def</span> <span class="nf">overall_reward</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">gamma</span><span class="o">**</span><span class="n">k</span> <span class="o">*</span> <span class="n">reward</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">reward</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rewards</span><span class="p">)])</span>

    <span class="k">if</span> <span class="n">reward_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="s1">&#39;grouped average&#39;</span><span class="p">]:</span>
      <span class="c1"># Get cumulated reward: Equation (4)</span>
      <span class="n">cumulated_reward</span> <span class="o">=</span> <span class="n">overall_reward</span><span class="p">(</span><span class="n">returned_rewards</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;grouped cosine&#39;</span><span class="p">:</span>
      <span class="c1"># Get probability weighted cumulated reward</span>
      <span class="n">cumulated_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">p</span> <span class="o">*</span> <span class="n">overall_reward</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;rewards&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)])</span>

    <span class="k">return</span> <span class="n">returned_rewards</span><span class="p">,</span> <span class="n">cumulated_reward</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Actor-class">Actor <code>class</code><a class="anchor-link" href="#Actor-class"> </a></h3><p>This is the policy approximator actor</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Actor</span><span class="p">():</span>
  <span class="sd">&#39;&#39;&#39; Policy function approximator. &#39;&#39;&#39;</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;actor&#39;</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">sess</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span> <span class="o">=</span> <span class="n">state_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">action_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ra_length</span> <span class="o">=</span> <span class="n">ra_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span> <span class="o">=</span> <span class="n">history_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope</span> <span class="o">=</span> <span class="n">scope</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Build Actor network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">action_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">&#39;estimator_actor&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>

      <span class="c1"># Build target Actor network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_action_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">&#39;target_actor&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">):]</span> <span class="c1"># TODO: why sublist [len(x):]? Maybe because its equal to network_params + target_network_params</span>

      <span class="c1"># Initialize target network weights with network weights (Î¸^Ï€â€² â† Î¸^Ï€)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>
        
      <span class="c1"># Update target network weights (Î¸^Ï€â€² â† Ï„Î¸^Ï€ + (1 âˆ’ Ï„)Î¸^Ï€â€²)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>

      <span class="c1"># Gradient computation from Critic&#39;s action_gradients</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">])</span>
      <span class="n">gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_weights</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;42222222222&#39;</span><span class="p">),</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span><span class="p">)</span>
      <span class="n">params_gradients</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">),</span> <span class="n">gradients</span><span class="p">))</span>
      
      <span class="c1"># Compute âˆ‡_a.Q(s, a|Î¸^Âµ).âˆ‡_Î¸^Ï€.f_Î¸^Ï€(s)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
          <span class="nb">zip</span><span class="p">(</span><span class="n">params_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_build_net</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Build the (target) Actor network. &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">gather_last_output</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
      <span class="k">def</span> <span class="nf">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

      <span class="n">batch_range</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">tmp_end</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">seq_lens</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">tmp_end</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Inputs: current state, sequence_length</span>
      <span class="c1"># Outputs: action weights to compute the score Equation (6)</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">],</span> <span class="s1">&#39;state&#39;</span><span class="p">)</span>
      <span class="n">state_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>
      <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="s1">&#39;sequence_length&#39;</span><span class="p">)</span>
      <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
                                    <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                                    <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(),</span>
                                    <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">state_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">)</span>
      <span class="n">last_output</span> <span class="o">=</span> <span class="n">gather_last_output</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span> <span class="c1"># TODO: replace by h</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ra_length</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">)(</span><span class="n">last_output</span><span class="p">)</span>
      <span class="n">action_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ra_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">action_weights</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">action_gradients</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;  Compute âˆ‡_a.Q(s, a|Î¸^Âµ).âˆ‡_Î¸^Ï€.f_Î¸^Ï€(s). &#39;&#39;&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span><span class="p">:</span> <span class="n">action_gradients</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_weights</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_action_weights</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">init_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">update_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">get_recommendation_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">noisy_state</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Algorithm 2</span>
<span class="sd">    Args:</span>
<span class="sd">      ra_length: length of the recommendation list.</span>
<span class="sd">      noisy_state: current/remembered environment state with noise.</span>
<span class="sd">      embeddings: Embeddings object.</span>
<span class="sd">      target: boolean to use Actor&#39;s network or target network.</span>
<span class="sd">    Returns:</span>
<span class="sd">      Recommendation List: list of embedded items as future actions.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
      <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">      Equation (6)</span>
<span class="sd">      Args:</span>
<span class="sd">        weights: w_t^k shape=(embedding_size,).</span>
<span class="sd">        embedding: e_i shape=(embedding_size,).</span>
<span class="sd">      Returns:</span>
<span class="sd">        score of the item i: score_i=w_t^k.e_i^T shape=(1,).</span>
<span class="sd">      &#39;&#39;&#39;</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">embedding</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">ret</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">noisy_state</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># &#39;1: Generate w_t = {w_t^1, ..., w_t^K} according to Equation (5)&#39;</span>
    <span class="n">method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_target</span> <span class="k">if</span> <span class="n">target</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">method</span><span class="p">(</span><span class="n">noisy_state</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="c1"># &#39;3: Score items in I according to Equation (6)&#39;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="n">get_score</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">],</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding_vector</span><span class="p">()]</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ra_length</span><span class="p">)]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>

    <span class="c1"># &#39;8: return a_t&#39;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]))</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ra_length</span><span class="p">)]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Critic-class">Critic <code>class</code><a class="anchor-link" href="#Critic-class"> </a></h3><p>This is the value approximator critic</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Critic</span><span class="p">():</span>
  <span class="sd">&#39;&#39;&#39; Value function approximator. &#39;&#39;&#39;</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;critic&#39;</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">sess</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span> <span class="o">=</span> <span class="n">state_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">action_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span> <span class="o">=</span> <span class="n">history_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope</span> <span class="o">=</span> <span class="n">scope</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Build Critic network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">&#39;estimator_critic&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">TRAINABLE_VARIABLES</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;estimator_critic&#39;</span><span class="p">)</span>

      <span class="c1"># Build target Critic network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">&#39;target_critic&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">TRAINABLE_VARIABLES</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;target_critic&#39;</span><span class="p">)</span>

      <span class="c1"># Initialize target network weights with network weights (Î¸^Âµâ€² â† Î¸^Âµ)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>

      <span class="c1"># Update target network weights (Î¸^Âµâ€² â† Ï„Î¸^Âµ + (1 âˆ’ Ï„)Î¸^Âµâ€²)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>

      <span class="c1"># Minimize MSE between Critic&#39;s and target Critic&#39;s outputed Q-values</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">expected_reward</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">expected_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

      <span class="c1"># Compute âˆ‡_a.Q(s, a|Î¸^Âµ)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_build_net</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Build the (target) Critic network. &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">gather_last_output</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
      <span class="k">def</span> <span class="nf">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

      <span class="n">this_range</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">seq_lens</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">tmp_end</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">seq_lens</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">this_range</span><span class="p">,</span> <span class="n">tmp_end</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Inputs: current state, current action</span>
      <span class="c1"># Outputs: predicted Q-value</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">],</span> <span class="s1">&#39;state&#39;</span><span class="p">)</span>
      <span class="n">state_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>
      <span class="n">action</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">],</span> <span class="s1">&#39;action&#39;</span><span class="p">)</span>
      <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;critic_sequence_length&#39;</span><span class="p">)</span>
      <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_length</span><span class="p">,</span>
                                    <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                                    <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(),</span>
                                    <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
      <span class="n">predicted_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">state_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">)</span>
      <span class="n">predicted_state</span> <span class="o">=</span> <span class="n">gather_last_output</span><span class="p">(</span><span class="n">predicted_state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>

      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">predicted_state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">layer1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">layer2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">layer1</span><span class="p">)</span>
      <span class="n">critic_Q_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">layer2</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">critic_Q_value</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">expected_reward</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Minimize MSE between expected reward and target Critic&#39;s Q-value. &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">],</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">expected_reward</span><span class="p">:</span> <span class="n">expected_reward</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Returns Critic&#39;s predicted Q-value. &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Returns target Critic&#39;s predicted Q-value. &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_Q_value</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">get_action_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Returns âˆ‡_a.Q(s, a|Î¸^Âµ). &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})[</span><span class="mi">0</span><span class="p">])</span>

  <span class="k">def</span> <span class="nf">init_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">update_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReplayMemory-class">ReplayMemory <code>class</code><a class="anchor-link" href="#ReplayMemory-class"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">ReplayMemory</span><span class="p">():</span>
  <span class="sd">&#39;&#39;&#39; Replay memory D. &#39;&#39;&#39;</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
    <span class="c1"># self.buffer = [[row[&#39;state&#39;], row[&#39;action&#39;], row[&#39;reward&#39;], row[&#39;n_state&#39;]] for _, row in data.iterrows()][-self.buffer_size:] TODO: empty or not?</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">n_state</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">n_state</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">sample_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="experience_replay-function">experience_replay <code>function</code><a class="anchor-link" href="#experience_replay-function"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">experience_replay</span><span class="p">(</span><span class="n">replay_memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">discount_factor</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  Experience replay.</span>
<span class="sd">  Args:</span>
<span class="sd">    replay_memory: replay memory D in article.</span>
<span class="sd">    batch_size: sample size.</span>
<span class="sd">    actor: Actor network.</span>
<span class="sd">    critic: Critic network.</span>
<span class="sd">    embeddings: Embeddings object.</span>
<span class="sd">    state_space_size: dimension of states.</span>
<span class="sd">    action_space_size: dimensions of actions.</span>
<span class="sd">  Returns:</span>
<span class="sd">    Best Q-value, loss of Critic network for printing/recording purpose.</span>
<span class="sd">  &#39;&#39;&#39;</span>

  <span class="c1"># &#39;22: Sample minibatch of N transitions (s, a, r, sâ€²) from D&#39;</span>
  <span class="n">samples</span> <span class="o">=</span> <span class="n">replay_memory</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
  <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
  <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
  <span class="n">n_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">)</span>

  <span class="c1"># &#39;23: Generate aâ€² by target Actor network according to Algorithm 2&#39;</span>
  <span class="n">n_actions</span> <span class="o">=</span> <span class="n">actor</span><span class="o">.</span><span class="n">get_recommendation_list</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">)</span>

  <span class="c1"># Calculate predicted Qâ€²(sâ€², aâ€²|Î¸^Âµâ€²) value</span>
  <span class="n">target_Q_value</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">predict_target</span><span class="p">(</span><span class="n">n_states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>

  <span class="c1"># &#39;24: Set y = r + Î³Qâ€²(sâ€², aâ€²|Î¸^Âµâ€²)&#39;</span>
  <span class="n">expected_rewards</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">target_Q_value</span>
  
  <span class="c1"># &#39;25: Update Critic by minimizing (y âˆ’ Q(s, a|Î¸^Âµ))Â²&#39;</span>
  <span class="n">critic_Q_value</span><span class="p">,</span> <span class="n">critic_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">expected_rewards</span><span class="p">)</span>
  
  <span class="c1"># &#39;26: Update the Actor using the sampled policy gradient&#39;</span>
  <span class="n">action_gradients</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">get_action_gradients</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
  <span class="n">actor</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">action_gradients</span><span class="p">)</span>

  <span class="c1"># &#39;27: Update the Critic target networks&#39;</span>
  <span class="n">critic</span><span class="o">.</span><span class="n">update_target_network</span><span class="p">()</span>

  <span class="c1"># &#39;28: Update the Actor target network&#39;</span>
  <span class="n">actor</span><span class="o">.</span><span class="n">update_target_network</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">critic_Q_value</span><span class="p">),</span> <span class="n">critic_loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OrnsteinUhlenbeckNoise-class">OrnsteinUhlenbeckNoise <code>class</code><a class="anchor-link" href="#OrnsteinUhlenbeckNoise-class"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">OrnsteinUhlenbeckNoise</span><span class="p">:</span>
  <span class="sd">&#39;&#39;&#39; Noise for Actor predictions. &#39;&#39;&#39;</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">action_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span>

  <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">environment</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">discount_factor</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="p">,</span> <span class="n">filename_summary</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39; Algorithm 3 in article. &#39;&#39;&#39;</span>

  <span class="c1"># Set up summary operators</span>
  <span class="k">def</span> <span class="nf">build_summaries</span><span class="p">():</span>
    <span class="n">episode_reward</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;reward&#39;</span><span class="p">,</span> <span class="n">episode_reward</span><span class="p">)</span>
    <span class="n">episode_max_Q</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;max_Q_value&#39;</span><span class="p">,</span> <span class="n">episode_max_Q</span><span class="p">)</span>
    <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;critic_loss&#39;</span><span class="p">,</span> <span class="n">critic_loss</span><span class="p">)</span>

    <span class="n">summary_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">episode_reward</span><span class="p">,</span> <span class="n">episode_max_Q</span><span class="p">,</span> <span class="n">critic_loss</span><span class="p">]</span>
    <span class="n">summary_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">summary_ops</span><span class="p">,</span> <span class="n">summary_vars</span>

  <span class="n">summary_ops</span><span class="p">,</span> <span class="n">summary_vars</span> <span class="o">=</span> <span class="n">build_summaries</span><span class="p">()</span>
  <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
  <span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">filename_summary</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

  <span class="c1"># &#39;2: Initialize target network fâ€² and Qâ€²&#39;</span>
  <span class="n">actor</span><span class="o">.</span><span class="n">init_target_network</span><span class="p">()</span>
  <span class="n">critic</span><span class="o">.</span><span class="n">init_target_network</span><span class="p">()</span>

  <span class="c1"># &#39;3: Initialize the capacity of replay memory D&#39;</span>
  <span class="n">replay_memory</span> <span class="o">=</span> <span class="n">ReplayMemory</span><span class="p">(</span><span class="n">buffer_size</span><span class="p">)</span> <span class="c1"># Memory D in article</span>
  <span class="n">replay</span> <span class="o">=</span> <span class="kc">False</span>


  <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i_session</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_episodes</span><span class="p">):</span> <span class="c1"># &#39;4: for session = 1, M do&#39;</span>
    <span class="n">session_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">session_Q_value</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">session_critic_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># &#39;5: Reset the item space I&#39; is useless because unchanged.</span>

    <span class="n">states</span> <span class="o">=</span> <span class="n">environment</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># &#39;6: Initialize state s_0 from previous sessions&#39;</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">i_session</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Update average parameters every 10 episodes</span>
      <span class="n">environment</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">environment</span><span class="o">.</span><span class="n">get_groups</span><span class="p">()</span>
      
    <span class="n">exploration_noise</span> <span class="o">=</span> <span class="n">OrnsteinUhlenbeckNoise</span><span class="p">(</span><span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_rounds</span><span class="p">):</span> <span class="c1"># &#39;7: for t = 1, T do&#39;</span>
      <span class="c1"># &#39;8: Stage 1: Transition Generating Stage&#39;</span>

      <span class="c1"># &#39;9: Select an action a_t = {a_t^1, ..., a_t^K} according to Algorithm 2&#39;</span>
      <span class="n">actions</span> <span class="o">=</span> <span class="n">actor</span><span class="o">.</span><span class="n">get_recommendation_list</span><span class="p">(</span>
          <span class="n">ra_length</span><span class="p">,</span>
          <span class="n">states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># TODO + exploration_noise.get().reshape(1, -1),</span>
          <span class="n">embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

      <span class="c1"># &#39;10: Execute action a_t and observe the reward list {r_t^1, ..., r_t^K} for each item in a_t&#39;</span>
      <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="n">environment</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>

      <span class="c1"># &#39;19: Store transition (s_t, a_t, r_t, s_t+1) in D&#39;</span>
      <span class="n">replay_memory</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                        <span class="n">actions</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ra_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                        <span class="p">[</span><span class="n">rewards</span><span class="p">],</span>
                        <span class="n">next_states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>

      <span class="n">states</span> <span class="o">=</span> <span class="n">next_states</span> <span class="c1"># &#39;20: Set s_t = s_t+1&#39;</span>

      <span class="n">session_reward</span> <span class="o">+=</span> <span class="n">rewards</span>
      
      <span class="c1"># &#39;21: Stage 2: Parameter Updating Stage&#39;</span>
      <span class="k">if</span> <span class="n">replay_memory</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">batch_size</span><span class="p">:</span> <span class="c1"># Experience replay</span>
        <span class="n">replay</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">replay_Q_value</span><span class="p">,</span> <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">experience_replay</span><span class="p">(</span><span class="n">replay_memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
          <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
          <span class="n">ra_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">discount_factor</span><span class="p">)</span>
        <span class="n">session_Q_value</span> <span class="o">+=</span> <span class="n">replay_Q_value</span>
        <span class="n">session_critic_loss</span> <span class="o">+=</span> <span class="n">critic_loss</span>

      <span class="n">summary_str</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">summary_ops</span><span class="p">,</span>
                             <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">summary_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">session_reward</span><span class="p">,</span>
                                        <span class="n">summary_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">session_Q_value</span><span class="p">,</span>
                                        <span class="n">summary_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">session_critic_loss</span><span class="p">})</span>
      
      <span class="n">writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary_str</span><span class="p">,</span> <span class="n">i_session</span><span class="p">)</span>

      <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">      print(state_to_items(embeddings.embed(data[&#39;state&#39;][0]), actor, ra_length, embeddings),</span>
<span class="sd">            state_to_items(embeddings.embed(data[&#39;state&#39;][0]), actor, ra_length, embeddings, True))</span>
<span class="sd">      &#39;&#39;&#39;</span>

    <span class="n">str_loss</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;Loss=</span><span class="si">%0.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">session_critic_loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Episode </span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1"> Reward=</span><span class="si">%d</span><span class="s1"> Time=</span><span class="si">%d</span><span class="s1">s &#39;</span> <span class="o">+</span> <span class="p">(</span><span class="n">str_loss</span> <span class="k">if</span> <span class="n">replay</span> <span class="k">else</span> <span class="s1">&#39;No replay&#39;</span><span class="p">))</span> <span class="o">%</span> <span class="p">(</span><span class="n">i_session</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="p">,</span> <span class="n">session_reward</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

  <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;models.h5&#39;</span><span class="p">,</span> <span class="n">write_meta_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">history_length</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># N in article</span>
<span class="n">ra_length</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># K in article</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.99</span> <span class="c1"># Gamma in Bellman equation</span>
<span class="n">actor_lr</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">critic_lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># Ï„ in Algorithm 3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">nb_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">nb_rounds</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">filename_summary</span> <span class="o">=</span> <span class="s1">&#39;summary.txt&#39;</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># Î± (alpha) in Equation (1)</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># Î“ (Gamma) in Equation (4)</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">1000000</span> <span class="c1"># Size of replay memory D in article</span>
<span class="n">fixed_length</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Fixed memory length</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-generation">Data generation<a class="anchor-link" href="#Data-generation"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">dg</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="s1">&#39;ml-100k/u.data&#39;</span><span class="p">,</span> <span class="s1">&#39;ml-100k/u.item&#39;</span><span class="p">)</span>
<span class="n">dg</span><span class="o">.</span><span class="n">gen_train_test</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">dg</span><span class="o">.</span><span class="n">write_csv</span><span class="p">(</span><span class="s1">&#39;train.csv&#39;</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[</span><span class="n">history_length</span><span class="p">],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[</span><span class="n">ra_length</span><span class="p">])</span>
<span class="n">dg</span><span class="o">.</span><span class="n">write_csv</span><span class="p">(</span><span class="s1">&#39;test.csv&#39;</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[</span><span class="n">history_length</span><span class="p">],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[</span><span class="n">ra_length</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">read_file</span><span class="p">(</span><span class="s1">&#39;train.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>n_state</th>
      <th>action</th>
      <th>reward</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[1050, 488, 497, 202, 64, 605, 173, 527, 674, ...</td>
      <td>[1050, 488, 497, 202, 64, 605, 173, 527, 674, ...</td>
      <td>[1074, 346, 94, 105]</td>
      <td>(2, 4, 2, 3)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[534, 280, 302, 1038, 887, 333, 278, 847, 256,...</td>
      <td>[534, 280, 302, 1038, 887, 333, 278, 847, 256,...</td>
      <td>[345, 904, 171, 718]</td>
      <td>(4, 4, 3, 3)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[989, 302, 272, 329, 343, 258, 313, 347, 300, ...</td>
      <td>[989, 302, 272, 329, 343, 258, 313, 347, 300, ...</td>
      <td>[689, 289, 271, 751]</td>
      <td>(4, 5, 4, 4)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[235, 192, 169, 952, 86, 603, 510, 127, 530, 4...</td>
      <td>[235, 192, 169, 952, 86, 603, 510, 127, 530, 4...</td>
      <td>[735, 273, 151, 654]</td>
      <td>(3, 4, 5, 4)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[132, 566, 433, 393, 1115, 185, 692, 154, 216,...</td>
      <td>[132, 566, 433, 393, 1115, 185, 692, 154, 216,...</td>
      <td>[1160, 281, 343, 137]</td>
      <td>(5, 3, 3, 5)</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Embedding-generation">Embedding generation<a class="anchor-link" href="#Embedding-generation"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">if</span> <span class="kc">True</span><span class="p">:</span> <span class="c1"># Generate embeddings?</span>
  <span class="n">eg</span> <span class="o">=</span> <span class="n">EmbeddingsGenerator</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">user_train</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;ml-100k/u.data&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">,</span> <span class="s1">&#39;itemId&#39;</span><span class="p">,</span> <span class="s1">&#39;rating&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span><span class="p">]))</span>
  <span class="n">eg</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">nb_epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
  <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">eg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">user_train</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train set: Loss=</span><span class="si">%.4f</span><span class="s1"> ; Accuracy=</span><span class="si">%.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
  <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">eg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">user_test</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set: Loss=</span><span class="si">%.4f</span><span class="s1"> ; Accuracy=</span><span class="si">%.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
  <span class="n">eg</span><span class="o">.</span><span class="n">save_embeddings</span><span class="p">(</span><span class="s1">&#39;embeddings.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1/300
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 495us/step - loss: 6.9263 - accuracy: 0.0110 - val_loss: 6.5268 - val_accuracy: 0.0134
2/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 6.4680 - accuracy: 0.0118 - val_loss: 6.2999 - val_accuracy: 0.0178
3/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 6.3099 - accuracy: 0.0146 - val_loss: 6.2204 - val_accuracy: 0.0162
4/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 6.2146 - accuracy: 0.0160 - val_loss: 6.1397 - val_accuracy: 0.0190
5/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 6.1541 - accuracy: 0.0158 - val_loss: 6.0923 - val_accuracy: 0.0202
6/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 6.1034 - accuracy: 0.0224 - val_loss: 6.0950 - val_accuracy: 0.0246
7/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 6.0729 - accuracy: 0.0230 - val_loss: 5.9786 - val_accuracy: 0.0198
8/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 6.0400 - accuracy: 0.0216 - val_loss: 5.9752 - val_accuracy: 0.0210
9/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 5.9840 - accuracy: 0.0240 - val_loss: 5.9695 - val_accuracy: 0.0234
10/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 5.9753 - accuracy: 0.0226 - val_loss: 5.9602 - val_accuracy: 0.0258
11/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 5.9451 - accuracy: 0.0276 - val_loss: 5.9046 - val_accuracy: 0.0284
12/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 409us/step - loss: 5.9366 - accuracy: 0.0238 - val_loss: 5.8897 - val_accuracy: 0.0342
13/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 5.8944 - accuracy: 0.0308 - val_loss: 5.8403 - val_accuracy: 0.0328
14/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 5.8901 - accuracy: 0.0288 - val_loss: 5.7764 - val_accuracy: 0.0344
15/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 5.8474 - accuracy: 0.0338 - val_loss: 5.8088 - val_accuracy: 0.0404
16/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 5.8704 - accuracy: 0.0338 - val_loss: 5.7251 - val_accuracy: 0.0408
17/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 5.8386 - accuracy: 0.0380 - val_loss: 5.7551 - val_accuracy: 0.0424
18/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 5.8129 - accuracy: 0.0396 - val_loss: 5.7250 - val_accuracy: 0.0384
19/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 411us/step - loss: 5.7635 - accuracy: 0.0434 - val_loss: 5.7054 - val_accuracy: 0.0456
20/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 5.7585 - accuracy: 0.0408 - val_loss: 5.6668 - val_accuracy: 0.0544
21/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 5.7168 - accuracy: 0.0510 - val_loss: 5.6489 - val_accuracy: 0.0614
22/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 5.7281 - accuracy: 0.0514 - val_loss: 5.6563 - val_accuracy: 0.0566
23/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 445us/step - loss: 5.6554 - accuracy: 0.0550 - val_loss: 5.5874 - val_accuracy: 0.0642
24/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 5.6469 - accuracy: 0.0566 - val_loss: 5.5724 - val_accuracy: 0.0644
25/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 5.6121 - accuracy: 0.0602 - val_loss: 5.5237 - val_accuracy: 0.0700
26/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 5.5610 - accuracy: 0.0642 - val_loss: 5.4931 - val_accuracy: 0.0782
27/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 5.5919 - accuracy: 0.0696 - val_loss: 5.4770 - val_accuracy: 0.0744
28/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 5.5000 - accuracy: 0.0744 - val_loss: 5.4322 - val_accuracy: 0.0792
29/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 5.5499 - accuracy: 0.0674 - val_loss: 5.4572 - val_accuracy: 0.0904
30/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 5.5014 - accuracy: 0.0748 - val_loss: 5.3764 - val_accuracy: 0.0908
31/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 5.4641 - accuracy: 0.0860 - val_loss: 5.3696 - val_accuracy: 0.0918
32/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 5.4016 - accuracy: 0.0856 - val_loss: 5.3434 - val_accuracy: 0.0992
33/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 5.4216 - accuracy: 0.0812 - val_loss: 5.2951 - val_accuracy: 0.1048
34/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 5.3415 - accuracy: 0.0898 - val_loss: 5.2822 - val_accuracy: 0.1108
35/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 5.3568 - accuracy: 0.0944 - val_loss: 5.2389 - val_accuracy: 0.1220
36/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 5.3402 - accuracy: 0.0978 - val_loss: 5.1883 - val_accuracy: 0.1184
37/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 5.2599 - accuracy: 0.1062 - val_loss: 5.1733 - val_accuracy: 0.1184
38/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 5.2709 - accuracy: 0.1030 - val_loss: 5.1164 - val_accuracy: 0.1304
39/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 5.2505 - accuracy: 0.1156 - val_loss: 5.0603 - val_accuracy: 0.1434
40/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 5.1489 - accuracy: 0.1200 - val_loss: 5.1065 - val_accuracy: 0.1440
41/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 5.1701 - accuracy: 0.1156 - val_loss: 5.0640 - val_accuracy: 0.1454
42/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 5.1677 - accuracy: 0.1254 - val_loss: 4.9177 - val_accuracy: 0.1684
43/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 5.0957 - accuracy: 0.1282 - val_loss: 4.9440 - val_accuracy: 0.1658
44/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 5.0372 - accuracy: 0.1404 - val_loss: 4.8884 - val_accuracy: 0.1710
45/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 5.0039 - accuracy: 0.1436 - val_loss: 4.8760 - val_accuracy: 0.1732
46/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 4.9804 - accuracy: 0.1410 - val_loss: 4.9184 - val_accuracy: 0.1790
47/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 4.9832 - accuracy: 0.1460 - val_loss: 4.8998 - val_accuracy: 0.1838
48/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 4.9988 - accuracy: 0.1512 - val_loss: 4.7654 - val_accuracy: 0.1968
49/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 409us/step - loss: 4.9118 - accuracy: 0.1526 - val_loss: 4.7077 - val_accuracy: 0.2076
50/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 4.8632 - accuracy: 0.1708 - val_loss: 4.7240 - val_accuracy: 0.2040
51/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 4.8099 - accuracy: 0.1764 - val_loss: 4.6635 - val_accuracy: 0.2200
52/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 4.7629 - accuracy: 0.1808 - val_loss: 4.6080 - val_accuracy: 0.2232
53/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 4.7340 - accuracy: 0.1838 - val_loss: 4.5219 - val_accuracy: 0.2426
54/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 4.7015 - accuracy: 0.1846 - val_loss: 4.5267 - val_accuracy: 0.2326
55/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 4.6569 - accuracy: 0.2002 - val_loss: 4.4797 - val_accuracy: 0.2470
56/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 4.6166 - accuracy: 0.2022 - val_loss: 4.4646 - val_accuracy: 0.2442
57/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 4.5724 - accuracy: 0.2170 - val_loss: 4.4611 - val_accuracy: 0.2614
58/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 4.5426 - accuracy: 0.2156 - val_loss: 4.3576 - val_accuracy: 0.2710
59/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 4.4908 - accuracy: 0.2298 - val_loss: 4.2942 - val_accuracy: 0.2756
60/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 4.4745 - accuracy: 0.2290 - val_loss: 4.2756 - val_accuracy: 0.2894
61/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 4.4500 - accuracy: 0.2270 - val_loss: 4.2529 - val_accuracy: 0.2930
62/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 4.4236 - accuracy: 0.2432 - val_loss: 4.1556 - val_accuracy: 0.3044
63/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 4.3458 - accuracy: 0.2470 - val_loss: 4.1702 - val_accuracy: 0.3056
64/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 4.2841 - accuracy: 0.2640 - val_loss: 4.1011 - val_accuracy: 0.3198
65/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 4.2623 - accuracy: 0.2644 - val_loss: 4.0939 - val_accuracy: 0.3148
66/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 4.1786 - accuracy: 0.2742 - val_loss: 4.0215 - val_accuracy: 0.3366
67/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 4.1830 - accuracy: 0.2786 - val_loss: 3.9993 - val_accuracy: 0.3494
68/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 4.1440 - accuracy: 0.2856 - val_loss: 3.8984 - val_accuracy: 0.3626
69/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 4.1597 - accuracy: 0.2800 - val_loss: 3.8628 - val_accuracy: 0.3628
70/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 4.0412 - accuracy: 0.3018 - val_loss: 3.8560 - val_accuracy: 0.3714
71/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 3.9953 - accuracy: 0.3144 - val_loss: 3.7981 - val_accuracy: 0.3874
72/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 4.0206 - accuracy: 0.3118 - val_loss: 3.6810 - val_accuracy: 0.4042
73/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 3.8894 - accuracy: 0.3260 - val_loss: 3.7203 - val_accuracy: 0.4036
74/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 3.8508 - accuracy: 0.3272 - val_loss: 3.6657 - val_accuracy: 0.4172
75/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 3.8432 - accuracy: 0.3390 - val_loss: 3.5954 - val_accuracy: 0.4250
76/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 3.7696 - accuracy: 0.3484 - val_loss: 3.5474 - val_accuracy: 0.4334
77/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 3.7487 - accuracy: 0.3440 - val_loss: 3.4959 - val_accuracy: 0.4438
78/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 3.6725 - accuracy: 0.3674 - val_loss: 3.4610 - val_accuracy: 0.4438
79/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 3.6026 - accuracy: 0.3854 - val_loss: 3.4438 - val_accuracy: 0.4460
80/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 3.6333 - accuracy: 0.3724 - val_loss: 3.3397 - val_accuracy: 0.4724
81/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 3.6077 - accuracy: 0.3756 - val_loss: 3.3388 - val_accuracy: 0.4696
82/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 3.5452 - accuracy: 0.3906 - val_loss: 3.2877 - val_accuracy: 0.4830
83/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 3.4469 - accuracy: 0.3982 - val_loss: 3.2358 - val_accuracy: 0.4916
84/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 3.4682 - accuracy: 0.4054 - val_loss: 3.1429 - val_accuracy: 0.5058
85/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 411us/step - loss: 3.4239 - accuracy: 0.4150 - val_loss: 3.1567 - val_accuracy: 0.5112
86/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 3.3371 - accuracy: 0.4314 - val_loss: 3.0750 - val_accuracy: 0.5336
87/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 3.3098 - accuracy: 0.4342 - val_loss: 2.9687 - val_accuracy: 0.5484
88/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 3.2436 - accuracy: 0.4448 - val_loss: 2.9758 - val_accuracy: 0.5428
89/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 3.1683 - accuracy: 0.4678 - val_loss: 2.9616 - val_accuracy: 0.5556
90/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 3.1165 - accuracy: 0.4724 - val_loss: 2.9104 - val_accuracy: 0.5614
91/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 3.1052 - accuracy: 0.4714 - val_loss: 2.9149 - val_accuracy: 0.5554
92/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 2.9836 - accuracy: 0.4904 - val_loss: 2.8334 - val_accuracy: 0.5690
93/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 3.0339 - accuracy: 0.4924 - val_loss: 2.7953 - val_accuracy: 0.5842
94/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 2.9270 - accuracy: 0.5030 - val_loss: 2.6870 - val_accuracy: 0.6066
95/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 2.9110 - accuracy: 0.5118 - val_loss: 2.6570 - val_accuracy: 0.6106
96/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 2.8658 - accuracy: 0.5188 - val_loss: 2.5933 - val_accuracy: 0.6158
97/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 2.8452 - accuracy: 0.5216 - val_loss: 2.5700 - val_accuracy: 0.6258
98/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 2.7918 - accuracy: 0.5378 - val_loss: 2.5877 - val_accuracy: 0.6228
99/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 2.6794 - accuracy: 0.5442 - val_loss: 2.5276 - val_accuracy: 0.6344
100/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 2.7009 - accuracy: 0.5410 - val_loss: 2.4005 - val_accuracy: 0.6526
101/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 2.6680 - accuracy: 0.5576 - val_loss: 2.4220 - val_accuracy: 0.6398
102/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 2.5977 - accuracy: 0.5708 - val_loss: 2.3582 - val_accuracy: 0.6704
103/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 2.5625 - accuracy: 0.5764 - val_loss: 2.2740 - val_accuracy: 0.6724
104/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 2.5312 - accuracy: 0.5858 - val_loss: 2.2564 - val_accuracy: 0.6756
105/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 2.4960 - accuracy: 0.5950 - val_loss: 2.2676 - val_accuracy: 0.6744
106/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 2.4551 - accuracy: 0.5960 - val_loss: 2.1711 - val_accuracy: 0.6890
107/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 2.3381 - accuracy: 0.6194 - val_loss: 2.0741 - val_accuracy: 0.7090
108/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 2.2763 - accuracy: 0.6346 - val_loss: 2.1419 - val_accuracy: 0.6964
109/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 440us/step - loss: 2.3450 - accuracy: 0.6194 - val_loss: 2.0829 - val_accuracy: 0.7000
110/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 2.2259 - accuracy: 0.6380 - val_loss: 2.0078 - val_accuracy: 0.7270
111/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 2.2772 - accuracy: 0.6274 - val_loss: 1.9881 - val_accuracy: 0.7290
112/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 2.2091 - accuracy: 0.6466 - val_loss: 1.8944 - val_accuracy: 0.7350
113/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 2.1799 - accuracy: 0.6508 - val_loss: 1.9111 - val_accuracy: 0.7396
114/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 2.0682 - accuracy: 0.6802 - val_loss: 1.9213 - val_accuracy: 0.7370
115/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 2.1039 - accuracy: 0.6666 - val_loss: 1.8179 - val_accuracy: 0.7488
116/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 2.0099 - accuracy: 0.6774 - val_loss: 1.7306 - val_accuracy: 0.7720
117/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 1.9553 - accuracy: 0.6854 - val_loss: 1.7174 - val_accuracy: 0.7718
118/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 1.9803 - accuracy: 0.6864 - val_loss: 1.6854 - val_accuracy: 0.7760
119/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 1.9012 - accuracy: 0.7010 - val_loss: 1.6228 - val_accuracy: 0.7832
120/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 1.9061 - accuracy: 0.7030 - val_loss: 1.6189 - val_accuracy: 0.7816
121/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 1.8193 - accuracy: 0.7116 - val_loss: 1.5719 - val_accuracy: 0.8002
122/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 1.7737 - accuracy: 0.7230 - val_loss: 1.5188 - val_accuracy: 0.8026
123/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 1.7159 - accuracy: 0.7362 - val_loss: 1.5347 - val_accuracy: 0.7988
124/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 1.7845 - accuracy: 0.7272 - val_loss: 1.4899 - val_accuracy: 0.8060
125/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 1.7209 - accuracy: 0.7342 - val_loss: 1.4685 - val_accuracy: 0.8144
126/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 1.7186 - accuracy: 0.7410 - val_loss: 1.4069 - val_accuracy: 0.8264
127/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 1.6180 - accuracy: 0.7534 - val_loss: 1.3848 - val_accuracy: 0.8240
128/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 1.5637 - accuracy: 0.7560 - val_loss: 1.3427 - val_accuracy: 0.8278
129/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 1.6099 - accuracy: 0.7564 - val_loss: 1.3952 - val_accuracy: 0.8232
130/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 1.4789 - accuracy: 0.7722 - val_loss: 1.2805 - val_accuracy: 0.8450
131/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 1.4903 - accuracy: 0.7780 - val_loss: 1.2237 - val_accuracy: 0.8430
132/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 1.4364 - accuracy: 0.7896 - val_loss: 1.2716 - val_accuracy: 0.8412
133/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 1.4797 - accuracy: 0.7760 - val_loss: 1.2296 - val_accuracy: 0.8436
134/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 1.4586 - accuracy: 0.7848 - val_loss: 1.1806 - val_accuracy: 0.8558
135/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 1.3773 - accuracy: 0.7910 - val_loss: 1.1906 - val_accuracy: 0.8554
136/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 437us/step - loss: 1.4057 - accuracy: 0.7874 - val_loss: 1.1071 - val_accuracy: 0.8652
137/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 1.4004 - accuracy: 0.7888 - val_loss: 1.0973 - val_accuracy: 0.8658
138/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 1.3436 - accuracy: 0.8032 - val_loss: 1.1279 - val_accuracy: 0.8602
139/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 1.2916 - accuracy: 0.8094 - val_loss: 1.0652 - val_accuracy: 0.8720
140/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 1.2377 - accuracy: 0.8254 - val_loss: 1.0494 - val_accuracy: 0.8814
141/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 1.2492 - accuracy: 0.8178 - val_loss: 1.0344 - val_accuracy: 0.8752
142/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 1.2039 - accuracy: 0.8298 - val_loss: 0.9970 - val_accuracy: 0.8808
143/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 1.1663 - accuracy: 0.8268 - val_loss: 1.0143 - val_accuracy: 0.8830
144/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 441us/step - loss: 1.2157 - accuracy: 0.8238 - val_loss: 1.0040 - val_accuracy: 0.8758
145/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 1.2299 - accuracy: 0.8244 - val_loss: 0.9235 - val_accuracy: 0.8904
146/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 1.1748 - accuracy: 0.8342 - val_loss: 0.9396 - val_accuracy: 0.8894
147/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 448us/step - loss: 1.0886 - accuracy: 0.8414 - val_loss: 0.8701 - val_accuracy: 0.8950
148/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 1.0928 - accuracy: 0.8404 - val_loss: 0.9259 - val_accuracy: 0.8854
149/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 1.0608 - accuracy: 0.8448 - val_loss: 0.8826 - val_accuracy: 0.8954
150/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 1.0561 - accuracy: 0.8516 - val_loss: 0.8936 - val_accuracy: 0.8874
151/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 1.0480 - accuracy: 0.8554 - val_loss: 0.8526 - val_accuracy: 0.8950
152/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 1.0491 - accuracy: 0.8458 - val_loss: 0.7957 - val_accuracy: 0.9112
153/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 1.0301 - accuracy: 0.8538 - val_loss: 0.8725 - val_accuracy: 0.8968
154/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 440us/step - loss: 1.0454 - accuracy: 0.8550 - val_loss: 0.8547 - val_accuracy: 0.8930
155/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 441us/step - loss: 0.9988 - accuracy: 0.8654 - val_loss: 0.7637 - val_accuracy: 0.9030
156/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.9550 - accuracy: 0.8692 - val_loss: 0.7502 - val_accuracy: 0.9074
157/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 0.9169 - accuracy: 0.8724 - val_loss: 0.7271 - val_accuracy: 0.9120
158/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 0.9087 - accuracy: 0.8738 - val_loss: 0.7595 - val_accuracy: 0.9104
159/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 0.9416 - accuracy: 0.8682 - val_loss: 0.7469 - val_accuracy: 0.9032
160/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 445us/step - loss: 0.9077 - accuracy: 0.8776 - val_loss: 0.7151 - val_accuracy: 0.9140
161/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 444us/step - loss: 0.8772 - accuracy: 0.8792 - val_loss: 0.6802 - val_accuracy: 0.9188
162/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 0.8246 - accuracy: 0.8860 - val_loss: 0.7598 - val_accuracy: 0.9056
163/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.8290 - accuracy: 0.8848 - val_loss: 0.6788 - val_accuracy: 0.9124
164/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.8190 - accuracy: 0.8948 - val_loss: 0.6626 - val_accuracy: 0.9224
165/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.8537 - accuracy: 0.8850 - val_loss: 0.6985 - val_accuracy: 0.9178
166/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.8617 - accuracy: 0.8826 - val_loss: 0.6534 - val_accuracy: 0.9260
167/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 456us/step - loss: 0.8402 - accuracy: 0.8830 - val_loss: 0.6782 - val_accuracy: 0.9216
168/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.8613 - accuracy: 0.8880 - val_loss: 0.6502 - val_accuracy: 0.9160
169/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.8064 - accuracy: 0.8968 - val_loss: 0.5609 - val_accuracy: 0.9298
170/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.7368 - accuracy: 0.9010 - val_loss: 0.5972 - val_accuracy: 0.9322
171/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 0.7479 - accuracy: 0.9032 - val_loss: 0.5802 - val_accuracy: 0.9308
172/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 443us/step - loss: 0.8182 - accuracy: 0.8928 - val_loss: 0.5866 - val_accuracy: 0.9332
173/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.7184 - accuracy: 0.9026 - val_loss: 0.5517 - val_accuracy: 0.9378
174/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 459us/step - loss: 0.7306 - accuracy: 0.9036 - val_loss: 0.5483 - val_accuracy: 0.9356
175/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 442us/step - loss: 0.7046 - accuracy: 0.9062 - val_loss: 0.5498 - val_accuracy: 0.9414
176/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 443us/step - loss: 0.7262 - accuracy: 0.9030 - val_loss: 0.5926 - val_accuracy: 0.9330
177/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.7250 - accuracy: 0.9084 - val_loss: 0.5790 - val_accuracy: 0.9308
178/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 0.6931 - accuracy: 0.9096 - val_loss: 0.5325 - val_accuracy: 0.9364
179/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.6769 - accuracy: 0.9102 - val_loss: 0.5641 - val_accuracy: 0.9340
180/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 0.7301 - accuracy: 0.9068 - val_loss: 0.5289 - val_accuracy: 0.9346
181/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 0.6643 - accuracy: 0.9062 - val_loss: 0.5486 - val_accuracy: 0.9290
182/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.6765 - accuracy: 0.9128 - val_loss: 0.4866 - val_accuracy: 0.9468
183/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 0.6674 - accuracy: 0.9128 - val_loss: 0.5452 - val_accuracy: 0.9282
184/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.6765 - accuracy: 0.9082 - val_loss: 0.4777 - val_accuracy: 0.9432
185/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 470us/step - loss: 0.6596 - accuracy: 0.9110 - val_loss: 0.5112 - val_accuracy: 0.9388
186/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.6278 - accuracy: 0.9178 - val_loss: 0.5298 - val_accuracy: 0.9334
187/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 0.6409 - accuracy: 0.9148 - val_loss: 0.5300 - val_accuracy: 0.9368
188/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.6472 - accuracy: 0.9152 - val_loss: 0.5234 - val_accuracy: 0.9352
189/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 0.5900 - accuracy: 0.9182 - val_loss: 0.4622 - val_accuracy: 0.9450
190/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 0.6294 - accuracy: 0.9186 - val_loss: 0.4752 - val_accuracy: 0.9462
191/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.6072 - accuracy: 0.9234 - val_loss: 0.4726 - val_accuracy: 0.9416
192/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.5583 - accuracy: 0.9234 - val_loss: 0.5011 - val_accuracy: 0.9344
193/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 0.5652 - accuracy: 0.9256 - val_loss: 0.4863 - val_accuracy: 0.9378
194/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.6142 - accuracy: 0.9222 - val_loss: 0.4753 - val_accuracy: 0.9398
195/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 0.6183 - accuracy: 0.9184 - val_loss: 0.5014 - val_accuracy: 0.9436
196/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.6179 - accuracy: 0.9196 - val_loss: 0.4096 - val_accuracy: 0.9462
197/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.5809 - accuracy: 0.9218 - val_loss: 0.4883 - val_accuracy: 0.9374
198/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 440us/step - loss: 0.6211 - accuracy: 0.9180 - val_loss: 0.4274 - val_accuracy: 0.9484
199/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.5918 - accuracy: 0.9254 - val_loss: 0.4602 - val_accuracy: 0.9404
200/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 0.5680 - accuracy: 0.9232 - val_loss: 0.4753 - val_accuracy: 0.9352
201/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 456us/step - loss: 0.5728 - accuracy: 0.9244 - val_loss: 0.4247 - val_accuracy: 0.9452
202/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 465us/step - loss: 0.5289 - accuracy: 0.9298 - val_loss: 0.4163 - val_accuracy: 0.9496
203/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 0.5668 - accuracy: 0.9246 - val_loss: 0.4187 - val_accuracy: 0.9514
204/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.5576 - accuracy: 0.9308 - val_loss: 0.4405 - val_accuracy: 0.9424
205/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.5579 - accuracy: 0.9300 - val_loss: 0.3840 - val_accuracy: 0.9500
206/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 441us/step - loss: 0.5781 - accuracy: 0.9268 - val_loss: 0.4180 - val_accuracy: 0.9488
207/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 459us/step - loss: 0.5559 - accuracy: 0.9320 - val_loss: 0.3964 - val_accuracy: 0.9492
208/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 448us/step - loss: 0.5753 - accuracy: 0.9246 - val_loss: 0.3951 - val_accuracy: 0.9516
209/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 444us/step - loss: 0.5030 - accuracy: 0.9332 - val_loss: 0.4359 - val_accuracy: 0.9492
210/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.4835 - accuracy: 0.9366 - val_loss: 0.3724 - val_accuracy: 0.9574
211/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 443us/step - loss: 0.4935 - accuracy: 0.9324 - val_loss: 0.4208 - val_accuracy: 0.9502
212/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 444us/step - loss: 0.4903 - accuracy: 0.9386 - val_loss: 0.4110 - val_accuracy: 0.9426
213/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 456us/step - loss: 0.4956 - accuracy: 0.9340 - val_loss: 0.3854 - val_accuracy: 0.9570
214/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 445us/step - loss: 0.4830 - accuracy: 0.9368 - val_loss: 0.4257 - val_accuracy: 0.9498
215/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.4810 - accuracy: 0.9370 - val_loss: 0.4113 - val_accuracy: 0.9450
216/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 448us/step - loss: 0.4949 - accuracy: 0.9374 - val_loss: 0.3799 - val_accuracy: 0.9476
217/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 450us/step - loss: 0.4604 - accuracy: 0.9410 - val_loss: 0.4125 - val_accuracy: 0.9454
218/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 462us/step - loss: 0.5221 - accuracy: 0.9300 - val_loss: 0.3965 - val_accuracy: 0.9512
219/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.4692 - accuracy: 0.9358 - val_loss: 0.3642 - val_accuracy: 0.9578
220/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 444us/step - loss: 0.5160 - accuracy: 0.9284 - val_loss: 0.3668 - val_accuracy: 0.9548
221/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.4608 - accuracy: 0.9326 - val_loss: 0.4120 - val_accuracy: 0.9496
222/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.5029 - accuracy: 0.9352 - val_loss: 0.3897 - val_accuracy: 0.9534
223/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 443us/step - loss: 0.4854 - accuracy: 0.9362 - val_loss: 0.3757 - val_accuracy: 0.9524
224/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.4988 - accuracy: 0.9334 - val_loss: 0.3910 - val_accuracy: 0.9512
225/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.4988 - accuracy: 0.9350 - val_loss: 0.4520 - val_accuracy: 0.9458
226/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 0.4992 - accuracy: 0.9324 - val_loss: 0.3596 - val_accuracy: 0.9554
227/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 437us/step - loss: 0.4953 - accuracy: 0.9324 - val_loss: 0.3554 - val_accuracy: 0.9540
228/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 443us/step - loss: 0.4566 - accuracy: 0.9428 - val_loss: 0.3816 - val_accuracy: 0.9556
229/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 444us/step - loss: 0.4710 - accuracy: 0.9394 - val_loss: 0.3805 - val_accuracy: 0.9518
230/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 442us/step - loss: 0.4904 - accuracy: 0.9354 - val_loss: 0.3081 - val_accuracy: 0.9568
231/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.4317 - accuracy: 0.9428 - val_loss: 0.3203 - val_accuracy: 0.9570
232/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 0.4103 - accuracy: 0.9452 - val_loss: 0.3224 - val_accuracy: 0.9570
233/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.4610 - accuracy: 0.9388 - val_loss: 0.3430 - val_accuracy: 0.9554
234/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 442us/step - loss: 0.4498 - accuracy: 0.9372 - val_loss: 0.3477 - val_accuracy: 0.9588
235/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 449us/step - loss: 0.4996 - accuracy: 0.9396 - val_loss: 0.3296 - val_accuracy: 0.9568
236/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.4480 - accuracy: 0.9380 - val_loss: 0.3525 - val_accuracy: 0.9534
237/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.4753 - accuracy: 0.9378 - val_loss: 0.3394 - val_accuracy: 0.9570
238/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 440us/step - loss: 0.4782 - accuracy: 0.9414 - val_loss: 0.3579 - val_accuracy: 0.9542
239/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 441us/step - loss: 0.4448 - accuracy: 0.9406 - val_loss: 0.4000 - val_accuracy: 0.9504
240/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 461us/step - loss: 0.4575 - accuracy: 0.9412 - val_loss: 0.3267 - val_accuracy: 0.9562
241/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 459us/step - loss: 0.4263 - accuracy: 0.9444 - val_loss: 0.3931 - val_accuracy: 0.9480
242/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 455us/step - loss: 0.4547 - accuracy: 0.9390 - val_loss: 0.3582 - val_accuracy: 0.9544
243/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.4481 - accuracy: 0.9428 - val_loss: 0.3552 - val_accuracy: 0.9552
244/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 466us/step - loss: 0.4322 - accuracy: 0.9474 - val_loss: 0.2764 - val_accuracy: 0.9656
245/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.4116 - accuracy: 0.9472 - val_loss: 0.3249 - val_accuracy: 0.9622
246/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 451us/step - loss: 0.4194 - accuracy: 0.9416 - val_loss: 0.3009 - val_accuracy: 0.9614
247/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 448us/step - loss: 0.4307 - accuracy: 0.9424 - val_loss: 0.3297 - val_accuracy: 0.9580
248/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 442us/step - loss: 0.4623 - accuracy: 0.9402 - val_loss: 0.3496 - val_accuracy: 0.9570
249/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.4467 - accuracy: 0.9400 - val_loss: 0.2773 - val_accuracy: 0.9638
250/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 463us/step - loss: 0.4325 - accuracy: 0.9452 - val_loss: 0.3598 - val_accuracy: 0.9510
251/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 456us/step - loss: 0.4522 - accuracy: 0.9414 - val_loss: 0.3184 - val_accuracy: 0.9606
252/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.4002 - accuracy: 0.9504 - val_loss: 0.3365 - val_accuracy: 0.9610
253/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 456us/step - loss: 0.4316 - accuracy: 0.9436 - val_loss: 0.3643 - val_accuracy: 0.9552
254/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 469us/step - loss: 0.4454 - accuracy: 0.9424 - val_loss: 0.2696 - val_accuracy: 0.9628
255/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 462us/step - loss: 0.4777 - accuracy: 0.9362 - val_loss: 0.3293 - val_accuracy: 0.9586
256/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 464us/step - loss: 0.4342 - accuracy: 0.9414 - val_loss: 0.3572 - val_accuracy: 0.9536
257/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.4225 - accuracy: 0.9440 - val_loss: 0.3203 - val_accuracy: 0.9586
258/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 458us/step - loss: 0.4638 - accuracy: 0.9428 - val_loss: 0.3037 - val_accuracy: 0.9632
259/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 456us/step - loss: 0.3731 - accuracy: 0.9490 - val_loss: 0.2899 - val_accuracy: 0.9638
260/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.4253 - accuracy: 0.9478 - val_loss: 0.3209 - val_accuracy: 0.9568
261/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.4223 - accuracy: 0.9434 - val_loss: 0.2988 - val_accuracy: 0.9626
262/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 466us/step - loss: 0.4720 - accuracy: 0.9402 - val_loss: 0.2963 - val_accuracy: 0.9632
263/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.4061 - accuracy: 0.9486 - val_loss: 0.3959 - val_accuracy: 0.9542
264/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.4545 - accuracy: 0.9384 - val_loss: 0.3724 - val_accuracy: 0.9594
265/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 478us/step - loss: 0.4541 - accuracy: 0.9444 - val_loss: 0.3321 - val_accuracy: 0.9626
266/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 453us/step - loss: 0.4369 - accuracy: 0.9454 - val_loss: 0.2972 - val_accuracy: 0.9644
267/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 457us/step - loss: 0.4180 - accuracy: 0.9456 - val_loss: 0.3310 - val_accuracy: 0.9560
268/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.4225 - accuracy: 0.9424 - val_loss: 0.3210 - val_accuracy: 0.9554
269/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 470us/step - loss: 0.4291 - accuracy: 0.9440 - val_loss: 0.3372 - val_accuracy: 0.9584
270/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 449us/step - loss: 0.3794 - accuracy: 0.9482 - val_loss: 0.3099 - val_accuracy: 0.9616
271/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 458us/step - loss: 0.4138 - accuracy: 0.9444 - val_loss: 0.3953 - val_accuracy: 0.9512
272/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 458us/step - loss: 0.4168 - accuracy: 0.9492 - val_loss: 0.2577 - val_accuracy: 0.9670
273/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.3676 - accuracy: 0.9482 - val_loss: 0.3069 - val_accuracy: 0.9628
274/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 459us/step - loss: 0.3627 - accuracy: 0.9520 - val_loss: 0.2839 - val_accuracy: 0.9676
275/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 442us/step - loss: 0.3493 - accuracy: 0.9548 - val_loss: 0.2668 - val_accuracy: 0.9690
276/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.3886 - accuracy: 0.9502 - val_loss: 0.3112 - val_accuracy: 0.9618
277/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.3366 - accuracy: 0.9550 - val_loss: 0.3035 - val_accuracy: 0.9608
278/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 454us/step - loss: 0.3165 - accuracy: 0.9570 - val_loss: 0.3030 - val_accuracy: 0.9652
279/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 458us/step - loss: 0.3650 - accuracy: 0.9536 - val_loss: 0.2773 - val_accuracy: 0.9654
280/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 469us/step - loss: 0.4533 - accuracy: 0.9396 - val_loss: 0.3659 - val_accuracy: 0.9540
281/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.4167 - accuracy: 0.9464 - val_loss: 0.2774 - val_accuracy: 0.9656
282/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 475us/step - loss: 0.4146 - accuracy: 0.9442 - val_loss: 0.3338 - val_accuracy: 0.9590
283/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.4036 - accuracy: 0.9482 - val_loss: 0.3035 - val_accuracy: 0.9618
284/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 453us/step - loss: 0.3774 - accuracy: 0.9504 - val_loss: 0.2949 - val_accuracy: 0.9632
285/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 471us/step - loss: 0.4482 - accuracy: 0.9414 - val_loss: 0.2921 - val_accuracy: 0.9640
286/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 461us/step - loss: 0.4196 - accuracy: 0.9488 - val_loss: 0.2654 - val_accuracy: 0.9678
287/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.3691 - accuracy: 0.9488 - val_loss: 0.3287 - val_accuracy: 0.9576
288/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 458us/step - loss: 0.4384 - accuracy: 0.9408 - val_loss: 0.3256 - val_accuracy: 0.9606
289/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 460us/step - loss: 0.3908 - accuracy: 0.9498 - val_loss: 0.2536 - val_accuracy: 0.9674
290/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 470us/step - loss: 0.4584 - accuracy: 0.9418 - val_loss: 0.3737 - val_accuracy: 0.9492
291/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 464us/step - loss: 0.4190 - accuracy: 0.9464 - val_loss: 0.3219 - val_accuracy: 0.9570
292/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 452us/step - loss: 0.4030 - accuracy: 0.9500 - val_loss: 0.2486 - val_accuracy: 0.9692
293/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 490us/step - loss: 0.3864 - accuracy: 0.9504 - val_loss: 0.3103 - val_accuracy: 0.9584
294/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 462us/step - loss: 0.3768 - accuracy: 0.9492 - val_loss: 0.2986 - val_accuracy: 0.9616
295/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 472us/step - loss: 0.3717 - accuracy: 0.9524 - val_loss: 0.3117 - val_accuracy: 0.9634
296/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 450us/step - loss: 0.3955 - accuracy: 0.9514 - val_loss: 0.2855 - val_accuracy: 0.9650
297/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 448us/step - loss: 0.3460 - accuracy: 0.9548 - val_loss: 0.2809 - val_accuracy: 0.9676
298/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 484us/step - loss: 0.3954 - accuracy: 0.9502 - val_loss: 0.2761 - val_accuracy: 0.9664
299/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 470us/step - loss: 0.3553 - accuracy: 0.9532 - val_loss: 0.2863 - val_accuracy: 0.9650
300/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 468us/step - loss: 0.3761 - accuracy: 0.9502 - val_loss: 0.2565 - val_accuracy: 0.9666
100000/100000 [==============================] - 11s 108us/step
Train set: Loss=0.2982 ; Accuracy=96.4%
100000/100000 [==============================] - 14s 139us/step
Test set: Loss=14.9148 ; Accuracy=2.0%
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-embeddings">Load embeddings<a class="anchor-link" href="#Load-embeddings"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">Embeddings</span><span class="p">(</span><span class="n">read_embeddings</span><span class="p">(</span><span class="s1">&#39;embeddings.csv&#39;</span><span class="p">))</span>

<span class="n">state_space_size</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">*</span> <span class="n">history_length</span>
<span class="n">action_space_size</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">*</span> <span class="n">ra_length</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Start-Agent-training">Start Agent training<a class="anchor-link" href="#Start-Agent-training"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">environment</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">fixed_length</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span> <span class="c1"># For multiple consecutive executions</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="c1"># &#39;1: Initialize actor network f_Î¸^Ï€ and critic network Q(s, a|Î¸^Âµ) with random weights&#39;</span>
<span class="n">actor</span> <span class="o">=</span> <span class="n">Actor</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">tau</span><span class="p">,</span> <span class="n">actor_lr</span><span class="p">)</span>
<span class="n">critic</span> <span class="o">=</span> <span class="n">Critic</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">tau</span><span class="p">,</span> <span class="n">critic_lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">environment</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">discount_factor</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="p">,</span> <span class="n">filename_summary</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From &lt;ipython-input-19-1a5cd2de5f02&gt;:69: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From &lt;ipython-input-19-1a5cd2de5f02&gt;:70: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
WARNING:tensorflow:From &lt;ipython-input-19-1a5cd2de5f02&gt;:40: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Episode 1/100 Reward=552 Time=4s No replay
Episode 2/100 Reward=551 Time=52s Loss=2082.7095
Episode 3/100 Reward=551 Time=68s Loss=123.3409
Episode 4/100 Reward=551 Time=67s Loss=67.4848
Episode 5/100 Reward=551 Time=67s Loss=44.0779
Episode 6/100 Reward=552 Time=67s Loss=40.3507
Episode 7/100 Reward=552 Time=67s Loss=29.4237
Episode 8/100 Reward=552 Time=68s Loss=26.5713
Episode 9/100 Reward=552 Time=68s Loss=27.1646
Episode 10/100 Reward=552 Time=68s Loss=25.9928
Episode 11/100 Reward=552 Time=67s Loss=22.3598
Episode 12/100 Reward=552 Time=68s Loss=18.7026
Episode 13/100 Reward=552 Time=67s Loss=17.8249
Episode 14/100 Reward=551 Time=67s Loss=19.8687
Episode 15/100 Reward=552 Time=68s Loss=20.9238
Episode 16/100 Reward=551 Time=67s Loss=19.9583
Episode 17/100 Reward=551 Time=68s Loss=20.2933
Episode 18/100 Reward=551 Time=67s Loss=19.9462
Episode 19/100 Reward=551 Time=67s Loss=24.3696
Episode 20/100 Reward=551 Time=67s Loss=25.6828
Episode 21/100 Reward=551 Time=67s Loss=28.5111
Episode 22/100 Reward=551 Time=67s Loss=29.4505
Episode 23/100 Reward=551 Time=67s Loss=27.2863
Episode 24/100 Reward=551 Time=68s Loss=28.4667
Episode 25/100 Reward=551 Time=67s Loss=26.7666
Episode 26/100 Reward=551 Time=67s Loss=26.2378
Episode 27/100 Reward=551 Time=67s Loss=25.0391
Episode 28/100 Reward=551 Time=67s Loss=25.0170
Episode 29/100 Reward=551 Time=68s Loss=22.9655
Episode 30/100 Reward=551 Time=68s Loss=23.8730
Episode 31/100 Reward=551 Time=67s Loss=20.4020
Episode 32/100 Reward=551 Time=67s Loss=22.4662
Episode 33/100 Reward=551 Time=67s Loss=23.8943
Episode 34/100 Reward=551 Time=67s Loss=21.1020
Episode 35/100 Reward=551 Time=67s Loss=22.8528
Episode 36/100 Reward=551 Time=67s Loss=21.2307
Episode 37/100 Reward=551 Time=67s Loss=19.7094
Episode 38/100 Reward=551 Time=67s Loss=21.4233
Episode 39/100 Reward=551 Time=67s Loss=23.6903
Episode 40/100 Reward=551 Time=67s Loss=24.4852
Episode 41/100 Reward=551 Time=67s Loss=25.7120
Episode 42/100 Reward=551 Time=67s Loss=21.7722
Episode 43/100 Reward=551 Time=67s Loss=20.9898
Episode 44/100 Reward=551 Time=67s Loss=20.6604
Episode 45/100 Reward=551 Time=68s Loss=20.8646
Episode 46/100 Reward=551 Time=67s Loss=19.4622
Episode 47/100 Reward=551 Time=67s Loss=20.4751
Episode 48/100 Reward=551 Time=67s Loss=18.9989
Episode 49/100 Reward=551 Time=67s Loss=17.7407
Episode 50/100 Reward=551 Time=67s Loss=17.3576
Episode 51/100 Reward=551 Time=68s Loss=17.2397
Episode 52/100 Reward=552 Time=67s Loss=16.5722
Episode 53/100 Reward=552 Time=67s Loss=15.5511
Episode 54/100 Reward=552 Time=67s Loss=15.7651
Episode 55/100 Reward=552 Time=67s Loss=14.0308
Episode 56/100 Reward=552 Time=67s Loss=14.4518
Episode 57/100 Reward=551 Time=67s Loss=15.9018
Episode 58/100 Reward=552 Time=67s Loss=14.2520
Episode 59/100 Reward=551 Time=67s Loss=14.2282
Episode 60/100 Reward=551 Time=67s Loss=14.1576
Episode 61/100 Reward=551 Time=67s Loss=13.1366
Episode 62/100 Reward=551 Time=67s Loss=13.7383
Episode 63/100 Reward=551 Time=67s Loss=12.3095
Episode 64/100 Reward=551 Time=68s Loss=11.7993
Episode 65/100 Reward=551 Time=67s Loss=12.1072
Episode 66/100 Reward=551 Time=67s Loss=12.8614
Episode 67/100 Reward=552 Time=67s Loss=11.4739
Episode 68/100 Reward=552 Time=67s Loss=12.6560
Episode 69/100 Reward=552 Time=67s Loss=12.8773
Episode 70/100 Reward=552 Time=67s Loss=11.7954
Episode 71/100 Reward=552 Time=67s Loss=11.2212
Episode 72/100 Reward=552 Time=67s Loss=12.3400
Episode 73/100 Reward=552 Time=67s Loss=12.5248
Episode 74/100 Reward=552 Time=67s Loss=11.2045
Episode 75/100 Reward=552 Time=67s Loss=11.1089
Episode 76/100 Reward=552 Time=67s Loss=11.6253
Episode 77/100 Reward=552 Time=67s Loss=10.9183
Episode 78/100 Reward=552 Time=67s Loss=9.2532
Episode 79/100 Reward=552 Time=67s Loss=10.4258
Episode 80/100 Reward=552 Time=67s Loss=10.0044
Episode 81/100 Reward=552 Time=67s Loss=10.4150
Episode 82/100 Reward=552 Time=67s Loss=10.9766
Episode 83/100 Reward=551 Time=67s Loss=8.8571
Episode 84/100 Reward=551 Time=67s Loss=10.5467
Episode 85/100 Reward=551 Time=67s Loss=8.8356
Episode 86/100 Reward=551 Time=67s Loss=11.0192
Episode 87/100 Reward=551 Time=67s Loss=9.3348
Episode 88/100 Reward=551 Time=67s Loss=11.0042
Episode 89/100 Reward=551 Time=67s Loss=8.5757
Episode 90/100 Reward=551 Time=67s Loss=8.8545
Episode 91/100 Reward=551 Time=67s Loss=10.0286
Episode 92/100 Reward=551 Time=67s Loss=10.2471
Episode 93/100 Reward=551 Time=67s Loss=9.3180
Episode 94/100 Reward=551 Time=68s Loss=8.2303
Episode 95/100 Reward=551 Time=68s Loss=9.1910
Episode 96/100 Reward=551 Time=67s Loss=8.2708
Episode 97/100 Reward=551 Time=67s Loss=8.1502
Episode 98/100 Reward=551 Time=67s Loss=8.1103
Episode 99/100 Reward=551 Time=67s Loss=8.2638
Episode 100/100 Reward=551 Time=67s Loss=8.2967
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Testing">Testing<a class="anchor-link" href="#Testing"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">dict_embeddings</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding_vector</span><span class="p">()):</span>
  <span class="n">str_item</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
  <span class="k">assert</span><span class="p">(</span><span class="n">str_item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dict_embeddings</span><span class="p">)</span>
  <span class="n">dict_embeddings</span><span class="p">[</span><span class="n">str_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">state_to_items</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">dict_embeddings</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)]</span>
          <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actor</span><span class="o">.</span><span class="n">get_recommendation_list</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">test_actor</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">test_df</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nb_rounds</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">ratings</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">unknown</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">random_seen</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_rounds</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">)):</span>
      <span class="n">history_sample</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">history_length</span><span class="p">)[</span><span class="s1">&#39;itemId&#39;</span><span class="p">])</span>
      <span class="n">recommendation</span> <span class="o">=</span> <span class="n">state_to_items</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">history_sample</span><span class="p">),</span> <span class="n">actor</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">recommendation</span><span class="p">:</span>
        <span class="n">l</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">item</span><span class="p">][</span><span class="s1">&#39;rating&#39;</span><span class="p">])</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">unknown</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">ratings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">history_sample</span><span class="p">:</span>
        <span class="n">random_seen</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;itemId&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">item</span><span class="p">][</span><span class="s1">&#39;rating&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">ratings</span><span class="p">,</span> <span class="n">unknown</span><span class="p">,</span> <span class="n">random_seen</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-1---Trainset-and-target=False">Test 1 - Trainset and target=False<a class="anchor-link" href="#Test-1---Trainset-and-target=False"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ratings</span><span class="p">,</span> <span class="n">unknown</span><span class="p">,</span> <span class="n">random_seen</span> <span class="o">=</span> <span class="n">test_actor</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nb_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%0.1f%%</span><span class="s1"> unknown&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">unknown</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span> <span class="o">+</span> <span class="n">unknown</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>91.5% unknown
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Predictions ; Mean = </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratings</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random ; Mean = </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-2---Trainset-and-target=True">Test 2 - Trainset and target=True<a class="anchor-link" href="#Test-2---Trainset-and-target=True"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ratings</span><span class="p">,</span> <span class="n">unknown</span><span class="p">,</span> <span class="n">random_seen</span> <span class="o">=</span> <span class="n">test_actor</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nb_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%0.1f%%</span><span class="s1"> unknown&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">unknown</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span> <span class="o">+</span> <span class="n">unknown</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>91.5% unknown
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Predictions ; Mean = </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratings</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random ; Mean = </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">watermark</span>
<span class="o">%</span><span class="n">reload_ext</span> <span class="n">watermark</span>
<span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">a</span> <span class="s2">&quot;Sparsh A.&quot;</span> <span class="o">-</span><span class="n">m</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">t</span> <span class="o">-</span><span class="n">d</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Author: Sparsh A.

Last updated: 2021-12-14 10:58:33

Compiler    : GCC 7.5.0
OS          : Linux
Release     : 5.4.104+
Machine     : x86_64
Processor   : x86_64
CPU cores   : 2
Architecture: 64bit

pandas    : 1.1.5
IPython   : 5.5.0
numpy     : 1.19.5
keras     : 2.3.1
tensorflow: 1.15.2
matplotlib: 3.2.2
csv       : 1.0

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>END</strong></p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/2022/01/13/listwise-ml.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Jupyter notebook database.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/recohut" target="_blank" title="recohut"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>

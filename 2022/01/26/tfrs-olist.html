<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Multi-Task Recommender on Olist dataset using TFRS Library | reconb</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Multi-Task Recommender on Olist dataset using TFRS Library" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="TFRS Retrieval, ranking, time and text feature embeddings, and multi-task modeling on Olist retail dataset." />
<meta property="og:description" content="TFRS Retrieval, ranking, time and text feature embeddings, and multi-task modeling on Olist retail dataset." />
<link rel="canonical" href="https://nb.recohut.com/2022/01/26/tfrs-olist.html" />
<meta property="og:url" content="https://nb.recohut.com/2022/01/26/tfrs-olist.html" />
<meta property="og:site_name" content="reconb" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-26T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Multi-Task Recommender on Olist dataset using TFRS Library" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-01-26T00:00:00-06:00","datePublished":"2022-01-26T00:00:00-06:00","description":"TFRS Retrieval, ranking, time and text feature embeddings, and multi-task modeling on Olist retail dataset.","headline":"Multi-Task Recommender on Olist dataset using TFRS Library","mainEntityOfPage":{"@type":"WebPage","@id":"https://nb.recohut.com/2022/01/26/tfrs-olist.html"},"url":"https://nb.recohut.com/2022/01/26/tfrs-olist.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nb.recohut.com/feed.xml" title="reconb" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">reconb</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Multi-Task Recommender on Olist dataset using TFRS Library</h1><p class="page-description">TFRS Retrieval, ranking, time and text feature embeddings, and multi-task modeling on Olist retail dataset.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-26T00:00:00-06:00" itemprop="datePublished">
        Jan 26, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      36 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/recohut/notebook/tree/master/_notebooks/2022-01-26-tfrs-olist.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/recohut/notebook/master?filepath=_notebooks%2F2022-01-26-tfrs-olist.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/recohut/notebook/blob/master/_notebooks/2022-01-26-tfrs-olist.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frecohut%2Fnotebook%2Fblob%2Fmaster%2F_notebooks%2F2022-01-26-tfrs-olist.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-26-tfrs-olist.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Overview">Overview<a class="anchor-link" href="#Overview"> </a></h3><ul>
<li>Objective: To demonstrate TensorFlow 2.0 TFRS recommenders library to build a recommendation system on a customer retail data.</li>
<li>Data source: <a href="https://www.kaggle.com/olistbr/brazilian-ecommerce/home/">https://www.kaggle.com/olistbr/brazilian-ecommerce/home/</a></li>
<li>Benefit: Flexible model, ability to add different features and specify and adjust model complexity easily.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Theory">Theory<a class="anchor-link" href="#Theory"> </a></h3><p>Two types of recommendation model-- Retrieval and Ranking.</p>
<ul>
<li>Retrieval: The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient. Retrieval can be computationally more efficient because it only returns smaller set of items a user would strongly interested.</li>
<li>Ranking: The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Built with TensorFlow 2.x, TFRS makes it possible to:</p>
<ul>
<li>Build and evaluate flexible <strong><a href="https://research.google/pubs/pub48840/">candidate nomination models</a></strong>;</li>
<li>Freely incorporate item, user, and context <strong><a href="https://tensorflow.org/recommenders/examples/featurization">information</a></strong> into recommendation models;</li>
<li>Train <strong><a href="https://tensorflow.org/recommenders/examples/multitask">multi-task models</a></strong> that jointly optimize multiple recommendation objectives;</li>
<li>Efficiently serve the resulting models using <strong><a href="https://www.tensorflow.org/tfx/guide/serving">TensorFlow Serving</a></strong>.</li>
<li><a href="https://research.google/pubs/pub47842/">Multi-task learning</a>, <a href="https://arxiv.org/abs/1708.05123">feature cross modeling</a>, <a href="https://arxiv.org/abs/2007.12865">self-supervised learning</a>, and state-of-the-art efficient <a href="https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html">approximate nearest neighbours computation</a>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Outline">Outline<a class="anchor-link" href="#Outline"> </a></h3><ol>
<li>Retrieval model</li>
<li>Ranking model</li>
<li>Adding text and timestamp embedding</li>
<li>Multitask recommendation, combining retrieval and ranking</li>
<li>Add more features using Cross Network.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">recommenders</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>     |████████████████████████████████| 85 kB 2.5 MB/s 
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Text</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_recommenders</span> <span class="k">as</span> <span class="nn">tfrs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">watermark</span>
<span class="o">%</span><span class="n">reload_ext</span> <span class="n">watermark</span>
<span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">m</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">t</span> <span class="o">-</span><span class="n">d</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Last updated: 2021-10-27 05:45:19

Compiler    : GCC 7.5.0
OS          : Linux
Release     : 5.4.104+
Machine     : x86_64
Processor   : x86_64
CPU cores   : 2
Architecture: 64bit

seaborn                : 0.11.2
pandas                 : 1.1.5
numpy                  : 1.19.5
matplotlib             : 3.2.2
tensorflow_recommenders: 0.6.0
IPython                : 5.5.0
tensorflow             : 2.6.0

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Loading">Data Loading<a class="anchor-link" href="#Data-Loading"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># !pip install --upgrade --force-reinstall --no-deps kaggle</span>
<span class="c1"># !mkdir ~/.kaggle</span>
<span class="c1"># !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/</span>
<span class="c1"># !chmod 600 ~/.kaggle/kaggle.json</span>
<span class="c1"># !kaggle datasets download -d olistbr/brazilian-ecommerce</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="o">-</span><span class="n">q</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">sparsh</span><span class="o">-</span><span class="n">ai</span><span class="o">/</span><span class="n">multiobjective</span><span class="o">-</span><span class="n">optimizations</span><span class="o">.</span><span class="n">git</span>
<span class="err">!</span><span class="n">cp</span> <span class="n">multiobjective</span><span class="o">-</span><span class="n">optimizations</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">brazilian</span><span class="o">-</span><span class="n">ecommerce</span><span class="o">.</span><span class="n">zip</span> <span class="o">.</span>
<span class="err">!</span><span class="n">unzip</span> <span class="n">brazilian</span><span class="o">-</span><span class="n">ecommerce</span><span class="o">.</span><span class="n">zip</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Archive:  brazilian-ecommerce.zip
  inflating: olist_customers_dataset.csv  
  inflating: olist_geolocation_dataset.csv  
  inflating: olist_order_items_dataset.csv  
  inflating: olist_order_payments_dataset.csv  
  inflating: olist_order_reviews_dataset.csv  
  inflating: olist_orders_dataset.csv  
  inflating: olist_products_dataset.csv  
  inflating: olist_sellers_dataset.csv  
  inflating: product_category_name_translation.csv  
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">glob</span>
<span class="n">files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;/content/*.csv&#39;</span><span class="p">))</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">files</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dfs</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">dfs </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">files</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">display</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 0: olist_customers_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_id</th>
      <th>customer_unique_id</th>
      <th>customer_zip_code_prefix</th>
      <th>customer_city</th>
      <th>customer_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>
      <td>861eff4711a542e4b93843c6dd7febb0</td>
      <td>14409</td>
      <td>franca</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18955e83d337fd6b2def6b18a428ac77</td>
      <td>290c77bc529b7ac935b93aa66c333dc3</td>
      <td>9790</td>
      <td>sao bernardo do campo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4e7b3e00288586ebd08712fdd0374a03</td>
      <td>060e732b5b29e8181a18229c7b0b2b5e</td>
      <td>1151</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>
      <td>259dac757896d24d7702b9acbbff3f3c</td>
      <td>8775</td>
      <td>mogi das cruzes</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>
      <td>345ecd01c38d18a9036ed96c73b8d066</td>
      <td>13056</td>
      <td>campinas</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 1: olist_geolocation_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geolocation_zip_code_prefix</th>
      <th>geolocation_lat</th>
      <th>geolocation_lng</th>
      <th>geolocation_city</th>
      <th>geolocation_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1037</td>
      <td>-23.545621</td>
      <td>-46.639292</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1046</td>
      <td>-23.546081</td>
      <td>-46.644820</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1046</td>
      <td>-23.546129</td>
      <td>-46.642951</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1041</td>
      <td>-23.544392</td>
      <td>-46.639499</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1035</td>
      <td>-23.541578</td>
      <td>-46.641607</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 2: olist_order_items_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>order_item_id</th>
      <th>product_id</th>
      <th>seller_id</th>
      <th>shipping_limit_date</th>
      <th>price</th>
      <th>freight_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00010242fe8c5a6d1ba2dd792cb16214</td>
      <td>1</td>
      <td>4244733e06e7ecb4970a6e2683c13e61</td>
      <td>48436dade18ac8b2bce089ec2a041202</td>
      <td>2017-09-19 09:45:35</td>
      <td>58.90</td>
      <td>13.29</td>
    </tr>
    <tr>
      <th>1</th>
      <td>00018f77f2f0320c557190d7a144bdd3</td>
      <td>1</td>
      <td>e5f2d52b802189ee658865ca93d83a8f</td>
      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>
      <td>2017-05-03 11:05:13</td>
      <td>239.90</td>
      <td>19.93</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000229ec398224ef6ca0657da4fc703e</td>
      <td>1</td>
      <td>c777355d18b72b67abbeef9df44fd0fd</td>
      <td>5b51032eddd242adc84c38acab88f23d</td>
      <td>2018-01-18 14:48:30</td>
      <td>199.00</td>
      <td>17.87</td>
    </tr>
    <tr>
      <th>3</th>
      <td>00024acbcdf0a6daa1e931b038114c75</td>
      <td>1</td>
      <td>7634da152a4610f1595efa32f14722fc</td>
      <td>9d7a1d34a5052409006425275ba1c2b4</td>
      <td>2018-08-15 10:10:18</td>
      <td>12.99</td>
      <td>12.79</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>
      <td>1</td>
      <td>ac6c3623068f30de03045865e4e10089</td>
      <td>df560393f3a51e74553ab94004ba5c87</td>
      <td>2017-02-13 13:57:51</td>
      <td>199.90</td>
      <td>18.14</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 3: olist_order_payments_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>payment_sequential</th>
      <th>payment_type</th>
      <th>payment_installments</th>
      <th>payment_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b81ef226f3fe1789b1e8b2acac839d17</td>
      <td>1</td>
      <td>credit_card</td>
      <td>8</td>
      <td>99.33</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a9810da82917af2d9aefd1278f1dcfa0</td>
      <td>1</td>
      <td>credit_card</td>
      <td>1</td>
      <td>24.39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>
      <td>1</td>
      <td>credit_card</td>
      <td>1</td>
      <td>65.71</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ba78997921bbcdc1373bb41e913ab953</td>
      <td>1</td>
      <td>credit_card</td>
      <td>8</td>
      <td>107.78</td>
    </tr>
    <tr>
      <th>4</th>
      <td>42fdf880ba16b47b59251dd489d4441a</td>
      <td>1</td>
      <td>credit_card</td>
      <td>2</td>
      <td>128.45</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 4: olist_order_reviews_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_id</th>
      <th>order_id</th>
      <th>review_score</th>
      <th>review_comment_title</th>
      <th>review_comment_message</th>
      <th>review_creation_date</th>
      <th>review_answer_timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7bc2406110b926393aa56f80a40eba40</td>
      <td>73fc7af87114b39712e6da79b0a377eb</td>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-01-18 00:00:00</td>
      <td>2018-01-18 21:46:59</td>
    </tr>
    <tr>
      <th>1</th>
      <td>80e641a11e56f04c1ad469d5645fdfde</td>
      <td>a548910a1c6147796b98fdf73dbeba33</td>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-03-10 00:00:00</td>
      <td>2018-03-11 03:05:13</td>
    </tr>
    <tr>
      <th>2</th>
      <td>228ce5500dc1d8e020d8d1322874b6f0</td>
      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-02-17 00:00:00</td>
      <td>2018-02-18 14:36:24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>e64fb393e7b32834bb789ff8bb30750e</td>
      <td>658677c97b385a9be170737859d3511b</td>
      <td>5</td>
      <td>NaN</td>
      <td>Recebi bem antes do prazo estipulado.</td>
      <td>2017-04-21 00:00:00</td>
      <td>2017-04-21 22:02:06</td>
    </tr>
    <tr>
      <th>4</th>
      <td>f7c4243c7fe1938f181bec41a392bdeb</td>
      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>
      <td>5</td>
      <td>NaN</td>
      <td>Parabéns lojas lannister adorei comprar pela I...</td>
      <td>2018-03-01 00:00:00</td>
      <td>2018-03-02 10:26:53</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 5: olist_orders_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>customer_id</th>
      <th>order_status</th>
      <th>order_purchase_timestamp</th>
      <th>order_approved_at</th>
      <th>order_delivered_carrier_date</th>
      <th>order_delivered_customer_date</th>
      <th>order_estimated_delivery_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>e481f51cbdc54678b7cc49136f2d6af7</td>
      <td>9ef432eb6251297304e76186b10a928d</td>
      <td>delivered</td>
      <td>2017-10-02 10:56:33</td>
      <td>2017-10-02 11:07:15</td>
      <td>2017-10-04 19:55:00</td>
      <td>2017-10-10 21:25:13</td>
      <td>2017-10-18 00:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>53cdb2fc8bc7dce0b6741e2150273451</td>
      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>
      <td>delivered</td>
      <td>2018-07-24 20:41:37</td>
      <td>2018-07-26 03:24:27</td>
      <td>2018-07-26 14:31:00</td>
      <td>2018-08-07 15:27:45</td>
      <td>2018-08-13 00:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>47770eb9100c2d0c44946d9cf07ec65d</td>
      <td>41ce2a54c0b03bf3443c3d931a367089</td>
      <td>delivered</td>
      <td>2018-08-08 08:38:49</td>
      <td>2018-08-08 08:55:23</td>
      <td>2018-08-08 13:50:00</td>
      <td>2018-08-17 18:06:29</td>
      <td>2018-09-04 00:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>
      <td>f88197465ea7920adcdbec7375364d82</td>
      <td>delivered</td>
      <td>2017-11-18 19:28:06</td>
      <td>2017-11-18 19:45:59</td>
      <td>2017-11-22 13:39:59</td>
      <td>2017-12-02 00:28:42</td>
      <td>2017-12-15 00:00:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>
      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>
      <td>delivered</td>
      <td>2018-02-13 21:18:39</td>
      <td>2018-02-13 22:20:29</td>
      <td>2018-02-14 19:46:34</td>
      <td>2018-02-16 18:17:02</td>
      <td>2018-02-26 00:00:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 6: olist_products_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_id</th>
      <th>product_category_name</th>
      <th>product_name_lenght</th>
      <th>product_description_lenght</th>
      <th>product_photos_qty</th>
      <th>product_weight_g</th>
      <th>product_length_cm</th>
      <th>product_height_cm</th>
      <th>product_width_cm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>
      <td>perfumaria</td>
      <td>40.0</td>
      <td>287.0</td>
      <td>1.0</td>
      <td>225.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>
      <td>artes</td>
      <td>44.0</td>
      <td>276.0</td>
      <td>1.0</td>
      <td>1000.0</td>
      <td>30.0</td>
      <td>18.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>96bd76ec8810374ed1b65e291975717f</td>
      <td>esporte_lazer</td>
      <td>46.0</td>
      <td>250.0</td>
      <td>1.0</td>
      <td>154.0</td>
      <td>18.0</td>
      <td>9.0</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cef67bcfe19066a932b7673e239eb23d</td>
      <td>bebes</td>
      <td>27.0</td>
      <td>261.0</td>
      <td>1.0</td>
      <td>371.0</td>
      <td>26.0</td>
      <td>4.0</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9dc1a7de274444849c219cff195d0b71</td>
      <td>utilidades_domesticas</td>
      <td>37.0</td>
      <td>402.0</td>
      <td>4.0</td>
      <td>625.0</td>
      <td>20.0</td>
      <td>17.0</td>
      <td>13.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 7: olist_sellers_dataset

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seller_id</th>
      <th>seller_zip_code_prefix</th>
      <th>seller_city</th>
      <th>seller_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3442f8959a84dea7ee197c632cb2df15</td>
      <td>13023</td>
      <td>campinas</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>
      <td>13844</td>
      <td>mogi guacu</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>
      <td>20031</td>
      <td>rio de janeiro</td>
      <td>RJ</td>
    </tr>
    <tr>
      <th>3</th>
      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>
      <td>4195</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>
      <td>12914</td>
      <td>braganca paulista</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

dfs 8: product_category_name_translation

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_category_name</th>
      <th>product_category_name_english</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>beleza_saude</td>
      <td>health_beauty</td>
    </tr>
    <tr>
      <th>1</th>
      <td>informatica_acessorios</td>
      <td>computers_accessories</td>
    </tr>
    <tr>
      <th>2</th>
      <td>automotivo</td>
      <td>auto</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cama_mesa_banho</td>
      <td>bed_bath_table</td>
    </tr>
    <tr>
      <th>4</th>
      <td>moveis_decoracao</td>
      <td>furniture_decor</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Preparation">Data Preparation<a class="anchor-link" href="#Data-Preparation"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df11</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">dfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;order_id&#39;</span><span class="p">)[[</span><span class="s1">&#39;product_id&#39;</span><span class="p">,</span><span class="s1">&#39;customer_id&#39;</span><span class="p">,</span><span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]]</span>
<span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">dfs</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;product_category_name&#39;</span><span class="p">)[[</span><span class="s1">&#39;product_id&#39;</span><span class="p">,</span><span class="s1">&#39;product_category_name_english&#39;</span><span class="p">]]</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df11</span><span class="p">,</span> <span class="n">df12</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;product_id&#39;</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;sku&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;product_category_name_english&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">cumcount</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;str&#39;</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;product_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;product_category_name_english&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;sku&#39;</span><span class="p">]</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;implicit_interaction_weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[[</span><span class="s1">&#39;customer_id&#39;</span><span class="p">,</span> <span class="s1">&#39;product_id&#39;</span><span class="p">,</span> <span class="s1">&#39;implicit_interaction_weight&#39;</span><span class="p">,</span> <span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]]</span>
<span class="n">df1</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">,</span><span class="s1">&#39;RATING&#39;</span><span class="p">,</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">]</span>
<span class="n">df1</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>USERID</th>
      <th>ITEMID</th>
      <th>RATING</th>
      <th>TIMESTAMP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3ce436f183e68e07877b285a838db11a</td>
      <td>cool_stuff_0</td>
      <td>1</td>
      <td>1.505293e+09</td>
    </tr>
    <tr>
      <th>1</th>
      <td>f6dd3ec061db4e3987629fe6b26e5cce</td>
      <td>pet_shop_0</td>
      <td>1</td>
      <td>1.493204e+09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6489ae5e4333f3693df5ad4372dab6d3</td>
      <td>furniture_decor_0</td>
      <td>1</td>
      <td>1.515940e+09</td>
    </tr>
    <tr>
      <th>3</th>
      <td>d4eb9395c8c0431ee92fce09860c5a06</td>
      <td>perfumery_0</td>
      <td>1</td>
      <td>1.533722e+09</td>
    </tr>
    <tr>
      <th>4</th>
      <td>58dbd0b2d70206bf40e62cd34e84d795</td>
      <td>garden_tools_0</td>
      <td>1</td>
      <td>1.486217e+09</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>112645</th>
      <td>b51593916b4b8e0d6f66f2ae24f2673d</td>
      <td>housewares_6963</td>
      <td>1</td>
      <td>1.524492e+09</td>
    </tr>
    <tr>
      <th>112646</th>
      <td>84c5d4fbaf120aae381fad077416eaa0</td>
      <td>computers_accessories_7825</td>
      <td>1</td>
      <td>1.531564e+09</td>
    </tr>
    <tr>
      <th>112647</th>
      <td>29309aa813182aaddc9b259e31b870e6</td>
      <td>sports_leisure_8640</td>
      <td>1</td>
      <td>1.508778e+09</td>
    </tr>
    <tr>
      <th>112648</th>
      <td>b5e6afd5a41800fdf401e0272ca74655</td>
      <td>computers_accessories_7826</td>
      <td>1</td>
      <td>1.502752e+09</td>
    </tr>
    <tr>
      <th>112649</th>
      <td>96d649da0cc4ff33bb408b199d4c7dcf</td>
      <td>bed_bath_table_11114</td>
      <td>1</td>
      <td>1.528564e+09</td>
    </tr>
  </tbody>
</table>
<p>111023 rows × 4 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">interactions_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span> <span class="s1">&#39;ITEMID&#39;</span><span class="p">])[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">interactions_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">interactions_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">interactions_dict</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">interactions</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">interactions</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;USERID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;ITEMID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;RATING&#39;</span> <span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]),</span>
<span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;00012a2ce6f8dcda20d059ce98491703&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;toys_1531&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000161a058600d5901f007fab4c27140&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;health_beauty_6074&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0001fd6190edaaf884bcaf3d49edf079&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;baby_571&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0002414f95344307404f0ace7a26f1d5&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;cool_stuff_1263&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000379cdec625522490c315e70c7a9fb&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;bed_bath_table_483&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">items_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">items_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">items_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">items</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">items_dict</span><span class="p">)</span>

<span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">unique_item_titles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">))))</span>
<span class="n">unique_user_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">interactions</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1_000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">]))))</span>

<span class="c1"># Randomly shuffle data and split between train and test.</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">shuffled</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">reshuffle_each_iteration</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">20_000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Retrieval-Model">Retrieval Model<a class="anchor-link" href="#Retrieval-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are five important component of the query and candicate tower: candidate model (item_model), querty model (user_model), metrics, task, and compute loss.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RetailModel</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_model</span><span class="p">,</span> <span class="n">item_model</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      
      <span class="c1">### Candidate model (item)</span>
      <span class="c1">### This is Keras preprocessing layers to first convert user ids to integers, </span>
      <span class="c1">### and then convert those to user embeddings via an Embedding layer. </span>
      <span class="c1">### We use the list of unique user ids we computed earlier as a vocabulary:</span>
      <span class="n">item_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                      <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_titles</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_titles</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                      <span class="p">])</span>
      <span class="c1">### we pass the embedding layer into item model</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="n">item_model</span>
          
      <span class="c1">### Query model (users)    </span>
      <span class="n">user_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                      <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                      <span class="c1"># We add an additional embedding to account for unknown tokens.</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                      <span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="n">user_model</span>
      
      <span class="c1">### for retrieval model. we take top-k accuracy as metrics</span>
      <span class="n">metrics</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FactorizedTopK</span><span class="p">(</span><span class="n">candidates</span><span class="o">=</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">item_model</span><span class="p">))</span>
      
      <span class="c1"># define the task, which is retrieval</span>
      <span class="n">task</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Retrieval</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
      
      <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">task</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
      <span class="c1"># We pick out the user features and pass them into the user model.</span>
      <span class="n">user_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>
      <span class="c1"># And pick out the movie features and pass them into the movie model,</span>
      <span class="c1"># getting embeddings back.</span>
      <span class="n">positive_movie_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>

      <span class="c1"># The task computes the loss and the metrics.</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">(</span><span class="n">user_embeddings</span><span class="p">,</span> <span class="n">positive_movie_embeddings</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1">### we choose the dimensionality of the query and candicate representation.</span>
<span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1">## we pass the model, which is the same model we created in the query and candidate tower, into the model</span>
<span class="n">item_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_titles</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_titles</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                <span class="p">])</span>

<span class="n">user_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                <span class="c1"># We add an additional embedding to account for unknown tokens.</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                <span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RetailModel</span><span class="p">(</span><span class="n">user_model</span><span class="p">,</span> <span class="n">item_model</span><span class="p">)</span>

<span class="c1"># a smaller learning rate may make the model move slower and prone to overfitting, so we stick to 0.1</span>
<span class="c1"># other optimizers, such as SGD and Adam, are listed here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8192</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="c1">## fit the model with ten epochs</span>
<span class="n">model_hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1">#evaluate the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/10
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
8/8 [==============================] - 400s 49s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_50_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.6667e-04 - loss: 62067.0734 - regularization_loss: 0.0000e+00 - total_loss: 62067.0734
Epoch 2/10
8/8 [==============================] - 396s 49s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0935 - factorized_top_k/top_10_categorical_accuracy: 0.1493 - factorized_top_k/top_50_categorical_accuracy: 0.3334 - factorized_top_k/top_100_categorical_accuracy: 0.4331 - loss: 61949.0182 - regularization_loss: 0.0000e+00 - total_loss: 61949.0182
Epoch 3/10
8/8 [==============================] - 392s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5566 - factorized_top_k/top_10_categorical_accuracy: 0.7027 - factorized_top_k/top_50_categorical_accuracy: 0.9107 - factorized_top_k/top_100_categorical_accuracy: 0.9537 - loss: 61799.8203 - regularization_loss: 0.0000e+00 - total_loss: 61799.8203
Epoch 4/10
8/8 [==============================] - 391s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6852 - factorized_top_k/top_10_categorical_accuracy: 0.8421 - factorized_top_k/top_50_categorical_accuracy: 0.9835 - factorized_top_k/top_100_categorical_accuracy: 0.9948 - loss: 61557.9358 - regularization_loss: 0.0000e+00 - total_loss: 61557.9358
Epoch 5/10
8/8 [==============================] - 390s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6006 - factorized_top_k/top_10_categorical_accuracy: 0.7915 - factorized_top_k/top_50_categorical_accuracy: 0.9886 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 61139.4262 - regularization_loss: 0.0000e+00 - total_loss: 61139.4262
Epoch 6/10
8/8 [==============================] - 389s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5041 - factorized_top_k/top_10_categorical_accuracy: 0.7085 - factorized_top_k/top_50_categorical_accuracy: 0.9848 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 60430.4431 - regularization_loss: 0.0000e+00 - total_loss: 60430.4431
Epoch 7/10
8/8 [==============================] - 390s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4606 - factorized_top_k/top_10_categorical_accuracy: 0.6669 - factorized_top_k/top_50_categorical_accuracy: 0.9832 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 59296.1063 - regularization_loss: 0.0000e+00 - total_loss: 59296.1063
Epoch 8/10
8/8 [==============================] - 384s 47s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4800 - factorized_top_k/top_10_categorical_accuracy: 0.6913 - factorized_top_k/top_50_categorical_accuracy: 0.9875 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 57606.5898 - regularization_loss: 0.0000e+00 - total_loss: 57606.5898
Epoch 9/10
8/8 [==============================] - 387s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5498 - factorized_top_k/top_10_categorical_accuracy: 0.7657 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 55261.9683 - regularization_loss: 0.0000e+00 - total_loss: 55261.9683
Epoch 10/10
8/8 [==============================] - 385s 47s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6651 - factorized_top_k/top_10_categorical_accuracy: 0.8625 - factorized_top_k/top_50_categorical_accuracy: 0.9977 - factorized_top_k/top_100_categorical_accuracy: 0.9997 - loss: 52214.9371 - regularization_loss: 0.0000e+00 - total_loss: 52214.9371
5/5 [==============================] - 132s 26s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.4167 - regularization_loss: 0.0000e+00 - total_loss: 32588.4167
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 29625.80078125,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 29625.80078125}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>5/5 [==============================] - 130s 26s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.4167 - regularization_loss: 0.0000e+00 - total_loss: 32588.4167
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 29625.80078125,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 29625.80078125}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model_hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;factorized_top_k/top_100_categorical_accuracy&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy vs epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Top-100 accuracy&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.legend.Legend at 0x7f289dc49790&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">factorized_top_k</span><span class="o">.</span><span class="n">BruteForce</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">user_model</span><span class="p">)</span>
<span class="c1"># recommends items out of the entire dataset.</span>
<span class="n">index</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">item_model</span><span class="p">),</span> <span class="n">items</span><span class="p">)</span>

<span class="c1"># Get recommendations.</span>
<span class="n">j</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">index</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">j</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recommendations for user %s: </span><span class="si">{</span><span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">j</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Recommendations for user 40: [b&#39;housewares_1189&#39; b&#39;housewares_1181&#39; b&#39;housewares_1186&#39;
 b&#39;housewares_1188&#39; b&#39;electronics_1206&#39; b&#39;housewares_1185&#39;
 b&#39;housewares_1190&#39; b&#39;electronics_1205&#39; b&#39;housewares_1182&#39;
 b&#39;housewares_1184&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There you are, our first simple yet effective recommendation engine using retrieval task. But what about ranking? can we rank all the items for best to worst, only then run retrieval task to retrieve selected items from the short list? Now we can explore another type of recommendation task: ranking.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ranking-Model">Ranking Model<a class="anchor-link" href="#Ranking-Model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ranking model is able to assist retrieval by ranking all the items from highest to lowest, predcting a probablity that a user may or may not like it. Ranking model is useful to filter out items that are not relevant for the user before retrieval task, making retrieval task much more accurate and efficient.</p>
<p>Here, many embedding layers works similarly with retrieval model, with addition of multiple hidden layers under Sequential latyers, where we can stack multiple dense layers. We split the query and candidate tower separately, and call them later into the model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RankingModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="c1"># Compute embeddings for users.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># Compute embeddings for movies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_titles</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_titles</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># Compute predictions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="c1"># Learn multiple dense layers.</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
          <span class="c1"># Make rating predictions in the final layer.</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">])</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>

        <span class="n">user_id</span><span class="p">,</span> <span class="n">item_id</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="n">user_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_embeddings</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span>
        <span class="n">item_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">item_id</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratings</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">user_embedding</span><span class="p">,</span> <span class="n">item_embedding</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This model takes user ids and item ids, and outputs a predicted rating, for example:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">RankingModel</span><span class="p">()(([</span><span class="s2">&quot;f6dd3ec061db4e3987629fe6b26e5cce&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;pet_shop_0&quot;</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;list&#39;&gt; input: [&#39;f6dd3ec061db4e3987629fe6b26e5cce&#39;]
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;list&#39;&gt; input: [&#39;pet_shop_0&#39;]
Consider rewriting this model with the Functional API.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01409375]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RetailModel</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranking_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="n">RankingModel</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Ranking</span><span class="p">(</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
          <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">RootMeanSquaredError</span><span class="p">()]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">rating_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranking_model</span><span class="p">(</span>
            <span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">],</span> <span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">]))</span>

        <span class="c1"># The task computes the loss and the metrics.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;RATING&quot;</span><span class="p">],</span> <span class="n">predictions</span><span class="o">=</span><span class="n">rating_predictions</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RetailModel</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8192</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/100
8/8 [==============================] - 3s 31ms/step - root_mean_squared_error: 0.9951 - loss: 0.8617 - regularization_loss: 0.0000e+00 - total_loss: 0.8617
Epoch 2/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.2813 - loss: 0.0668 - regularization_loss: 0.0000e+00 - total_loss: 0.0668
Epoch 3/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 0.0593 - loss: 0.0030 - regularization_loss: 0.0000e+00 - total_loss: 0.0030
Epoch 4/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.0126 - loss: 1.3481e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.3481e-04
Epoch 5/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.0027 - loss: 6.1202e-06 - regularization_loss: 0.0000e+00 - total_loss: 6.1202e-06
Epoch 6/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 5.7347e-04 - loss: 2.7786e-07 - regularization_loss: 0.0000e+00 - total_loss: 2.7786e-07
Epoch 7/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.2221e-04 - loss: 1.2619e-08 - regularization_loss: 0.0000e+00 - total_loss: 1.2619e-08
Epoch 8/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 2.6041e-05 - loss: 5.7305e-10 - regularization_loss: 0.0000e+00 - total_loss: 5.7305e-10
Epoch 9/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 5.5814e-06 - loss: 2.6307e-11 - regularization_loss: 0.0000e+00 - total_loss: 2.6307e-11
Epoch 10/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1712e-06 - loss: 1.1586e-12 - regularization_loss: 0.0000e+00 - total_loss: 1.1586e-12
Epoch 11/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 2.6456e-07 - loss: 5.9607e-14 - regularization_loss: 0.0000e+00 - total_loss: 5.9607e-14
Epoch 12/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 13/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 14/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 15/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 16/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 17/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 18/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 19/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 20/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 21/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 22/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 23/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 24/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 25/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 26/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 27/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 28/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 29/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 30/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 31/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 32/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 33/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 34/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 35/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 36/100
8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 37/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 38/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 39/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 40/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 41/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 42/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 43/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 44/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 45/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 46/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 47/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 48/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 49/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 50/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 51/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 52/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 53/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 54/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 55/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 56/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 57/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 58/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 59/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 60/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 61/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 62/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 63/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 64/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 65/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 66/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 67/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 68/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 69/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 70/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 71/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 72/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 73/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 74/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 75/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 76/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 77/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 78/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 79/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 80/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 81/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 82/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 83/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 84/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 85/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 86/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 87/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 88/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 89/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 90/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 91/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 92/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 93/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 94/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 95/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 96/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 97/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 98/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 99/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 100/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f28a37c5d90&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>5/5 [==============================] - 2s 22ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;loss&#39;: 1.4210854715202004e-14,
 &#39;regularization_loss&#39;: 0,
 &#39;root_mean_squared_error&#39;: 1.1920928955078125e-07,
 &#39;total_loss&#39;: 1.4210854715202004e-14}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The RMSE is not very good, which we shall see how we can improve it by adding more features and combining ranking and retrieval model together.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Adding-Context">Adding Context<a class="anchor-link" href="#Adding-Context"> </a></h2><p>Adding Timestamp and Text embeddings</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">interactions_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span> <span class="s1">&#39;ITEMID&#39;</span><span class="p">,</span> <span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">])[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">interactions_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">interactions_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">interactions_dict</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">interactions</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">interactions</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;USERID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;ITEMID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;RATING&#39;</span> <span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;TIMESTAMP&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">],</span>
<span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;00012a2ce6f8dcda20d059ce98491703&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;toys_1531&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1510675706.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000161a058600d5901f007fab4c27140&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;health_beauty_6074&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1500198032.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0001fd6190edaaf884bcaf3d49edf079&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;baby_571&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1488280003.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0002414f95344307404f0ace7a26f1d5&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;cool_stuff_1263&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1502888960.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000379cdec625522490c315e70c7a9fb&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;bed_bath_table_483&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1522676537.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">items_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">items_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">items_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">items</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">items_dict</span><span class="p">)</span>

<span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>timestamp is an exmaple of continuous features, which needs to be rescaled, or otherwise it will be too large for the model. there are other methods to reduce the size of the timestamp, ,such as standardization and normalization here we use discretization, which puts them into buckets of categorical features,</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">timestamps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">interactions</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)))</span>
<span class="n">max_timestamp</span> <span class="o">=</span> <span class="n">timestamps</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">min_timestamp</span> <span class="o">=</span> <span class="n">timestamps</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">timestamp_buckets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
    <span class="n">min_timestamp</span><span class="p">,</span> <span class="n">max_timestamp</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">,)</span>

<span class="n">item_ids</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>
<span class="n">user_ids</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>

<span class="n">unique_item_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">item_ids</span><span class="p">)))</span>
<span class="n">unique_user_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">user_ids</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">shuffled</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">reshuffle_each_iteration</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">20_000</span><span class="p">)</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We split the query and candidate model separately to allow more stacked embedding layers before we pass it into the model. In the user model (query model), in addition to user embedding, we also add timestamp embedding.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">UserModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_timestamps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_use_timestamps</span> <span class="o">=</span> <span class="n">use_timestamps</span>

        <span class="c1">## embed user id from unique_user_ids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
        <span class="p">])</span>

        <span class="c1">## embed timestamp</span>
        <span class="k">if</span> <span class="n">use_timestamps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timestamp_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Discretization</span><span class="p">(</span><span class="n">timestamp_buckets</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">timestamp_buckets</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_timestamp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Normalization</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_timestamp</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">timestamps</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_timestamps</span><span class="p">:</span>
              <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>

        <span class="c1">## all features here</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timestamp_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_timestamp</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">]),</span>
        <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the candidate model, we want the model to learn from the text features too by processing the text features that is able to learn words that are similar to each other. It can also identify OOV (out of Vocabulary) word, so if we are predicing a new item, the model can calculate them appropriately.</p>
<p>Below, the item name will be transformated by tokenization (splitting into constituent words or word-pieces), followed by vocabulary learning, then followed by an embedding.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">ItemModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">10_000</span>

        <span class="c1">## embed title from unique_item_ids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">title_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
              <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1">## processing text features: item title vectorizer (see self.title_vectorizer)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">title_vectorizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">TextVectorization</span><span class="p">(</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">)</span>

        <span class="c1">## we apply title vectorizer to items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">title_text_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">title_vectorizer</span><span class="p">,</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">title_vectorizer</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">titles</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">title_embedding</span><span class="p">(</span><span class="n">titles</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">title_text_embedding</span><span class="p">(</span><span class="n">titles</span><span class="p">),</span>
        <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With both UserModel and ItemModel defined, we can put together a combined model and implement our loss and metrics logic.</p>
<p>Note that we also need to make sure that the query model and candidate model output embeddings of compatible size. Because we'll be varying their sizes by adding more features, the easiest way to accomplish this is to use a dense projection layer after each model:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RetailModel</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_timestamps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1">## query model is user model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">UserModel</span><span class="p">(</span><span class="n">use_timestamps</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
        <span class="p">])</span>
        
        <span class="c1">## candidate model is the item model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">ItemModel</span><span class="p">(),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
        <span class="p">])</span>
        
        <span class="c1">## retrieval task, choose metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Retrieval</span><span class="p">(</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">tfrs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FactorizedTopK</span><span class="p">(</span>
                <span class="n">candidates</span><span class="o">=</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_model</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># We only pass the user id and timestamp features into the query model. This</span>
        <span class="c1"># is to ensure that the training inputs would have the same keys as the</span>
        <span class="c1"># query inputs. Otherwise the discrepancy in input structure would cause an</span>
        <span class="c1"># error when loading the query model after saving it.</span>
        
        <span class="n">query_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_model</span><span class="p">({</span>
            <span class="s2">&quot;USERID&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">],</span>
            <span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">],</span>
        <span class="p">})</span>
        
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">(</span><span class="n">query_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="flash">
    <svg class="octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Baseline is with no timestamp feature.
</div></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RetailModel</span><span class="p">(</span><span class="n">use_timestamps</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/3
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
30/30 [==============================] - 422s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0564 - factorized_top_k/top_5_categorical_accuracy: 0.0614 - factorized_top_k/top_10_categorical_accuracy: 0.0640 - factorized_top_k/top_50_categorical_accuracy: 0.0715 - factorized_top_k/top_100_categorical_accuracy: 0.0752 - loss: 14855.2315 - regularization_loss: 0.0000e+00 - total_loss: 14855.2315
Epoch 2/3
30/30 [==============================] - 420s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0479 - factorized_top_k/top_5_categorical_accuracy: 0.0490 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.0508 - factorized_top_k/top_100_categorical_accuracy: 0.0516 - loss: 14047.4312 - regularization_loss: 0.0000e+00 - total_loss: 14047.4312
Epoch 3/3
30/30 [==============================] - 422s 14s/step - factorized_top_k/top_1_categorical_accuracy: 5.1667e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0026 - factorized_top_k/top_50_categorical_accuracy: 0.0101 - factorized_top_k/top_100_categorical_accuracy: 0.0195 - loss: 11625.8452 - regularization_loss: 0.0000e+00 - total_loss: 11625.8452
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f2837bac9d0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
5/5 [==============================] - 137s 27s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33116.2435 - regularization_loss: 0.0000e+00 - total_loss: 33116.2435
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 30138.40234375,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 30138.40234375}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Including time into the model:</p>
<p>Do the result change if we add time features?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span><span class="n">x</span> <span class="n">RetailModel</span><span class="p">(</span><span class="n">use_timestamps</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/3
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
30/30 [==============================] - 430s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0077 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0228 - factorized_top_k/top_50_categorical_accuracy: 0.0459 - factorized_top_k/top_100_categorical_accuracy: 0.0664 - loss: 14859.7737 - regularization_loss: 0.0000e+00 - total_loss: 14859.7737
Epoch 2/3
30/30 [==============================] - 430s 14s/step - factorized_top_k/top_1_categorical_accuracy: 2.1667e-04 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0011 - factorized_top_k/top_50_categorical_accuracy: 0.0032 - factorized_top_k/top_100_categorical_accuracy: 0.0051 - loss: 12473.8825 - regularization_loss: 0.0000e+00 - total_loss: 12473.8825
Epoch 3/3
30/30 [==============================] - 432s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0070 - factorized_top_k/top_10_categorical_accuracy: 0.0132 - factorized_top_k/top_50_categorical_accuracy: 0.0543 - factorized_top_k/top_100_categorical_accuracy: 0.1117 - loss: 8039.4111 - regularization_loss: 0.0000e+00 - total_loss: 8039.4111
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f27e41ea250&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
5/5 [==============================] - 138s 27s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33796.7786 - regularization_loss: 0.0000e+00 - total_loss: 33796.7786
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 30721.021484375,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 30721.021484375}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="flash">
    <svg class="octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Eventhough we only run it at three epochs, we can see accuracy increase as we add time into the model.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multi-Task-Model-with-ReLU-based-DNN">Multi-Task Model with ReLU-based DNN<a class="anchor-link" href="#Multi-Task-Model-with-ReLU-based-DNN"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">rating_weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We take the loss weights in the constructor: this allows us to instantiate</span>
        <span class="c1"># several model objects with different loss weights.</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="c1"># item models.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>
            
        <span class="c1">## user model    </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># A small model to take in user and item embeddings and predict ratings.</span>
        <span class="c1"># We can make this as complicated as we want as long as we output a scalar</span>
        <span class="c1"># as our prediction.</span>
        
        <span class="c1">## this is Relu-Based DNN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">])</span>

        <span class="c1"># rating and retrieval task.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Ranking</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">RootMeanSquaredError</span><span class="p">()],</span>
        <span class="p">)</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Retrieval</span><span class="p">(</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">tfrs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FactorizedTopK</span><span class="p">(</span>
                <span class="n">candidates</span><span class="o">=</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># The loss weights.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_weight</span> <span class="o">=</span> <span class="n">rating_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_weight</span> <span class="o">=</span> <span class="n">retrieval_weight</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># We pick out the user features and pass them into the user model.</span>
        <span class="n">user_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>
        
        <span class="c1"># And pick out the item features and pass them into the item model.</span>
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">user_embeddings</span><span class="p">,</span>
            <span class="n">item_embeddings</span><span class="p">,</span>
            <span class="c1"># We apply the multi-layered rating model to a concatentation of</span>
            <span class="c1"># user and item embeddings.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rating_model</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">user_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

        <span class="c1">## ratings go here as a method to compute loss</span>
        <span class="n">ratings</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;RATING&quot;</span><span class="p">)</span>

        <span class="n">user_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">,</span> <span class="n">rating_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># We compute the loss for each task.</span>
        <span class="n">rating_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rating_task</span><span class="p">(</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">ratings</span><span class="p">,</span>
            <span class="n">predictions</span><span class="o">=</span><span class="n">rating_predictions</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">retrieval_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_task</span><span class="p">(</span><span class="n">user_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">)</span>

        <span class="c1"># And combine them using the loss weights.</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rating_weight</span> <span class="o">*</span> <span class="n">rating_loss</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_weight</span> <span class="o">*</span> <span class="n">retrieval_loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Rating-specialized-model">Rating-specialized model<a class="anchor-link" href="#Rating-specialized-model"> </a></h3><p>Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">rating_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8192</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieval top-100 accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;factorized_top_k/top_100_categorical_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ranking RMSE: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/3
8/8 [==============================] - 388s 48s/step - root_mean_squared_error: 0.4401 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 7.8333e-04 - loss: 0.1581 - regularization_loss: 0.0000e+00 - total_loss: 0.1581
Epoch 2/3
8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.0205 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1667e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 3.7047e-04 - regularization_loss: 0.0000e+00 - total_loss: 3.7047e-04
Epoch 3/3
8/8 [==============================] - 386s 48s/step - root_mean_squared_error: 0.0125 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1667e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 1.5387e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5387e-04
5/5 [==============================] - 133s 26s/step - root_mean_squared_error: 0.0123 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 9.0000e-04 - loss: 1.5055e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5055e-04
Retrieval top-100 accuracy: 0.001.
Ranking RMSE: 0.012.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Retrieval-specialized-model">Retrieval-specialized model<a class="anchor-link" href="#Retrieval-specialized-model"> </a></h3><p>Let's now try a model that focuses on retrieval only.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">rating_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieval top-100 accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;factorized_top_k/top_100_categorical_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ranking RMSE: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/3
8/8 [==============================] - 382s 47s/step - root_mean_squared_error: 0.9892 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_50_categorical_accuracy: 3.8333e-04 - factorized_top_k/top_100_categorical_accuracy: 7.0000e-04 - loss: 62067.1797 - regularization_loss: 0.0000e+00 - total_loss: 62067.1797
Epoch 2/3
8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.9881 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0918 - factorized_top_k/top_10_categorical_accuracy: 0.1484 - factorized_top_k/top_50_categorical_accuracy: 0.3325 - factorized_top_k/top_100_categorical_accuracy: 0.4333 - loss: 61949.0569 - regularization_loss: 0.0000e+00 - total_loss: 61949.0569
Epoch 3/3
8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.9851 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5590 - factorized_top_k/top_10_categorical_accuracy: 0.7058 - factorized_top_k/top_50_categorical_accuracy: 0.9094 - factorized_top_k/top_100_categorical_accuracy: 0.9534 - loss: 61799.7860 - regularization_loss: 0.0000e+00 - total_loss: 61799.7860
5/5 [==============================] - 130s 26s/step - root_mean_squared_error: 0.9883 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.8281 - regularization_loss: 0.0000e+00 - total_loss: 32588.8281
Retrieval top-100 accuracy: 0.000.
Ranking RMSE: 0.988.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Joint-model">Joint model<a class="anchor-link" href="#Joint-model"> </a></h3><p>Let's now train a model that assigns positive weights to both tasks.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">rating_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieval top-100 accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;factorized_top_k/top_100_categorical_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ranking RMSE: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/3
8/8 [==============================] - 383s 47s/step - root_mean_squared_error: 0.4693 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_50_categorical_accuracy: 2.6667e-04 - factorized_top_k/top_100_categorical_accuracy: 7.5000e-04 - loss: 31033.7246 - regularization_loss: 0.0000e+00 - total_loss: 31033.7246
Epoch 2/3
8/8 [==============================] - 387s 48s/step - root_mean_squared_error: 0.0133 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0084 - factorized_top_k/top_10_categorical_accuracy: 0.0152 - factorized_top_k/top_50_categorical_accuracy: 0.0466 - factorized_top_k/top_100_categorical_accuracy: 0.0706 - loss: 31004.2229 - regularization_loss: 0.0000e+00 - total_loss: 31004.2229
Epoch 3/3
8/8 [==============================] - 382s 47s/step - root_mean_squared_error: 0.0138 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1620 - factorized_top_k/top_10_categorical_accuracy: 0.2301 - factorized_top_k/top_50_categorical_accuracy: 0.4188 - factorized_top_k/top_100_categorical_accuracy: 0.5109 - loss: 30972.8370 - regularization_loss: 0.0000e+00 - total_loss: 30972.8370
5/5 [==============================] - 131s 26s/step - root_mean_squared_error: 0.0136 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_100_categorical_accuracy: 1.5000e-04 - loss: 16294.1732 - regularization_loss: 0.0000e+00 - total_loss: 16294.1732
Retrieval top-100 accuracy: 0.000.
Ranking RMSE: 0.014.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that accuracy is highest and RMSE is lowest when we combine both ranking and retrieval together.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/2022/01/26/tfrs-olist.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Jupyter notebook database.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/recohut" target="_blank" title="recohut"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>

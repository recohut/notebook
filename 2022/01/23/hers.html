<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>HERS Cold-start Recommendations on LastFM dataset | reconb</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="HERS Cold-start Recommendations on LastFM dataset" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation." />
<meta property="og:description" content="Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation." />
<link rel="canonical" href="https://nb.recohut.com/2022/01/23/hers.html" />
<meta property="og:url" content="https://nb.recohut.com/2022/01/23/hers.html" />
<meta property="og:site_name" content="reconb" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-23T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="HERS Cold-start Recommendations on LastFM dataset" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-01-23T00:00:00-06:00","datePublished":"2022-01-23T00:00:00-06:00","description":"Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation.","headline":"HERS Cold-start Recommendations on LastFM dataset","mainEntityOfPage":{"@type":"WebPage","@id":"https://nb.recohut.com/2022/01/23/hers.html"},"url":"https://nb.recohut.com/2022/01/23/hers.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nb.recohut.com/feed.xml" title="reconb" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">reconb</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">HERS Cold-start Recommendations on LastFM dataset</h1><p class="page-description">Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-23T00:00:00-06:00" itemprop="datePublished">
        Jan 23, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      17 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/recohut/notebook/tree/master/_notebooks/2022-01-23-hers.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/recohut/notebook/master?filepath=_notebooks%2F2022-01-23-hers.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/recohut/notebook/blob/master/_notebooks/2022-01-23-hers.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frecohut%2Fnotebook%2Fblob%2Fmaster%2F_notebooks%2F2022-01-23-hers.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-23-hers.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>HERS consists of three heterogeneous relations: user-user, item-item, and user-item. Each user’s choice is relevant to the corresponding user’s and item’s influential contexts.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/recohut/coldstart-recsys/raw/da72950ca514faee94f010a2cb6e99a373044ec1/docs/_images/T229879_1.png" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Architecture">Model Architecture<a class="anchor-link" href="#Model-Architecture"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The architecture of HERS for modeling user-item interaction with user’s and item’s influential contexts.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/recohut/coldstart-recsys/raw/da72950ca514faee94f010a2cb6e99a373044ec1/docs/_images/T229879_2.png" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Influential-Context Aggregation Unit (ICAU): A two-stage aggregation model to construct ICE.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/recohut/coldstart-recsys/raw/da72950ca514faee94f010a2cb6e99a373044ec1/docs/_images/T229879_3.png" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CLI-Run">CLI Run<a class="anchor-link" href="#CLI-Run"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">fastFM</span><span class="o">==</span><span class="mf">0.2</span><span class="o">.</span><span class="mi">9</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">tensorflow_version</span> <span class="mf">1.</span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow 1.x selected.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="o">-</span><span class="n">qq</span> <span class="n">install</span> <span class="n">tree</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Selecting previously unselected package tree.
(Reading database ... 155062 files and directories currently installed.)
Preparing to unpack .../tree_1.7.0-5_amd64.deb ...
Unpacking tree (1.7.0-5) ...
Setting up tree (1.7.0-5) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">rainmilk</span><span class="o">/</span><span class="n">aaai19hers</span><span class="o">.</span><span class="n">git</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Cloning into &#39;aaai19hers&#39;...
remote: Enumerating objects: 70, done.
remote: Counting objects: 100% (13/13), done.
remote: Compressing objects: 100% (10/10), done.
remote: Total 70 (delta 3), reused 9 (delta 3), pack-reused 57
Unpacking objects: 100% (70/70), done.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">cd</span> <span class="n">aaai19hers</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>/content/aaai19hers
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">tree</span> <span class="o">--</span><span class="n">du</span> <span class="o">-</span><span class="n">h</span> <span class="o">-</span><span class="n">C</span> <span class="o">.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-blue-intense-fg ansi-bold">.</span>
├── [ 40M]  <span class="ansi-blue-intense-fg ansi-bold">datasets</span>
│   ├── [ 23M]  <span class="ansi-blue-intense-fg ansi-bold">book</span>
│   │   ├── [7.6M]  book_itemNet.txt
│   │   ├── [1.2M]  book_rating_test_cold_item_neg.txt
│   │   ├── [1.3M]  book_rating_test_cold_item.txt
│   │   ├── [573K]  book_rating_test_cold_user_neg.txt
│   │   ├── [490K]  book_rating_test_cold_user.txt
│   │   ├── [1014K]  book_rating_test.txt
│   │   ├── [757K]  book_rating_train_cold_item_reverse.txt
│   │   ├── [757K]  book_rating_train_cold_item.txt
│   │   ├── [4.5M]  book_rating_train_cold_user.txt
│   │   ├── [4.0M]  book_rating_train.txt
│   │   ├── [1022K]  book_rating.txt
│   │   └── [134K]  book_userNet.txt
│   └── [ 17M]  <span class="ansi-blue-intense-fg ansi-bold">lastfm</span>
│       ├── [1.2M]  lastfm_itemNet.txt
│       ├── [2.3M]  lastfm_rating_test_cold_item_neg.txt
│       ├── [2.9M]  lastfm_rating_test_cold_item.txt
│       ├── [792K]  lastfm_rating_test_cold_user_neg.txt
│       ├── [864K]  lastfm_rating_test_cold_user.txt
│       ├── [844K]  lastfm_rating_test.txt
│       ├── [230K]  lastfm_rating_train_cold_item_reverse.txt
│       ├── [230K]  lastfm_rating_train_cold_item.txt
│       ├── [3.3M]  lastfm_rating_train_cold_user.txt
│       ├── [3.3M]  lastfm_rating_train.txt
│       ├── [749K]  lastfm_rating.txt
│       └── [219K]  lastfm_userNet.txt
├── [ 18K]  <span class="ansi-blue-intense-fg ansi-bold">evaluation</span>
│   ├── [   0]  __init__.py
│   ├── [3.9K]  test_FM.py
│   └── [9.9K]  test_hers.py
├── [ 79K]  <span class="ansi-blue-intense-fg ansi-bold">model</span>
│   ├── [ 25K]  attentionlayer.py
│   ├── [8.3K]  batch_generator_np.py
│   ├── [10.0K]  construct_RS_train.py
│   ├── [ 626]  data_utilities.py
│   ├── [1.4K]  graph_utilities.py
│   ├── [   0]  __init__.py
│   ├── [ 515]  losses.py
│   ├── [ 905]  masklayers.py
│   ├── [1.5K]  mlmr.py
│   ├── [2.7K]  ranking.py
│   ├── [4.1K]  RSbatch.py
│   ├── [2.5K]  scorer.py
│   ├── [2.6K]  socialRC.py
│   ├── [8.3K]  srs_model.py
│   └── [6.2K]  timedistributed.py
└── [ 119]  README.md

  40M used in 5 directories, 43 files
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">model.graph_utilities</span> <span class="kn">import</span>  <span class="n">read_graph</span>
<span class="kn">from</span> <span class="nn">model.losses</span> <span class="kn">import</span> <span class="n">infinite_margin_loss</span><span class="p">,</span> <span class="n">max_margin_loss</span>
<span class="kn">from</span> <span class="nn">keras.regularizers</span> <span class="kn">import</span> <span class="n">l2</span>
<span class="kn">from</span> <span class="nn">model.srs_model</span> <span class="kn">import</span> <span class="n">NetworkRS</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">model.RSbatch</span> <span class="kn">import</span> <span class="n">ItemGenerator</span><span class="p">,</span><span class="n">TripletGenerator</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">model.socialRC</span> <span class="kn">import</span> <span class="n">test_recommendation</span>
<span class="kn">from</span> <span class="nn">model.mlmr</span> <span class="kn">import</span> <span class="n">mlmf</span>
<span class="kn">from</span> <span class="nn">model.scorer</span> <span class="kn">import</span> <span class="n">nn_scoremodel</span><span class="p">,</span> <span class="n">inner_prod_scoremodel</span><span class="p">,</span> <span class="n">fm_scoremodel</span>


<span class="n">data_name</span><span class="o">=</span><span class="s1">&#39;lastfm&#39;</span>
<span class="n">user_net_path</span><span class="o">=</span><span class="s1">&#39;datasets/</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">_userNet.txt&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>
<span class="n">ui_net_path</span> <span class="o">=</span><span class="s1">&#39;datasets/</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">_rating.txt&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>
<span class="n">item_path</span> <span class="o">=</span> <span class="s1">&#39;datasets/</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">_itemNet.txt&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># train_path = &quot;networkRS/%s_rating_train.txt&quot;%data_name</span>
<span class="c1"># test_path = &quot;networkRS/%s_rating_test.txt&quot;%data_name</span>
<span class="c1"># neg_test_path = &quot;networkRS/%s_rating_test_neg.csv&quot;%data_name</span>

<span class="c1"># item_rep_path = &quot;networkRS/%s_item_rep_user.txt&quot;%data_name</span>
<span class="c1"># user_rep_path = &quot;networkRS/%s_user_rep_user.txt&quot;%data_name</span>

<span class="n">neg_test_path</span><span class="o">=</span> <span class="s2">&quot;datasets/</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">_rating_test_cold_user_neg.txt&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>
<span class="n">train_path</span> <span class="o">=</span> <span class="s2">&quot;datasets/</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">_rating_train_cold_user.txt&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>
<span class="n">test_path</span> <span class="o">=</span> <span class="s2">&quot;datasets/</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">_rating_test_cold_user.txt&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>

<span class="n">item_rep_path</span> <span class="o">=</span> <span class="s2">&quot;datasets/</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">_item_rep_user_cold.txt&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>
<span class="n">user_rep_path</span> <span class="o">=</span> <span class="s2">&quot;datasets/</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">_user_rep_user_cold.txt&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span><span class="n">data_name</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># neg_test_path= &quot;networkRS/%s_rating_test_cold_item_neg.txt&quot;%data_name</span>
<span class="c1"># train_path = &quot;networkRS/%s_rating_train_cold_item.txt&quot;%data_name</span>
<span class="c1"># test_path = &quot;networkRS/%s_rating_test_cold_item.txt&quot;%data_name</span>
<span class="c1">#</span>
<span class="c1"># item_rep_path = &quot;networkRS/%s_item_rep_item_cold.txt&quot;%data_name</span>
<span class="c1"># user_rep_path = &quot;networkRS/%s_user_rep_item_cold.txt&quot;%data_name</span>


<span class="k">def</span> <span class="nf">get_user_rep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">nx_G</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">,</span> <span class="n">user_rep_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">node_size</span> <span class="o">=</span> <span class="n">nx_G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
    <span class="n">memory_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">node_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">))</span>

    <span class="n">node_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx_G</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
    <span class="n">num_node</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span>
    <span class="n">nb_batch</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_batch</span><span class="p">):</span>
        <span class="n">batch_node</span> <span class="o">=</span> <span class="n">node_list</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">num_node</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)]</span>
        <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">second_batch_data</span> <span class="o">=</span> <span class="n">batchGenerator</span><span class="o">.</span><span class="n">get_batch_data_topk</span><span class="p">(</span><span class="n">batch_node</span><span class="o">=</span><span class="n">batch_node</span><span class="p">,</span> <span class="n">topK</span><span class="o">=</span><span class="n">topK</span><span class="p">)</span>
        <span class="n">memory_out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">user_model</span><span class="o">.</span><span class="n">predict_on_batch</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch_node</span><span class="p">),</span> <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">second_batch_data</span><span class="p">])</span>
        <span class="n">memory_output</span><span class="p">[</span><span class="n">batch_node</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">memory_out</span>

    <span class="k">if</span> <span class="n">save</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">user_rep_path</span><span class="p">,</span> <span class="n">memory_output</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;save memory successfully&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">memory_output</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="k">def</span> <span class="nf">get_cold_start_user_rep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">,</span> <span class="n">test_users</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">memory_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">user_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">))</span>

    <span class="n">node_list</span> <span class="o">=</span> <span class="n">test_users</span>
    <span class="n">num_node</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span>
    <span class="n">nb_batch</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_batch</span><span class="p">):</span>
        <span class="n">batch_node</span> <span class="o">=</span> <span class="n">node_list</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">num_node</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)]</span>
        <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">second_batch_data</span> <span class="o">=</span> <span class="n">batchGenerator</span><span class="o">.</span><span class="n">get_batch_data_topk</span><span class="p">(</span><span class="n">batch_node</span><span class="o">=</span><span class="n">batch_node</span><span class="p">,</span> <span class="n">topK</span><span class="o">=</span><span class="n">topK</span><span class="p">)</span>
        <span class="n">memory_out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">first_model</span><span class="o">.</span><span class="n">predict_on_batch</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch_node</span><span class="p">),</span> <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">second_batch_data</span><span class="p">])</span>
        <span class="n">memory_output</span><span class="p">[</span><span class="n">batch_node</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">memory_out</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">memory_output</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>


<span class="k">def</span> <span class="nf">get_item_rep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">G_item</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">,</span> <span class="n">item_rep_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">node_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">G_item</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
    <span class="n">node_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span>
    <span class="n">memory_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">node_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">))</span>
    <span class="n">nb_batch</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_batch</span><span class="p">):</span>
        <span class="n">batch_node</span> <span class="o">=</span> <span class="n">node_list</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">node_size</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)]</span>
        <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span>  <span class="n">batchGenerator</span><span class="o">.</span><span class="n">itemGenerate</span><span class="o">.</span><span class="n">get_batch_data_topk</span><span class="p">(</span><span class="n">batch_node</span><span class="o">=</span><span class="n">batch_node</span><span class="p">,</span> <span class="n">topK</span><span class="o">=</span><span class="n">topK</span><span class="p">,</span> <span class="n">predict_batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">memory_out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">item_model</span><span class="o">.</span><span class="n">predict_on_batch</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch_node</span><span class="p">),</span> <span class="n">first_batch_data</span><span class="p">])</span>
        <span class="n">memory_output</span><span class="p">[</span><span class="n">batch_node</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">memory_out</span>

    <span class="c1"># embedding_nodeset = embedding_matrix[node_set]</span>
    <span class="c1"># np.savetxt(config.embedding_path, embedding_matrix[1:])</span>
    <span class="c1"># np.savetxt(config.memory_path, memory_output)</span>
    <span class="k">if</span> <span class="n">save</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">item_rep_path</span><span class="p">,</span> <span class="n">memory_output</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;save item representation successfully&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">memory_output</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="k">def</span> <span class="nf">model_testembed_zero</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_path</span><span class="p">):</span>
    <span class="n">test_data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">test_path</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">test_user_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">test_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">user_embed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">user_emb</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">user_embed</span><span class="p">[</span><span class="n">test_user_list</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">user_embed</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">user_embed</span><span class="p">)</span>

<span class="n">test_data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">test_path</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">test_user_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">test_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">G_user</span><span class="o">=</span><span class="n">read_graph</span><span class="p">(</span><span class="n">user_net_path</span><span class="p">)</span>
<span class="n">G_item</span><span class="o">=</span><span class="n">read_graph</span><span class="p">(</span><span class="n">item_path</span><span class="p">)</span>
<span class="n">G_ui</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>



<span class="n">directed</span><span class="o">=</span><span class="kc">False</span>
<span class="n">user_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">G_user</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
<span class="n">item_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">G_item</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>

<span class="n">user_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">user_list</span><span class="p">)</span>
<span class="n">item_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">item_list</span><span class="p">)</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">G_ui</span>
<span class="n">num_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>



<span class="n">embed_len</span><span class="o">=</span><span class="mi">128</span>
<span class="n">topK</span><span class="o">=</span><span class="mi">10</span>
<span class="n">fliter_theta</span><span class="o">=</span><span class="mi">16</span>
<span class="n">aggre_theta</span><span class="o">=</span><span class="mi">64</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">samples</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">margin</span><span class="o">=</span><span class="mi">20</span>
<span class="n">iter_without_att</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">iter_with_att</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="n">iter_without_att</span> <span class="o">+</span> <span class="n">iter_with_att</span>
<span class="n">batch_num</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_edges</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">max_margin_loss</span>

<span class="c1"># score_model = nn_scoremodel((embed_len,), embed_len, score_act=None)</span>
<span class="n">score_model</span> <span class="o">=</span> <span class="n">inner_prod_scoremodel</span><span class="p">((</span><span class="n">embed_len</span><span class="p">,),</span> <span class="n">score_rep_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># score_model = fm_scoremodel((embed_len,), score_rep_norm=False, score_act=None)</span>

<span class="n">pretrain_model</span><span class="o">=</span><span class="n">mlmf</span><span class="p">(</span><span class="n">nb_user</span><span class="o">=</span><span class="n">user_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_item</span><span class="o">=</span><span class="n">item_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="n">embed_len</span><span class="p">,</span>
                    <span class="n">score_model</span><span class="o">=</span><span class="n">score_model</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-7</span><span class="p">))</span>
<span class="n">pretrain_model</span><span class="o">.</span><span class="n">contrast_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
<span class="n">pretrain_model</span><span class="o">.</span><span class="n">contrast_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">pretrain_samples</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">pretrain_batch_sz</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">pretrain_batch_num</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_edges</span> <span class="o">/</span> <span class="n">pretrain_batch_sz</span><span class="p">)</span>
<span class="n">pretrain_iter</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pretrain_iter</span><span class="p">):</span>
    <span class="n">shuffle</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># print(&quot;Running on iteration %d/%d:&quot;%(i, max_iter))</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pretrain_samples</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pretrain_batch_num</span><span class="p">):</span>
            <span class="n">edge_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">pretrain_batch_sz</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">pretrain_batch_sz</span><span class="p">)])</span>
            <span class="n">batch_node_array</span><span class="p">,</span> <span class="n">positive_batch_array</span><span class="p">,</span> <span class="n">negative_batch_array</span> <span class="o">=</span> \
                <span class="p">(</span><span class="n">edge_batch</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">edge_batch</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="n">item_size</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">edge_batch</span><span class="p">)))</span>
            <span class="n">train_loss_temp</span> <span class="o">=</span> <span class="n">pretrain_model</span><span class="o">.</span><span class="n">contrast_model</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">batch_node_array</span><span class="p">,</span> <span class="n">positive_batch_array</span><span class="p">,</span> <span class="n">negative_batch_array</span><span class="p">,],</span> <span class="n">y</span><span class="o">=</span><span class="n">margin</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">edge_batch</span><span class="p">)]))</span>
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">train_loss_temp</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training on sample </span><span class="si">%d</span><span class="s2"> and iter </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish iteration </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> with loss: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pretrain_iter</span><span class="p">,</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">pretrain_batch_num</span> <span class="o">*</span> <span class="n">pretrain_samples</span><span class="p">)))</span>
    <span class="n">user_rep</span> <span class="o">=</span> <span class="n">pretrain_model</span><span class="o">.</span><span class="n">user_emb</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">item_rep</span> <span class="o">=</span> <span class="n">pretrain_model</span><span class="o">.</span><span class="n">item_emb</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">test_recommendation</span><span class="p">(</span><span class="n">user_rep</span><span class="p">,</span> <span class="n">item_rep</span><span class="p">,</span> <span class="n">pretrain_model</span><span class="o">.</span><span class="n">score_model</span><span class="p">,</span> <span class="n">test_path</span><span class="p">,</span> <span class="n">neg_test_path</span><span class="p">)</span>
    <span class="c1">#test_recommendation(item_rep, user_rep, test_path, neg_test_path) #for cold start item</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">NetworkRS</span><span class="p">(</span><span class="n">user_size</span><span class="p">,</span> <span class="n">item_size</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">,</span> <span class="n">score_model</span><span class="p">,</span>
                  <span class="n">topK</span><span class="p">,</span> <span class="n">topK</span><span class="p">,</span> <span class="n">embed_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">5e-7</span><span class="p">),</span> <span class="n">directed</span><span class="o">=</span><span class="n">directed</span><span class="p">,</span>
                  <span class="n">mem_filt_alpha</span><span class="o">=</span><span class="n">fliter_theta</span><span class="p">,</span> <span class="n">mem_agg_alpha</span><span class="o">=</span><span class="n">aggre_theta</span><span class="p">,</span>
                  <span class="n">user_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">triplet_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">triplet_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="k">if</span> <span class="n">pretrain_iter</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">user_embed</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">pretrain_model</span><span class="o">.</span><span class="n">user_emb</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">item_embed</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">pretrain_model</span><span class="o">.</span><span class="n">item_emb</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>


<span class="n">batchGenerator</span> <span class="o">=</span> <span class="n">TripletGenerator</span><span class="p">(</span><span class="n">G_user</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">G_ui</span><span class="p">,</span> <span class="n">G_item</span><span class="p">)</span>


<span class="c1"># model.user_embed.set_weights([user_embed])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">edges</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># print(&quot;Running on iteration %d/%d:&quot;%(i, max_iter))</span>

    <span class="n">spl</span> <span class="o">=</span> <span class="n">samples</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">iter_without_att</span> <span class="k">else</span> <span class="n">samples</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">spl</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_num</span><span class="p">):</span>
            <span class="n">edge_batch</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)]</span>
            <span class="n">batch_node</span><span class="p">,</span> <span class="n">positive_batch</span><span class="p">,</span> <span class="n">negative_batch</span><span class="p">,</span> \
            <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">second_batch_data</span><span class="p">,</span> \
            <span class="n">positive_first_batch</span><span class="p">,</span> \
            <span class="n">negative_first_batch</span> <span class="o">=</span> \
                <span class="n">batchGenerator</span><span class="o">.</span><span class="n">generate_triplet_batch</span><span class="p">(</span><span class="n">edge_batch</span><span class="o">=</span><span class="n">edge_batch</span><span class="p">,</span> <span class="n">topK</span><span class="o">=</span><span class="n">topK</span><span class="p">,</span>
                                                       <span class="n">attention_sampling</span><span class="o">=</span><span class="n">i</span> <span class="o">&gt;=</span> <span class="n">iter_without_att</span><span class="p">)</span>

            <span class="n">batch_node_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">batch_node</span><span class="p">)</span>
            <span class="n">positive_batch_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">positive_batch</span><span class="p">)</span>
            <span class="n">negative_batch_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">negative_batch</span><span class="p">)</span>
            <span class="n">train_loss_temp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">triplet_model</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">batch_node_array</span><span class="p">,</span> <span class="n">first_batch_data</span><span class="p">,</span> <span class="n">second_batch_data</span><span class="p">,</span>
                   <span class="n">positive_batch_array</span><span class="p">,</span> <span class="n">positive_first_batch</span><span class="p">,</span>
                   <span class="n">negative_batch_array</span><span class="p">,</span> <span class="n">negative_first_batch</span><span class="p">],</span>
                <span class="n">y</span><span class="o">=</span><span class="n">margin</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_node</span><span class="p">),)))</span>
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">train_loss_temp</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training on batch </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> sample </span><span class="si">%d</span><span class="s2"> and iter </span><span class="si">%d</span><span class="s2"> on dataset </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_num</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data_name</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish iteration </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> with loss: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_num</span> <span class="o">*</span> <span class="n">spl</span><span class="p">)))</span>

    <span class="n">batchGenerator</span><span class="o">.</span><span class="n">clear_node_cache</span><span class="p">()</span>

    <span class="n">saveMem</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">==</span> <span class="n">max_iter</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">item_rep</span><span class="o">=</span> <span class="n">get_item_rep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">G_item</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">,</span> <span class="n">item_rep_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="n">saveMem</span><span class="p">)</span>

    <span class="c1"># user_rep = get_cold_start_user_rep(model, embed_len, test_user_list, batch_size=batch_size)</span>
    <span class="c1"># test_recommendation(user_rep, item_rep, test_path, neg_test_path)</span>

    <span class="n">user_rep</span> <span class="o">=</span> <span class="n">get_user_rep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">G_user</span><span class="p">,</span> <span class="n">embed_len</span><span class="p">,</span> <span class="n">user_rep_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="n">saveMem</span><span class="p">)</span>
    <span class="n">test_recommendation</span><span class="p">(</span><span class="n">user_rep</span><span class="p">,</span> <span class="n">item_rep</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">score_model</span><span class="p">,</span> <span class="n">test_path</span><span class="p">,</span> <span class="n">neg_test_path</span><span class="p">)</span>
    <span class="c1">#test_recommendation(item_rep, user_rep, test_path, neg_test_path)  # for cold start item</span>

<span class="c1">#</span>
<span class="c1"># from model.construct_RS_train import get_attention_graph_RS</span>
<span class="c1"># att_graph_path=&quot;./%s_att_graph.csv&quot;%data_name</span>
<span class="c1"># edge=[41,2589]</span>
<span class="c1"># get_attention_graph_RS(model, G_user, G_item, edge, topK, att_graph_path, order=2)</span>

<span class="c1"># model_save_path=&quot;./%s_model.h5&quot;%data_name</span>
<span class="c1"># model.triplet_model.save(model_save_path)</span>
<span class="c1"># print(&quot;save triplet model successfully&quot;)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: &#34;contrastive_model&#34;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
user_input (InputLayer)         (None, 1)            0                                            
__________________________________________________________________________________________________
pos_item_input (InputLayer)     (None, 1)            0                                            
__________________________________________________________________________________________________
neg_item_input (InputLayer)     (None, 1)            0                                            
__________________________________________________________________________________________________
user_embedding (Embedding)      (None, 1, 128)       242304      user_input[0][0]                 
__________________________________________________________________________________________________
item_embedding (Embedding)      (None, 1, 128)       1581952     pos_item_input[0][0]             
                                                                 neg_item_input[0][0]             
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 128)          0           user_embedding[0][0]             
                                                                 item_embedding[0][0]             
                                                                 item_embedding[1][0]             
__________________________________________________________________________________________________
score_model (Model)             (None, 1)            0           lambda_1[0][0]                   
                                                                 lambda_1[1][0]                   
                                                                 lambda_1[0][0]                   
                                                                 lambda_1[2][0]                   
__________________________________________________________________________________________________
contrastive_score (Concatenate) (None, 2)            0           score_model[1][0]                
                                                                 score_model[2][0]                
==================================================================================================
Total params: 1,824,256
Trainable params: 1,824,256
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Training on sample 1 and iter 1
Training on sample 2 and iter 1
Training on sample 3 and iter 1
Finish iteration 1/3 with loss: 18.241182
the MAP at
[0.10525066 0.0872151  0.07567542 0.068401   0.06283624 0.05824598
 0.05463924 0.05170926 0.0496745  0.04895933]
the mean recall at 
[0.0182748  0.03368914 0.04729032 0.06166572 0.0743528  0.08638901
 0.0984089  0.10993599 0.12167688 0.13167849]
the mean ndcg at
[0.15023066 0.14890209 0.14392312 0.14235024 0.13911982 0.13628249
 0.13438462 0.13275857 0.132171   0.13357852]
Training on sample 1 and iter 2
Training on sample 2 and iter 2
Training on sample 3 and iter 2
Finish iteration 2/3 with loss: 8.765345
the MAP at
[0.08685136 0.07197921 0.0628175  0.0567766  0.0524198  0.04882929
 0.04610379 0.043686   0.04215434 0.04212455]
the mean recall at 
[0.0168401  0.03020062 0.0425496  0.05502262 0.06809384 0.07972486
 0.09124271 0.10185474 0.1125887  0.12428723]
the mean ndcg at
[0.12904449 0.12753073 0.12488705 0.12343631 0.12321759 0.12169319
 0.12068633 0.1194807  0.11922531 0.12245477]
Training on sample 1 and iter 3
Training on sample 2 and iter 3
Training on sample 3 and iter 3
Finish iteration 3/3 with loss: 5.985732
the MAP at
[0.08126649 0.0675802  0.0598328  0.0548443  0.05030018 0.04711405
 0.04437393 0.04241969 0.04094197 0.04086823]
the mean recall at 
[0.01551918 0.02886323 0.0416366  0.05463804 0.06596641 0.07809979
 0.08893671 0.10060455 0.11160765 0.12215893]
the mean ndcg at
[0.11808492 0.12025033 0.12024766 0.12048602 0.11854225 0.11812849
 0.11669326 0.11661063 0.11676213 0.11934721]
Model: &#34;triplet_model&#34;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
target_input (InputLayer)       (None, 1)            0                                            
__________________________________________________________________________________________________
target_first_input (InputLayer) (None, 10)           0                                            
__________________________________________________________________________________________________
target_second_input (InputLayer (None, 10, 10)       0                                            
__________________________________________________________________________________________________
positive_input (InputLayer)     (None, 1)            0                                            
__________________________________________________________________________________________________
positive_first_input (InputLaye (None, 10)           0                                            
__________________________________________________________________________________________________
negative_input (InputLayer)     (None, 1)            0                                            
__________________________________________________________________________________________________
negative_first_input (InputLaye (None, 10)           0                                            
__________________________________________________________________________________________________
user_model (Model)              (None, 128)          291972      target_input[0][0]               
                                                                 target_first_input[0][0]         
                                                                 target_second_input[0][0]        
__________________________________________________________________________________________________
item_model (Model)              (None, 128)          1606786     positive_input[0][0]             
                                                                 positive_first_input[0][0]       
                                                                 negative_input[0][0]             
                                                                 negative_first_input[0][0]       
__________________________________________________________________________________________________
score_model (Model)             (None, 1)            0           user_model[1][0]                 
                                                                 item_model[1][0]                 
                                                                 user_model[1][0]                 
                                                                 item_model[2][0]                 
__________________________________________________________________________________________________
contrastive_score (Concatenate) (None, 2)            0           score_model[3][0]                
                                                                 score_model[4][0]                
==================================================================================================
Total params: 1,898,758
Trainable params: 1,898,758
Non-trainable params: 0
__________________________________________________________________________________________________
Training on batch 100/172 sample 1 and iter 1 on dataset lastfm
Training on batch 100/172 sample 2 and iter 1 on dataset lastfm
Training on batch 100/172 sample 3 and iter 1 on dataset lastfm
Finish iteration 1/30 with loss: 5.635064
the MAP at
[0.22272647 0.18670666 0.16461287 0.15177528 0.1401979  0.12925662
 0.1209762  0.11374372 0.10803256 0.10594346]
the mean recall at 
[0.03084107 0.06147762 0.08677184 0.11261106 0.13533306 0.15546178
 0.17478276 0.19213053 0.2077343  0.22380648]
the mean ndcg at
[0.297442   0.28639218 0.27565113 0.27016327 0.26246969 0.25434639
 0.24773193 0.24141381 0.23614692 0.23696483]
Training on batch 100/172 sample 1 and iter 2 on dataset lastfm
Training on batch 100/172 sample 2 and iter 2 on dataset lastfm
Training on batch 100/172 sample 3 and iter 2 on dataset lastfm
Finish iteration 2/30 with loss: 4.760596
the MAP at
[0.27255937 0.2214915  0.19454094 0.17665937 0.16201014 0.14929053
 0.13920971 0.13047091 0.12350605 0.12078478]
the mean recall at 
[0.03570137 0.06554486 0.09525043 0.1212082  0.14425527 0.16494801
 0.18483454 0.2039537  0.2208235  0.23820965]
the mean ndcg at
[0.34373792 0.32286684 0.30855118 0.29816215 0.28769292 0.27742483
 0.26905321 0.26214813 0.25619899 0.25651924]
Training on batch 100/172 sample 1 and iter 3 on dataset lastfm
Training on batch 100/172 sample 2 and iter 3 on dataset lastfm
Training on batch 100/172 sample 3 and iter 3 on dataset lastfm
Finish iteration 3/30 with loss: 4.170074
the MAP at
[0.25850484 0.21837637 0.19161314 0.17420808 0.15983544 0.14886259
 0.13885896 0.13045848 0.12387013 0.12106817]
the mean recall at 
[0.0347768  0.06725711 0.09320374 0.11939323 0.14213045 0.16360747
 0.18313954 0.20073852 0.21866584 0.23455916]
the mean ndcg at
[0.32949986 0.31400003 0.29867472 0.28971258 0.27982352 0.27166466
 0.26370649 0.25613718 0.25132485 0.25118102]
Training on batch 100/172 sample 1 and iter 4 on dataset lastfm
Training on batch 100/172 sample 2 and iter 4 on dataset lastfm
Training on batch 100/172 sample 3 and iter 4 on dataset lastfm
Finish iteration 4/30 with loss: 3.683889
the MAP at
[0.27147757 0.22222578 0.19223141 0.17430309 0.16066627 0.14936223
 0.14034241 0.1326905  0.12613214 0.12428094]
the mean recall at 
[0.0387941  0.06790382 0.09499372 0.1208624  0.14601645 0.16823789
 0.18969912 0.21026749 0.22825787 0.24726625]
the mean ndcg at
[0.34616364 0.32171579 0.30627825 0.2958496  0.28811596 0.27976426
 0.2729372  0.26703786 0.26152012 0.26310554]
Training on batch 100/172 sample 1 and iter 5 on dataset lastfm
Training on batch 100/172 sample 2 and iter 5 on dataset lastfm
Training on batch 100/172 sample 3 and iter 5 on dataset lastfm
Finish iteration 5/30 with loss: 3.332913
save item representation successfully
save memory successfully
the MAP at
[0.23755497 0.200826   0.17411452 0.15809933 0.14601762 0.13604498
 0.12853867 0.12246192 0.1172684  0.11549145]
the mean recall at 
[0.03456201 0.06227569 0.08672343 0.11114177 0.13400808 0.15473667
 0.17558321 0.1956089  0.21396345 0.2317678 ]
the mean ndcg at
[0.3042486  0.28998448 0.27695444 0.2691055  0.26218003 0.25516614
 0.25017115 0.24607019 0.24236405 0.24389987]
Training on batch 100/172 sample 1 and iter 6 on dataset lastfm
Training on batch 100/172 sample 2 and iter 6 on dataset lastfm
Training on batch 100/172 sample 3 and iter 6 on dataset lastfm
Finish iteration 6/30 with loss: 3.017033
the MAP at
[0.30626209 0.25481352 0.22328453 0.20141359 0.18325239 0.16898384
 0.15620385 0.14655656 0.13887434 0.13569403]
the mean recall at 
[0.04220384 0.07383557 0.10216575 0.12894536 0.15304636 0.17516488
 0.19454146 0.21364018 0.23261608 0.25069024]
the mean ndcg at
[0.37789034 0.35147161 0.33302959 0.31987234 0.30788797 0.29728847
 0.28683243 0.27880649 0.27319241 0.27346335]
Training on batch 100/172 sample 1 and iter 7 on dataset lastfm
Training on batch 100/172 sample 2 and iter 7 on dataset lastfm
Training on batch 100/172 sample 3 and iter 7 on dataset lastfm
Finish iteration 7/30 with loss: 2.761373
the MAP at
[0.28737907 0.23977164 0.21232614 0.18720858 0.17027161 0.1560692
 0.14477297 0.13582319 0.12833658 0.12551523]
the mean recall at 
[0.0398102  0.07022699 0.09873408 0.12217624 0.14644166 0.16835766
 0.18810265 0.2078854  0.2260577  0.24430567]
the mean ndcg at
[0.35974147 0.33515181 0.32088719 0.30417715 0.29399527 0.28445681
 0.27549809 0.26888653 0.26327119 0.26377186]
Training on batch 100/172 sample 1 and iter 8 on dataset lastfm
Training on batch 100/172 sample 2 and iter 8 on dataset lastfm
Training on batch 100/172 sample 3 and iter 8 on dataset lastfm
Finish iteration 8/30 with loss: 2.519779
the MAP at
[0.25593668 0.20735572 0.1817019  0.16258274 0.14947434 0.13703792
 0.12728549 0.11946924 0.11303752 0.1107409 ]
the mean recall at 
[0.03362044 0.06378493 0.08879778 0.11286946 0.13549632 0.15545845
 0.17478091 0.19265355 0.20889323 0.22536967]
the mean ndcg at
[0.32451431 0.30247467 0.28776008 0.27698124 0.26857394 0.25985634
 0.25287661 0.24679682 0.24161056 0.24225384]
Training on batch 100/172 sample 1 and iter 9 on dataset lastfm
Training on batch 100/172 sample 2 and iter 9 on dataset lastfm
Training on batch 100/172 sample 3 and iter 9 on dataset lastfm
Finish iteration 9/30 with loss: 2.351650
the MAP at
[0.25324538 0.19760031 0.17231283 0.15344305 0.13937447 0.12881417
 0.11924113 0.11143542 0.10548039 0.10282508]
the mean recall at 
[0.03372707 0.05907113 0.08629609 0.10927638 0.12903035 0.14958907
 0.16698803 0.18436671 0.20104376 0.21638212]
the mean ndcg at
[0.32711054 0.29632793 0.28280124 0.27154773 0.26036307 0.25311439
 0.24493126 0.23887481 0.23446399 0.23445968]
Training on batch 100/172 sample 1 and iter 10 on dataset lastfm
Training on batch 100/172 sample 2 and iter 10 on dataset lastfm
Training on batch 100/172 sample 3 and iter 10 on dataset lastfm
Finish iteration 10/30 with loss: 2.213068
save item representation successfully
save memory successfully
the MAP at
[0.26776605 0.21782437 0.18787246 0.16778486 0.15312793 0.14203968
 0.13228501 0.12306069 0.11654155 0.11367439]
the mean recall at 
[0.03593744 0.06472916 0.0920411  0.11557171 0.13756059 0.15920119
 0.17836887 0.19447762 0.21185864 0.22823893]
the mean ndcg at
[0.34035604 0.3154945  0.2978132  0.28517721 0.27472339 0.26721048
 0.25948749 0.25112593 0.24619955 0.24607255]
Training on batch 100/172 sample 1 and iter 11 on dataset lastfm
Training on batch 100/172 sample 2 and iter 11 on dataset lastfm
Training on batch 100/172 sample 3 and iter 11 on dataset lastfm
Finish iteration 11/30 with loss: 2.049977
the MAP at
[0.25583113 0.20507266 0.1802549  0.16081145 0.1462962  0.13534861
 0.12682628 0.11920289 0.11318884 0.11090376]
the mean recall at 
[0.03486257 0.06155943 0.09029582 0.11311628 0.13462271 0.15513749
 0.17546979 0.19428764 0.21189049 0.22895547]
the mean ndcg at
[0.33006603 0.3034149  0.29126745 0.27869606 0.26859612 0.26048915
 0.25427608 0.24863362 0.24408893 0.24462987]
Training on batch 100/172 sample 1 and iter 12 on dataset lastfm
Training on batch 100/172 sample 2 and iter 12 on dataset lastfm
Training on batch 100/172 sample 3 and iter 12 on dataset lastfm
Finish iteration 12/30 with loss: 1.940037
the MAP at
[0.25922603 0.2100511  0.18532501 0.16448848 0.14976868 0.13851862
 0.12853499 0.12086081 0.1148144  0.1131881 ]
the mean recall at 
[0.03486234 0.06197616 0.09103478 0.11338199 0.13554359 0.15644586
 0.17510304 0.19402452 0.21247467 0.23097315]
the mean ndcg at
[0.33120488 0.30498386 0.29256551 0.27894538 0.26975689 0.26189511
 0.25389984 0.24839298 0.24465479 0.24644975]
Training on batch 100/172 sample 1 and iter 13 on dataset lastfm
Training on batch 100/172 sample 2 and iter 13 on dataset lastfm
Training on batch 100/172 sample 3 and iter 13 on dataset lastfm
Finish iteration 13/30 with loss: 1.809631
the MAP at
[0.25720317 0.21096955 0.18442228 0.16627673 0.15169154 0.1393995
 0.12997507 0.12219363 0.11646076 0.1143801 ]
the mean recall at 
[0.033904   0.0620167  0.09062036 0.11501597 0.13782259 0.1579188
 0.17784078 0.19714789 0.21513915 0.23274233]
the mean ndcg at
[0.33137395 0.30835894 0.29439567 0.28380531 0.27473124 0.26517046
 0.2581782  0.25260677 0.24813933 0.24912551]
Training on batch 100/172 sample 1 and iter 14 on dataset lastfm
Training on batch 100/172 sample 2 and iter 14 on dataset lastfm
Training on batch 100/172 sample 3 and iter 14 on dataset lastfm
Finish iteration 14/30 with loss: 1.701791
the MAP at
[0.25397537 0.20204873 0.17975512 0.16304339 0.14795512 0.13680931
 0.12693788 0.11940866 0.113457   0.1111581 ]
the mean recall at 
[0.0334876  0.05986583 0.08949628 0.11357236 0.13411029 0.15488265
 0.17356544 0.19187672 0.21028328 0.22693466]
the mean ndcg at
[0.32315626 0.29762914 0.28869415 0.27855411 0.26740752 0.25949753
 0.25174072 0.24579463 0.24194455 0.24270333]
Training on batch 100/172 sample 1 and iter 15 on dataset lastfm
Training on batch 100/172 sample 2 and iter 15 on dataset lastfm
Training on batch 100/172 sample 3 and iter 15 on dataset lastfm
Finish iteration 15/30 with loss: 1.630384
save item representation successfully
save memory successfully
the MAP at
[0.2182058  0.18113509 0.16019778 0.14506571 0.13280463 0.12137789
 0.11388569 0.10751192 0.10217517 0.10111828]
the mean recall at 
[0.02967468 0.05503142 0.08118111 0.10378638 0.12433406 0.1417488
 0.16105635 0.17909831 0.19588391 0.21382027]
the mean ndcg at
[0.2855451  0.26991778 0.25986712 0.25209454 0.24425917 0.23550627
 0.23049601 0.22604128 0.22252292 0.22492766]
Training on batch 100/172 sample 1 and iter 16 on dataset lastfm
Training on batch 100/172 sample 2 and iter 16 on dataset lastfm
Training on batch 100/172 sample 3 and iter 16 on dataset lastfm
Finish iteration 16/30 with loss: 1.566339
the MAP at
[0.20591909 0.17341092 0.15532148 0.14095635 0.12978597 0.1204427
 0.11257745 0.10647815 0.10179339 0.1002338 ]
the mean recall at 
[0.02819758 0.05358144 0.07893282 0.10020005 0.12179601 0.14099291
 0.15892562 0.17652275 0.19388226 0.2104588 ]
the mean ndcg at
[0.26798143 0.25808928 0.2496284  0.24157542 0.23629948 0.23025325
 0.22456234 0.22013443 0.21733429 0.21911362]
Training on batch 100/172 sample 1 and iter 17 on dataset lastfm
Training on batch 100/172 sample 2 and iter 17 on dataset lastfm
Training on batch 100/172 sample 3 and iter 17 on dataset lastfm
Finish iteration 17/30 with loss: 1.493484
the MAP at
[0.16306069 0.13660008 0.11944043 0.10751592 0.09974598 0.09202424
 0.08637625 0.081895   0.07796739 0.0766401 ]
the mean recall at 
[0.0228597  0.04449086 0.0665177  0.08430162 0.10325818 0.11937424
 0.13494307 0.15120494 0.16521616 0.17949766]
the mean ndcg at
[0.22580028 0.21885995 0.21154837 0.20463799 0.20129841 0.1957813
 0.19131689 0.18867335 0.1856005  0.18696221]
Training on batch 100/172 sample 1 and iter 18 on dataset lastfm
Training on batch 100/172 sample 2 and iter 18 on dataset lastfm
Training on batch 100/172 sample 3 and iter 18 on dataset lastfm
Finish iteration 18/30 with loss: 1.423724
the MAP at
[0.13813544 0.11872304 0.10353435 0.09447171 0.0876722  0.08154195
 0.07724628 0.07282223 0.06946746 0.06828121]
the mean recall at 
[0.0201383  0.0431395  0.05994607 0.07727967 0.09362966 0.10893769
 0.12517866 0.13821757 0.15203621 0.16449533]
the mean ndcg at
[0.19702241 0.19635344 0.18825263 0.18405342 0.18001654 0.17621656
 0.17420998 0.1704177  0.16864232 0.16962136]
Training on batch 100/172 sample 1 and iter 19 on dataset lastfm
Training on batch 100/172 sample 2 and iter 19 on dataset lastfm
Training on batch 100/172 sample 3 and iter 19 on dataset lastfm
Finish iteration 19/30 with loss: 1.366675
the MAP at
[0.14432718 0.11400804 0.09842052 0.08892525 0.08152314 0.07550994
 0.07037349 0.06630479 0.06376948 0.0631296 ]
the mean recall at 
[0.02436324 0.04249572 0.0595887  0.07587341 0.09087383 0.10546706
 0.11948694 0.13284822 0.14776192 0.16194132]
the mean ndcg at
[0.20678944 0.19404984 0.18645651 0.18119955 0.17596929 0.17164038
 0.16807869 0.16515024 0.16459408 0.16720269]
Training on batch 100/172 sample 1 and iter 20 on dataset lastfm
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Citations">Citations<a class="anchor-link" href="#Citations"> </a></h2><p>HERS: Modeling Influential Contexts with Heterogeneous Relations for Sparse and Cold-Start Recommendation. Hu et. al.. 2019. arXiv. <a href="https://ojs.aaai.org//index.php/AAAI/article/view/4270">https://ojs.aaai.org//index.php/AAAI/article/view/4270</a></p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/2022/01/23/hers.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Jupyter notebook database.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/recohut" target="_blank" title="recohut"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>

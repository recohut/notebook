<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>STOSA | reconb</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="STOSA" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Jupyter notebook database." />
<meta property="og:description" content="Jupyter notebook database." />
<link rel="canonical" href="https://nb.recohut.com/2022/01/15/stosa.html" />
<meta property="og:url" content="https://nb.recohut.com/2022/01/15/stosa.html" />
<meta property="og:site_name" content="reconb" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-15T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="STOSA" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-01-15T00:00:00-06:00","datePublished":"2022-01-15T00:00:00-06:00","description":"Jupyter notebook database.","headline":"STOSA","mainEntityOfPage":{"@type":"WebPage","@id":"https://nb.recohut.com/2022/01/15/stosa.html"},"url":"https://nb.recohut.com/2022/01/15/stosa.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nb.recohut.com/feed.xml" title="reconb" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">reconb</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">STOSA</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-15T00:00:00-06:00" itemprop="datePublished">
        Jan 15, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      59 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/recohut/notebook/tree/master/_notebooks/2022-01-15-stosa.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/recohut/notebook/master?filepath=_notebooks%2F2022-01-15-stosa.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/recohut/notebook/blob/master/_notebooks/2022-01-15-stosa.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frecohut%2Fnotebook%2Fblob%2Fmaster%2F_notebooks%2F2022-01-15-stosa.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-15-stosa.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Utils">Utils<a class="anchor-link" href="#Utils"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PYTHONHASHSEED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="c1"># some cudnn methods can be random even after fixing the seed</span>
    <span class="c1"># unless you tell it to be deterministic</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># REPLACE WITH from recohut.utils.common_utils import seed_everything</span>

<span class="k">def</span> <span class="nf">random_neg_sample</span><span class="p">(</span><span class="n">item_set</span><span class="p">,</span> <span class="n">item_size</span><span class="p">):</span>
    <span class="n">item</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">item_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_set</span><span class="p">:</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">item_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">item</span>

<span class="c1"># REPLACE WITH from recohut.utils.negative_sampling import random_neg_sample</span>

<span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Early stops the training if validation loss doesn&#39;t improve after a given patience.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            patience (int): How long to wait after last time validation loss improved.</span>
<span class="sd">                            Default: 7</span>
<span class="sd">            verbose (bool): If True, prints a message for each validation loss improvement.</span>
<span class="sd">                            Default: False</span>
<span class="sd">            delta (float): Minimum change in the monitored quantity to qualify as an improvement.</span>
<span class="sd">                            Default: 0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">checkpoint_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>

    <span class="k">def</span> <span class="nf">compare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">score</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="c1"># score HIT@10 NDCG@10</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">score_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">score</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;EarlyStopping counter: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Saves model when validation loss decrease.&#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Validation score increased.  Saving model ...&#39;</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score_min</span> <span class="o">=</span> <span class="n">score</span>

<span class="c1"># CHECK IF CAN BE REPLACE WITH from pytorch_lightning.callbacks.early_stopping import EarlyStopping</span>
<span class="c1"># https://pytorch-lightning.readthedocs.io/en/latest/common/early_stopping.html</span>

<span class="k">def</span> <span class="nf">kmax_pooling</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.utils.pooling import kmax_pooling</span>

<span class="k">def</span> <span class="nf">avg_pooling</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span><span class="o">/</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.utils.pooling import avg_pooling</span>

<span class="c1"># def generate_rating_matrix_valid(user_seq, num_users, num_items):</span>
<span class="c1">#     # three lists are used to construct sparse matrix</span>
<span class="c1">#     row = []</span>
<span class="c1">#     col = []</span>
<span class="c1">#     data = []</span>
<span class="c1">#     for user_id, item_list in enumerate(user_seq):</span>
<span class="c1">#         for item in item_list[:-2]: #</span>
<span class="c1">#             row.append(user_id)</span>
<span class="c1">#             col.append(item)</span>
<span class="c1">#             data.append(1)</span>

<span class="c1">#     row = np.array(row)</span>
<span class="c1">#     col = np.array(col)</span>
<span class="c1">#     data = np.array(data)</span>
<span class="c1">#     rating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))</span>

<span class="c1">#     return rating_matrix</span>

<span class="c1"># def generate_rating_matrix_test(user_seq, num_users, num_items):</span>
<span class="c1">#     # three lists are used to construct sparse matrix</span>
<span class="c1">#     row = []</span>
<span class="c1">#     col = []</span>
<span class="c1">#     data = []</span>
<span class="c1">#     for user_id, item_list in enumerate(user_seq):</span>
<span class="c1">#         for item in item_list[:-1]: #</span>
<span class="c1">#             row.append(user_id)</span>
<span class="c1">#             col.append(item)</span>
<span class="c1">#             data.append(1)</span>

<span class="c1">#     row = np.array(row)</span>
<span class="c1">#     col = np.array(col)</span>
<span class="c1">#     data = np.array(data)</span>
<span class="c1">#     rating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))</span>

<span class="c1">#     return rating_matrix</span>

<span class="k">def</span> <span class="nf">generate_rating_matrix</span><span class="p">(</span><span class="n">user_seq</span><span class="p">,</span> <span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">row</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">col</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">item_list</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">user_seq</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span><span class="p">[:</span><span class="o">-</span><span class="n">n</span><span class="p">]:</span> <span class="c1">#</span>
            <span class="n">row</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span>
            <span class="n">col</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">rating_matrix</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">rating_matrix</span>

<span class="c1"># REPLACE WITH from recohut.transforms.matrix import generate_rating_matrix</span>

<span class="k">def</span> <span class="nf">get_user_seqs</span><span class="p">(</span><span class="n">data_file</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">user_seq</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">item_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">user</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">]</span>
        <span class="n">user_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
        <span class="n">item_set</span> <span class="o">=</span> <span class="n">item_set</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="n">max_item</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">item_set</span><span class="p">)</span>

    <span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
    <span class="n">num_items</span> <span class="o">=</span> <span class="n">max_item</span> <span class="o">+</span> <span class="mi">2</span>

    <span class="n">valid_rating_matrix</span> <span class="o">=</span> <span class="n">generate_rating_matrix</span><span class="p">(</span><span class="n">user_seq</span><span class="p">,</span> <span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">test_rating_matrix</span> <span class="o">=</span> <span class="n">generate_rating_matrix</span><span class="p">(</span><span class="n">user_seq</span><span class="p">,</span> <span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">max_item</span><span class="p">,</span> <span class="n">valid_rating_matrix</span><span class="p">,</span> <span class="n">test_rating_matrix</span><span class="p">,</span> <span class="n">num_users</span>

<span class="k">def</span> <span class="nf">get_user_seqs_long</span><span class="p">(</span><span class="n">data_file</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">user_seq</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">long_sequence</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">item_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">user</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">]</span>
        <span class="n">long_sequence</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="c1">#</span>
        <span class="n">user_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
        <span class="n">item_set</span> <span class="o">=</span> <span class="n">item_set</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="n">max_item</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">item_set</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">max_item</span><span class="p">,</span> <span class="n">long_sequence</span>

<span class="k">def</span> <span class="nf">get_user_seqs_and_sample</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">sample_file</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">user_seq</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">item_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">user</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">]</span>
        <span class="n">user_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
        <span class="n">item_set</span> <span class="o">=</span> <span class="n">item_set</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="n">max_item</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">item_set</span><span class="p">)</span>

    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">sample_file</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">sample_seq</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">user</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">]</span>
        <span class="n">sample_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">user_seq</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_seq</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">max_item</span><span class="p">,</span> <span class="n">sample_seq</span>

<span class="k">def</span> <span class="nf">get_item2attribute_json</span><span class="p">(</span><span class="n">data_file</span><span class="p">):</span>
    <span class="n">item2attribute</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span><span class="o">.</span><span class="n">readline</span><span class="p">())</span>
    <span class="n">attribute_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">item</span><span class="p">,</span> <span class="n">attributes</span> <span class="ow">in</span> <span class="n">item2attribute</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">attribute_set</span> <span class="o">=</span> <span class="n">attribute_set</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">attributes</span><span class="p">)</span>
    <span class="n">attribute_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">attribute_set</span><span class="p">)</span> <span class="c1"># 331</span>
    <span class="k">return</span> <span class="n">item2attribute</span><span class="p">,</span> <span class="n">attribute_size</span>

<span class="k">def</span> <span class="nf">get_eval_metrics_v2</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">NDCG</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">HIT</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">MRR</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># [batch] the answer&#39;s rank</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">pred_list</span><span class="p">:</span>
        <span class="n">MRR</span> <span class="o">+=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">topk</span><span class="p">:</span>
            <span class="n">NDCG</span> <span class="o">+=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mf">2.0</span><span class="p">)</span>
            <span class="n">HIT</span> <span class="o">+=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">HIT</span> <span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_list</span><span class="p">),</span> <span class="n">NDCG</span> <span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_list</span><span class="p">),</span> <span class="n">MRR</span> <span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_list</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import get_eval_metrics_v2</span>

<span class="k">def</span> <span class="nf">precision_at_k_per_sample</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="n">num_hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">place</span> <span class="ow">in</span> <span class="n">predicted</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">place</span> <span class="ow">in</span> <span class="n">actual</span><span class="p">:</span>
            <span class="n">num_hits</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">num_hits</span> <span class="o">/</span> <span class="p">(</span><span class="n">topk</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import precision_at_k_per_sample</span>

<span class="k">def</span> <span class="nf">precision_at_k</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="n">sum_precision</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_users</span><span class="p">):</span>
        <span class="n">act_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">pred_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">topk</span><span class="p">])</span>
        <span class="n">sum_precision</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">act_set</span> <span class="o">&amp;</span> <span class="n">pred_set</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">topk</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sum_precision</span> <span class="o">/</span> <span class="n">num_users</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import precision_at_k</span>

<span class="k">def</span> <span class="nf">recall_at_k</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="n">sum_recall</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="n">true_users</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">recall_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_users</span><span class="p">):</span>
        <span class="n">act_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">pred_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">topk</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">act_set</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1">#sum_recall += len(act_set &amp; pred_set) / float(len(act_set))</span>
            <span class="n">one_user_recall</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">act_set</span> <span class="o">&amp;</span> <span class="n">pred_set</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">act_set</span><span class="p">))</span>
            <span class="n">recall_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">one_user_recall</span>
            <span class="n">sum_recall</span> <span class="o">+=</span> <span class="n">one_user_recall</span>
            <span class="n">true_users</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">sum_recall</span> <span class="o">/</span> <span class="n">true_users</span><span class="p">,</span> <span class="n">recall_dict</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import recall_at_k</span>

<span class="k">def</span> <span class="nf">cal_mrr</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    <span class="n">sum_mrr</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">true_users</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="n">mrr_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_users</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">act_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">pred_list</span> <span class="o">=</span> <span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">pred_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">act_set</span><span class="p">:</span>
                <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1">#sum_mrr += np.reciprocal(np.where(r==1)[0]+1, dtype=np.float)[0]</span>
            <span class="n">one_user_mrr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">r</span><span class="o">==</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sum_mrr</span> <span class="o">+=</span> <span class="n">one_user_mrr</span>
            <span class="n">true_users</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">mrr_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">one_user_mrr</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mrr_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">return</span> <span class="n">sum_mrr</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">),</span> <span class="n">mrr_dict</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import cal_mrr</span>

<span class="k">def</span> <span class="nf">ap_at_k</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the average precision at k.</span>
<span class="sd">    This function computes the average precision at k between two lists of</span>
<span class="sd">    items.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    actual : list</span>
<span class="sd">             A list of elements that are to be predicted (order doesn&#39;t matter)</span>
<span class="sd">    predicted : list</span>
<span class="sd">                A list of predicted elements (order does matter)</span>
<span class="sd">    k : int, optional</span>
<span class="sd">        The maximum number of predicted elements</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : double</span>
<span class="sd">            The average precision at k over the input lists</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span><span class="o">&gt;</span><span class="n">k</span><span class="p">:</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>

    <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">num_hits</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predicted</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">actual</span> <span class="ow">and</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">predicted</span><span class="p">[:</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">num_hits</span> <span class="o">+=</span> <span class="mf">1.0</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="n">num_hits</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">actual</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">score</span> <span class="o">/</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import ap_at_k</span>

<span class="k">def</span> <span class="nf">map_at_k</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the mean average precision at k.</span>
<span class="sd">    This function computes the mean average prescision at k between two lists</span>
<span class="sd">    of lists of items.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    actual : list</span>
<span class="sd">             A list of lists of elements that are to be predicted</span>
<span class="sd">             (order doesn&#39;t matter in the lists)</span>
<span class="sd">    predicted : list</span>
<span class="sd">                A list of lists of predicted elements</span>
<span class="sd">                (order matters in the lists)</span>
<span class="sd">    k : int, optional</span>
<span class="sd">        The maximum number of predicted elements</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : double</span>
<span class="sd">            The mean average precision at k over the input lists</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">ap_at_k</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)])</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import map_at_k</span>

<span class="c1"># def idcg_at_k(k):</span>
<span class="c1">#     &quot;&quot;&quot;Calculates the ideal discounted cumulative gain at k.&quot;&quot;&quot;</span>
<span class="c1">#     res = sum([1.0/math.log(i+2, 2) for i in range(k)])</span>
<span class="c1">#     if not res:</span>
<span class="c1">#         return 1.0</span>
<span class="c1">#     else:</span>
<span class="c1">#         return res</span>

<span class="k">def</span> <span class="nf">ndcg_at_k</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ndcg_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">user_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)):</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">topk</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="n">user_id</span><span class="p">]))</span>
        <span class="c1"># idcg = idcg_at_k(k)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mf">1.0</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)])</span>
        <span class="n">idcg</span> <span class="o">=</span> <span class="n">res</span> <span class="k">if</span> <span class="n">res</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="n">dcg_k</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="n">user_id</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="ow">in</span>
                         <span class="nb">set</span><span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="n">user_id</span><span class="p">]))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">topk</span><span class="p">)])</span>
        <span class="n">res</span> <span class="o">+=</span> <span class="n">dcg_k</span> <span class="o">/</span> <span class="n">idcg</span>
        <span class="n">ndcg_dict</span><span class="p">[</span><span class="n">user_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">dcg_k</span> <span class="o">/</span> <span class="n">idcg</span>
    <span class="k">return</span> <span class="n">res</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">actual</span><span class="p">)),</span> <span class="n">ndcg_dict</span>

<span class="c1"># REPLACE WITH from recohut.evaluation.metrics import ndcg_at_k</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Datasets">Datasets<a class="anchor-link" href="#Datasets"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">PretrainDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">long_sequence</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_seq</span> <span class="o">=</span> <span class="n">user_seq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">long_sequence</span> <span class="o">=</span> <span class="n">long_sequence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">part_sequence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split_sequence</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">split_sequence</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_seq</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">seq</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># keeping same as train set</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">part_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">part_sequence</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>

        <span class="n">sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">part_sequence</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="c1"># pos_items</span>
        <span class="c1"># sample neg item for every masked item</span>
        <span class="n">masked_item_sequence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">neg_items</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Masked Item Prediction</span>
        <span class="n">item_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_p</span><span class="p">:</span>
                <span class="n">masked_item_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">)</span>
                <span class="n">neg_items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_neg_sample</span><span class="p">(</span><span class="n">item_set</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">masked_item_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                <span class="n">neg_items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="c1"># add mask at the last position</span>
        <span class="n">masked_item_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">)</span>
        <span class="n">neg_items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_neg_sample</span><span class="p">(</span><span class="n">item_set</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">))</span>

        <span class="c1"># Segment Prediction</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">masked_segment_sequence</span> <span class="o">=</span> <span class="n">sequence</span>
            <span class="n">pos_segment</span> <span class="o">=</span> <span class="n">sequence</span>
            <span class="n">neg_segment</span> <span class="o">=</span> <span class="n">sequence</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sample_length</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">start_id</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">-</span> <span class="n">sample_length</span><span class="p">)</span>
            <span class="n">neg_start_id</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">long_sequence</span><span class="p">)</span> <span class="o">-</span> <span class="n">sample_length</span><span class="p">)</span>
            <span class="n">pos_segment</span> <span class="o">=</span> <span class="n">sequence</span><span class="p">[</span><span class="n">start_id</span><span class="p">:</span> <span class="n">start_id</span> <span class="o">+</span> <span class="n">sample_length</span><span class="p">]</span>
            <span class="n">neg_segment</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">long_sequence</span><span class="p">[</span><span class="n">neg_start_id</span><span class="p">:</span><span class="n">neg_start_id</span> <span class="o">+</span> <span class="n">sample_length</span><span class="p">]</span>
            <span class="n">masked_segment_sequence</span> <span class="o">=</span> <span class="n">sequence</span><span class="p">[:</span><span class="n">start_id</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample_length</span> <span class="o">+</span> <span class="n">sequence</span><span class="p">[</span>
                                                                                      <span class="n">start_id</span> <span class="o">+</span> <span class="n">sample_length</span><span class="p">:]</span>
            <span class="n">pos_segment</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">]</span> <span class="o">*</span> <span class="n">start_id</span> <span class="o">+</span> <span class="n">pos_segment</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">start_id</span> <span class="o">+</span> <span class="n">sample_length</span><span class="p">))</span>
            <span class="n">neg_segment</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">]</span> <span class="o">*</span> <span class="n">start_id</span> <span class="o">+</span> <span class="n">neg_segment</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">start_id</span> <span class="o">+</span> <span class="n">sample_length</span><span class="p">))</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">masked_segment_sequence</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pos_segment</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_segment</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>

        <span class="c1"># padding sequence</span>
        <span class="n">pad_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">masked_item_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span> <span class="o">+</span> <span class="n">masked_item_sequence</span>
        <span class="n">pos_items</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span> <span class="o">+</span> <span class="n">sequence</span>
        <span class="n">neg_items</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span> <span class="o">+</span> <span class="n">neg_items</span>
        <span class="n">masked_segment_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">pad_len</span> <span class="o">+</span> <span class="n">masked_segment_sequence</span>
        <span class="n">pos_segment</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">pad_len</span> <span class="o">+</span> <span class="n">pos_segment</span>
        <span class="n">neg_segment</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">pad_len</span> <span class="o">+</span> <span class="n">neg_segment</span>

        <span class="n">masked_item_sequence</span> <span class="o">=</span> <span class="n">masked_item_sequence</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>
        <span class="n">pos_items</span> <span class="o">=</span> <span class="n">pos_items</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>
        <span class="n">neg_items</span> <span class="o">=</span> <span class="n">neg_items</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>

        <span class="n">masked_segment_sequence</span> <span class="o">=</span> <span class="n">masked_segment_sequence</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>
        <span class="n">pos_segment</span> <span class="o">=</span> <span class="n">pos_segment</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>
        <span class="n">neg_segment</span> <span class="o">=</span> <span class="n">neg_segment</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>

        <span class="c1"># Associated Attribute Prediction</span>
        <span class="c1"># Masked Attribute Prediction</span>
        <span class="n">attributes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">pos_items</span><span class="p">:</span>
            <span class="n">attribute</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">attribute_size</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">now_attribute</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">item2attribute</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)]</span>
                <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">now_attribute</span><span class="p">:</span>
                    <span class="n">attribute</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="n">attributes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attribute</span><span class="p">)</span>


        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">attributes</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">masked_item_sequence</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pos_items</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_items</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">masked_segment_sequence</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pos_segment</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_segment</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>


        <span class="n">cur_tensors</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">attributes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">masked_item_sequence</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">pos_items</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">neg_items</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">masked_segment_sequence</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">pos_segment</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">neg_segment</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),)</span>
        <span class="k">return</span> <span class="n">cur_tensors</span>

<span class="k">class</span> <span class="nc">SASRecDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">test_neg_items</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_seq</span> <span class="o">=</span> <span class="n">user_seq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_neg_items</span> <span class="o">=</span> <span class="n">test_neg_items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_type</span> <span class="o">=</span> <span class="n">data_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>

        <span class="n">user_id</span> <span class="o">=</span> <span class="n">index</span>
        <span class="n">items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_seq</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_type</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">}</span>

        <span class="c1"># [0, 1, 2, 3, 4, 5, 6]</span>
        <span class="c1"># train [0, 1, 2, 3]</span>
        <span class="c1"># target [1, 2, 3, 4]</span>

        <span class="c1"># valid [0, 1, 2, 3, 4]</span>
        <span class="c1"># answer [5]</span>

        <span class="c1"># test [0, 1, 2, 3, 4, 5]</span>
        <span class="c1"># answer [6]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">items</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span>
            <span class="n">target_pos</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">answer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># no use</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="s1">&#39;valid&#39;</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">items</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">target_pos</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">answer</span> <span class="o">=</span> <span class="p">[</span><span class="n">items</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">items</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">target_pos</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="n">answer</span> <span class="o">=</span> <span class="p">[</span><span class="n">items</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>

        <span class="n">target_neg</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">seq_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">:</span>
            <span class="n">target_neg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_neg_sample</span><span class="p">(</span><span class="n">seq_set</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">))</span>

        <span class="n">pad_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span> <span class="o">+</span> <span class="n">input_ids</span>
        <span class="n">target_pos</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span> <span class="o">+</span> <span class="n">target_pos</span>
        <span class="n">target_neg</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_len</span> <span class="o">+</span> <span class="n">target_neg</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>
        <span class="n">target_pos</span> <span class="o">=</span> <span class="n">target_pos</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>
        <span class="n">target_neg</span> <span class="o">=</span> <span class="n">target_neg</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">:]</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_pos</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_neg</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_neg_items</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">test_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_neg_items</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="n">cur_tensors</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span> <span class="c1"># user_id for testing</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_pos</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_neg</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cur_tensors</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>  <span class="c1"># user_id for testing</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_pos</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_neg</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">cur_tensors</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_seq</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.datasets.bases.sequential import SASRecDataset, SASRecDataModule</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Modules">Modules<a class="anchor-link" href="#Modules"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">GELU</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implementation of the GELU activation function.</span>
<span class="sd">        For information: OpenAI GPT&#39;s GELU is slightly different</span>
<span class="sd">        (and gives slightly different results):</span>
<span class="sd">        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) *</span>
<span class="sd">        (x + 0.044715 * torch.pow(x, 3))))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)))</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.activation import GELU</span>

<span class="k">def</span> <span class="nf">swish</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.activation import swish</span>

<span class="k">def</span> <span class="nf">wasserstein_distance</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">):</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">mean1</span> <span class="o">-</span> <span class="n">mean2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean1</span> <span class="o">-</span> <span class="n">mean2</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">cov1_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cov1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-24</span><span class="p">))</span> 
    <span class="n">cov2_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cov2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-24</span><span class="p">))</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">cov1_sqrt</span> <span class="o">-</span> <span class="n">cov2_sqrt</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">cov1_sqrt</span> <span class="o">-</span> <span class="n">cov2_sqrt</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ret</span>

<span class="c1"># REPLACE WITH from recohut.utils.stats import wasserstein_distance</span>

<span class="k">def</span> <span class="nf">wasserstein_distance_matmul</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">):</span>
    <span class="n">mean1_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mean1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">mean2_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mean2</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="n">mean1_2</span> <span class="o">+</span> <span class="n">mean2_2</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1">#ret = torch.clamp(-2 * torch.matmul(mean1, mean2.transpose(-1, -2)) + mean1_2 + mean2_2.transpose(-1, -2), min=1e-24)</span>
    <span class="c1">#ret = torch.sqrt(ret)</span>

    <span class="n">cov1_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cov1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">cov2_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cov2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1">#cov_ret = torch.clamp(-2 * torch.matmul(torch.sqrt(torch.clamp(cov1, min=1e-24)), torch.sqrt(torch.clamp(cov2, min=1e-24)).transpose(-1, -2)) + cov1_2 + cov2_2.transpose(-1, -2), min=1e-24)</span>
    <span class="c1">#cov_ret = torch.sqrt(cov_ret)</span>
    <span class="n">cov_ret</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cov1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-24</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">cov2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-24</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="n">cov1_2</span> <span class="o">+</span> <span class="n">cov2_2</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ret</span> <span class="o">+</span> <span class="n">cov_ret</span>

<span class="c1"># REPLACE WITH from recohut.utils.stats import wasserstein_distance_matmul</span>

<span class="k">def</span> <span class="nf">kl_distance</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">):</span>
    <span class="n">trace_part</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cov1</span> <span class="o">/</span> <span class="n">cov2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mean_cov_part</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">mean2</span> <span class="o">-</span> <span class="n">mean1</span><span class="p">)</span> <span class="o">/</span> <span class="n">cov2</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean2</span> <span class="o">-</span> <span class="n">mean1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">determinant_part</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">cov2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">cov1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">trace_part</span> <span class="o">+</span> <span class="n">mean_cov_part</span> <span class="o">-</span> <span class="n">mean1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">determinant_part</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

<span class="c1"># REPLACE WITH from recohut.utils.stats import kl_distance</span>

<span class="k">def</span> <span class="nf">kl_distance_matmul</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">):</span>
    <span class="n">cov1_det</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">cov1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">cov2_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">cov2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">log_det</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cov1_det</span><span class="p">,</span> <span class="n">cov2_det</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)))</span>

    <span class="n">trace_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">cov2</span><span class="p">,</span> <span class="n">cov1</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1">#mean_cov_part1 = torch.matmul(mean1 / cov2, mean1.transpose(-1, -2))</span>
    <span class="c1">#mean_cov_part1 = torch.matmul(mean1 * mean1, (1 / cov2).transpose(-1, -2))</span>
    <span class="c1">#mean_cov_part2 = -torch.matmul(mean1 / cov2, mean2.transpose(-1, -2))</span>
    <span class="c1">#mean_cov_part2 = -torch.matmul(mean1 * mean2, (1 / cov2).transpose(-1, -2))</span>
    <span class="c1">#mean_cov_part3 = -torch.matmul(mean2 / cov2, mean1.transpose(-1, -2))</span>
    <span class="c1">#mean_cov_part4 = torch.matmul(mean2 / cov2, mean2.transpose(-1, -2))</span>
    <span class="c1">#mean_cov_part4 = torch.matmul(mean2 * mean2, (1 / cov2).transpose(-1, -2))</span>

    <span class="c1">#mean_cov_part = mean_cov_part1 + mean_cov_part2 + mean_cov_part3 + mean_cov_part4</span>
    <span class="n">mean_cov_part</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">((</span><span class="n">mean1</span> <span class="o">-</span> <span class="n">mean2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">cov2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">log_det</span> <span class="o">+</span> <span class="n">mean_cov_part</span> <span class="o">+</span> <span class="n">trace_sum</span> <span class="o">-</span> <span class="n">mean1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>

<span class="c1"># REPLACE WITH from recohut.utils.stats import kl_distance_matmul</span>

<span class="k">def</span> <span class="nf">d2s_gaussiannormal</span><span class="p">(</span><span class="n">distance</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span><span class="o">*</span><span class="n">distance</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">d2s_1overx</span><span class="p">(</span><span class="n">distance</span><span class="p">):</span>

    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">distance</span><span class="p">)</span>


<span class="n">ACT2FN</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;GELU&quot;</span><span class="p">:</span> <span class="n">GELU</span><span class="p">,</span> <span class="s2">&quot;relu&quot;</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="s2">&quot;swish&quot;</span><span class="p">:</span> <span class="n">swish</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a layernorm module in the TF style (epsilon inside the square root).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variance_epsilon</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">variance_epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.common import LayerNorm</span>

<span class="k">class</span> <span class="nc">ItemPosEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct the embeddings from item, position.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">):</span>
        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">items_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">items_embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeddings</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.common import ItemPosEmbedding</span>

<span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The hidden size (</span><span class="si">%d</span><span class="s2">) is not a multiple of the number of attention &quot;</span>
                <span class="s2">&quot;heads (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">new_x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_x_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">mixed_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">mixed_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">mixed_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

        <span class="n">query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_query_layer</span><span class="p">)</span>
        <span class="n">key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_key_layer</span><span class="p">)</span>
        <span class="n">value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_value_layer</span><span class="p">)</span>

        <span class="c1"># Take the dot product between &quot;query&quot; and &quot;key&quot; to get the raw attention scores.</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_layer</span><span class="p">,</span> <span class="n">key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>

        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="c1"># Apply the attention mask is (precomputed for all layers in BertModel forward() function)</span>
        <span class="c1"># [batch_size heads seq_len seq_len] scores</span>
        <span class="c1"># [batch_size 1 1 seq_len]</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">+</span> <span class="n">attention_mask</span>

        <span class="c1"># Normalize the attention scores to probabilities.</span>
        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">attention_scores</span><span class="p">)</span>
        <span class="c1"># This is actually dropping out entire tokens to attend to, which might</span>
        <span class="c1"># seem a bit unusual, but is taken from the original Transformer paper.</span>
        <span class="c1"># Fixme</span>
        <span class="n">attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">)</span>
        <span class="n">context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">)</span>
        <span class="n">context_layer</span> <span class="o">=</span> <span class="n">context_layer</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">new_context_layer_shape</span> <span class="o">=</span> <span class="n">context_layer</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">,)</span>
        <span class="n">context_layer</span> <span class="o">=</span> <span class="n">context_layer</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_context_layer_shape</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">context_layer</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_states</span> <span class="o">+</span> <span class="n">input_tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_probs</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.common import SelfAttention</span>

<span class="k">class</span> <span class="nc">DistSelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistSelfAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The hidden size (</span><span class="si">%d</span><span class="s2">) is not a multiple of the number of attention &quot;</span>
                <span class="s2">&quot;heads (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">distance_metric</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">distance_metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">kernel_param</span>


    <span class="k">def</span> <span class="nf">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">new_x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_x_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_mean_tensor</span><span class="p">,</span> <span class="n">input_cov_tensor</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">mixed_mean_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_query</span><span class="p">(</span><span class="n">input_mean_tensor</span><span class="p">)</span>
        <span class="n">mixed_mean_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_key</span><span class="p">(</span><span class="n">input_mean_tensor</span><span class="p">)</span>
        <span class="n">mixed_mean_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_value</span><span class="p">(</span><span class="n">input_mean_tensor</span><span class="p">)</span>

        <span class="n">mean_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_mean_query_layer</span><span class="p">)</span>
        <span class="n">mean_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_mean_key_layer</span><span class="p">)</span>
        <span class="n">mean_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_mean_value_layer</span><span class="p">)</span>

        <span class="n">mixed_cov_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_query</span><span class="p">(</span><span class="n">input_cov_tensor</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">mixed_cov_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_key</span><span class="p">(</span><span class="n">input_cov_tensor</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">mixed_cov_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_value</span><span class="p">(</span><span class="n">input_cov_tensor</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">cov_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_cov_query_layer</span><span class="p">)</span>
        <span class="n">cov_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_cov_key_layer</span><span class="p">)</span>
        <span class="n">cov_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_cov_value_layer</span><span class="p">)</span>

        <span class="c1">#if self.distance_metric == &#39;wasserstein&#39;:</span>
        <span class="c1">#    attention_scores = d2s_gaussiannormal(wasserstein_distance(mean_query_layer, cov_query_layer, mean_key_layer, cov_key_layer))</span>
        <span class="c1">#else:</span>
        <span class="c1">#    attention_scores = d2s_gaussiannormal(kl_distance(mean_query_layer, cov_query_layer, mean_key_layer, cov_key_layer))</span>
        <span class="c1">#attention_scores = d2s_gaussiannormal(wasserstein_distance_matmul(mean_query_layer, cov_query_layer, mean_key_layer, cov_key_layer))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance_metric</span> <span class="o">==</span> <span class="s1">&#39;wasserstein&#39;</span><span class="p">:</span>
            <span class="c1">#attention_scores = d2s_gaussiannormal(wasserstein_distance_matmul(mean_query_layer, cov_query_layer, mean_key_layer, cov_key_layer), self.gamma)</span>
            <span class="n">attention_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">wasserstein_distance_matmul</span><span class="p">(</span><span class="n">mean_query_layer</span><span class="p">,</span> <span class="n">cov_query_layer</span><span class="p">,</span> <span class="n">mean_key_layer</span><span class="p">,</span> <span class="n">cov_key_layer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_scores</span> <span class="o">=</span> <span class="o">-</span><span class="n">kl_distance_matmul</span><span class="p">(</span><span class="n">mean_query_layer</span><span class="p">,</span> <span class="n">cov_query_layer</span><span class="p">,</span> <span class="n">mean_key_layer</span><span class="p">,</span> <span class="n">cov_key_layer</span><span class="p">)</span>

        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">+</span> <span class="n">attention_mask</span>
        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">attention_scores</span><span class="p">)</span>

        <span class="n">attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">)</span>
        <span class="n">mean_context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">mean_value_layer</span><span class="p">)</span>
        <span class="n">cov_context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cov_value_layer</span><span class="p">)</span>
        <span class="n">mean_context_layer</span> <span class="o">=</span> <span class="n">mean_context_layer</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">cov_context_layer</span> <span class="o">=</span> <span class="n">cov_context_layer</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">new_context_layer_shape</span> <span class="o">=</span> <span class="n">mean_context_layer</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">,)</span>

        <span class="n">mean_context_layer</span> <span class="o">=</span> <span class="n">mean_context_layer</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_context_layer_shape</span><span class="p">)</span>
        <span class="n">cov_context_layer</span> <span class="o">=</span> <span class="n">cov_context_layer</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_context_layer_shape</span><span class="p">)</span>

        <span class="n">mean_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_dense</span><span class="p">(</span><span class="n">mean_context_layer</span><span class="p">)</span>
        <span class="n">mean_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span><span class="p">(</span><span class="n">mean_hidden_states</span><span class="p">)</span>
        <span class="n">mean_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">mean_hidden_states</span> <span class="o">+</span> <span class="n">input_mean_tensor</span><span class="p">)</span>

        <span class="n">cov_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_dense</span><span class="p">(</span><span class="n">cov_context_layer</span><span class="p">)</span>
        <span class="n">cov_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span><span class="p">(</span><span class="n">cov_hidden_states</span><span class="p">)</span>
        <span class="n">cov_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">cov_hidden_states</span> <span class="o">+</span> <span class="n">input_cov_tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_probs</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.common import DistSelfAttention</span>

<span class="k">class</span> <span class="nc">DistMeanSelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistMeanSelfAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The hidden size (</span><span class="si">%d</span><span class="s2">) is not a multiple of the number of attention &quot;</span>
                <span class="s2">&quot;heads (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">new_x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_x_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_mean_tensor</span><span class="p">,</span> <span class="n">input_cov_tensor</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">mixed_mean_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_query</span><span class="p">(</span><span class="n">input_mean_tensor</span><span class="p">)</span>
        <span class="n">mixed_mean_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_key</span><span class="p">(</span><span class="n">input_mean_tensor</span><span class="p">)</span>
        <span class="n">mixed_mean_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_value</span><span class="p">(</span><span class="n">input_mean_tensor</span><span class="p">)</span>

        <span class="n">mean_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_mean_query_layer</span><span class="p">)</span>
        <span class="n">mean_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_mean_key_layer</span><span class="p">)</span>
        <span class="n">mean_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_mean_value_layer</span><span class="p">)</span>

        <span class="n">mixed_cov_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_query</span><span class="p">(</span><span class="n">input_cov_tensor</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">mixed_cov_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_key</span><span class="p">(</span><span class="n">input_cov_tensor</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">mixed_cov_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_value</span><span class="p">(</span><span class="n">input_cov_tensor</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">cov_query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_cov_query_layer</span><span class="p">)</span>
        <span class="n">cov_key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_cov_key_layer</span><span class="p">)</span>
        <span class="n">cov_value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_cov_value_layer</span><span class="p">)</span>

        <span class="n">mean_attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mean_query_layer</span><span class="p">,</span> <span class="n">mean_key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">cov_attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cov_query_layer</span><span class="p">,</span> <span class="n">cov_key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>

        <span class="n">mean_attention_scores</span> <span class="o">=</span> <span class="n">mean_attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="n">mean_attention_scores</span> <span class="o">=</span> <span class="n">mean_attention_scores</span> <span class="o">+</span> <span class="n">attention_mask</span>
        <span class="n">mean_attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">mean_attention_scores</span><span class="p">)</span>

        <span class="n">cov_attention_scores</span> <span class="o">=</span> <span class="n">cov_attention_scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">)</span>
        <span class="n">cov_attention_scores</span> <span class="o">=</span> <span class="n">cov_attention_scores</span> <span class="o">+</span> <span class="n">attention_mask</span>
        <span class="n">cov_attention_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">cov_attention_scores</span><span class="p">)</span>

        <span class="n">mean_attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span><span class="p">(</span><span class="n">mean_attention_probs</span><span class="p">)</span>
        <span class="n">cov_attention_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_dropout</span><span class="p">(</span><span class="n">cov_attention_probs</span><span class="p">)</span>
        <span class="n">mean_context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mean_attention_probs</span><span class="p">,</span> <span class="n">mean_value_layer</span><span class="p">)</span>
        <span class="n">cov_context_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cov_attention_probs</span><span class="p">,</span> <span class="n">cov_value_layer</span><span class="p">)</span>
        <span class="n">mean_context_layer</span> <span class="o">=</span> <span class="n">mean_context_layer</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">cov_context_layer</span> <span class="o">=</span> <span class="n">cov_context_layer</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">new_context_layer_shape</span> <span class="o">=</span> <span class="n">mean_context_layer</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_head_size</span><span class="p">,)</span>

        <span class="n">mean_context_layer</span> <span class="o">=</span> <span class="n">mean_context_layer</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_context_layer_shape</span><span class="p">)</span>
        <span class="n">cov_context_layer</span> <span class="o">=</span> <span class="n">cov_context_layer</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">new_context_layer_shape</span><span class="p">)</span>

        <span class="n">mean_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_dense</span><span class="p">(</span><span class="n">mean_context_layer</span><span class="p">)</span>
        <span class="n">mean_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span><span class="p">(</span><span class="n">mean_hidden_states</span><span class="p">)</span>
        <span class="n">mean_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">mean_hidden_states</span> <span class="o">+</span> <span class="n">input_mean_tensor</span><span class="p">)</span>

        <span class="n">cov_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_dense</span><span class="p">(</span><span class="n">cov_context_layer</span><span class="p">)</span>
        <span class="n">cov_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dropout</span><span class="p">(</span><span class="n">cov_hidden_states</span><span class="p">)</span>
        <span class="n">cov_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">cov_hidden_states</span> <span class="o">+</span> <span class="n">input_cov_tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">mean_attention_probs</span>

<span class="c1"># REPLACE WITH from recohut.models.layers.common import DistMeanSelfAttention</span>

<span class="k">class</span> <span class="nc">Intermediate</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Intermediate</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_act</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_act_fn</span> <span class="o">=</span> <span class="n">ACT2FN</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_act</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_act_fn</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_act</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dense_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_1</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_act_fn</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_2</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_states</span> <span class="o">+</span> <span class="n">input_tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">hidden_states</span>


<span class="k">class</span> <span class="nc">DistIntermediate</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistIntermediate</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_act_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dense_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_1</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_act_fn</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_2</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_states</span> <span class="o">+</span> <span class="n">input_tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">hidden_states</span>


<span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate</span> <span class="o">=</span> <span class="n">Intermediate</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">attention_output</span><span class="p">,</span> <span class="n">attention_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">intermediate_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate</span><span class="p">(</span><span class="n">attention_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">intermediate_output</span><span class="p">,</span> <span class="n">attention_scores</span>


<span class="k">class</span> <span class="nc">DistLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">DistSelfAttention</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_intermediate</span> <span class="o">=</span> <span class="n">DistIntermediate</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_intermediate</span> <span class="o">=</span> <span class="n">DistIntermediate</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">mean_attention_output</span><span class="p">,</span> <span class="n">cov_attention_output</span><span class="p">,</span> <span class="n">attention_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">mean_intermediate_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_intermediate</span><span class="p">(</span><span class="n">mean_attention_output</span><span class="p">)</span>
        <span class="n">cov_intermediate_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_intermediate</span><span class="p">(</span><span class="n">cov_attention_output</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">mean_intermediate_output</span><span class="p">,</span> <span class="n">cov_intermediate_output</span><span class="p">,</span> <span class="n">attention_scores</span>


<span class="k">class</span> <span class="nc">DistMeanSALayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistMeanSALayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">DistMeanSelfAttention</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_intermediate</span> <span class="o">=</span> <span class="n">DistIntermediate</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_intermediate</span> <span class="o">=</span> <span class="n">DistIntermediate</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">mean_attention_output</span><span class="p">,</span> <span class="n">cov_attention_output</span><span class="p">,</span> <span class="n">attention_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">mean_intermediate_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_intermediate</span><span class="p">(</span><span class="n">mean_attention_output</span><span class="p">)</span>
        <span class="n">cov_intermediate_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_intermediate</span><span class="p">(</span><span class="n">cov_attention_output</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">mean_intermediate_output</span><span class="p">,</span> <span class="n">cov_intermediate_output</span><span class="p">,</span> <span class="n">attention_scores</span>


<span class="k">class</span> <span class="nc">DistSAEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>               
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistSAEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">DistLayer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">all_encoder_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer_module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">:</span>
            <span class="n">maen_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">att_scores</span> <span class="o">=</span> <span class="n">layer_module</span><span class="p">(</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
                <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">att_scores</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
            <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">att_scores</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">all_encoder_layers</span>


<span class="k">class</span> <span class="nc">DistMeanSAEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistMeanSAEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">DistMeanSALayer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">all_encoder_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer_module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">:</span>
            <span class="n">maen_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">att_scores</span> <span class="o">=</span> <span class="n">layer_module</span><span class="p">(</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
                <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">att_scores</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
            <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">mean_hidden_states</span><span class="p">,</span> <span class="n">cov_hidden_states</span><span class="p">,</span> <span class="n">att_scores</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">all_encoder_layers</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">Layer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">all_encoder_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer_module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">:</span>
            <span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">layer_module</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
                <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_scores</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
            <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">attention_scores</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">all_encoder_layers</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Models">Models<a class="anchor-link" href="#Models"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="c1"># from modules import Encoder, LayerNorm</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">S3RecModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">S3RecModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">attribute_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

        <span class="c1"># add unique dense layer for 4 losses respectively</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aap_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mip_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">map_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sp_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>

    <span class="c1"># AAP</span>
    <span class="k">def</span> <span class="nf">associated_attribute_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">attribute_embedding</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :param sequence_output: [B L H]</span>
<span class="sd">        :param attribute_embedding: [arribute_num H]</span>
<span class="sd">        :return: scores [B*L tag_num]</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aap_norm</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span> <span class="c1"># [B L H]</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="c1"># [B*L H 1]</span>
        <span class="c1"># [tag_num H] [B*L H 1] -&gt; [B*L tag_num 1]</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attribute_embedding</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># [B*L tag_num]</span>

    <span class="c1"># MIP sample neg items</span>
    <span class="k">def</span> <span class="nf">masked_item_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">target_item</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :param sequence_output: [B L H]</span>
<span class="sd">        :param target_item: [B L H]</span>
<span class="sd">        :return: scores [B*L]</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mip_norm</span><span class="p">(</span><span class="n">sequence_output</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">]))</span> <span class="c1"># [B*L H]</span>
        <span class="n">target_item</span> <span class="o">=</span> <span class="n">target_item</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">])</span> <span class="c1"># [B*L H]</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">target_item</span><span class="p">)</span> <span class="c1"># [B*L H]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># [B*L]</span>

    <span class="c1"># MAP</span>
    <span class="k">def</span> <span class="nf">masked_attribute_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">attribute_embedding</span><span class="p">):</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_norm</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>  <span class="c1"># [B L H]</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># [B*L H 1]</span>
        <span class="c1"># [tag_num H] [B*L H 1] -&gt; [B*L tag_num 1]</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attribute_embedding</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># [B*L tag_num]</span>

    <span class="c1"># SP sample neg segment</span>
    <span class="k">def</span> <span class="nf">segment_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">segment</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :param context: [B H]</span>
<span class="sd">        :param segment: [B H]</span>
<span class="sd">        :return:</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp_norm</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">segment</span><span class="p">)</span> <span class="c1"># [B H]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># [B]</span>

    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">add_position_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">):</span>

        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="n">item_embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sequence_emb</span>

    <span class="k">def</span> <span class="nf">pretrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attributes</span><span class="p">,</span> <span class="n">masked_item_sequence</span><span class="p">,</span> <span class="n">pos_items</span><span class="p">,</span>  <span class="n">neg_items</span><span class="p">,</span>
                  <span class="n">masked_segment_sequence</span><span class="p">,</span> <span class="n">pos_segment</span><span class="p">,</span> <span class="n">neg_segment</span><span class="p">):</span>

        <span class="c1"># Encode masked sequence</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_embedding</span><span class="p">(</span><span class="n">masked_item_sequence</span><span class="p">)</span>
        <span class="n">sequence_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">masked_item_sequence</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e8</span>
        <span class="n">sequence_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">sequence_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">,</span>
                                          <span class="n">sequence_mask</span><span class="p">,</span>
                                          <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># [B L H]</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">attribute_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attribute_embeddings</span><span class="o">.</span><span class="n">weight</span>
        <span class="c1"># AAP</span>
        <span class="n">aap_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">associated_attribute_prediction</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">attribute_embeddings</span><span class="p">)</span>
        <span class="n">aap_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">aap_score</span><span class="p">,</span> <span class="n">attributes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">attribute_size</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="c1"># only compute loss at non-masked position</span>
        <span class="n">aap_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">masked_item_sequence</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> \
                         <span class="p">(</span><span class="n">masked_item_sequence</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">aap_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">aap_loss</span> <span class="o">*</span> <span class="n">aap_mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># MIP</span>
        <span class="n">pos_item_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">pos_items</span><span class="p">)</span>
        <span class="n">neg_item_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">neg_items</span><span class="p">)</span>
        <span class="n">pos_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_prediction</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">pos_item_embs</span><span class="p">)</span>
        <span class="n">neg_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_prediction</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">neg_item_embs</span><span class="p">)</span>
        <span class="n">mip_distance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pos_score</span> <span class="o">-</span> <span class="n">neg_score</span><span class="p">)</span>
        <span class="n">mip_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">mip_distance</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mip_distance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">mip_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">masked_item_sequence</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">mip_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mip_loss</span> <span class="o">*</span> <span class="n">mip_mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># MAP</span>
        <span class="n">map_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_attribute_prediction</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">attribute_embeddings</span><span class="p">)</span>
        <span class="n">map_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">map_score</span><span class="p">,</span> <span class="n">attributes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">attribute_size</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="n">map_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">masked_item_sequence</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mask_id</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">map_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">map_loss</span> <span class="o">*</span> <span class="n">map_mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># SP</span>
        <span class="c1"># segment context</span>
        <span class="n">segment_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_embedding</span><span class="p">(</span><span class="n">masked_segment_sequence</span><span class="p">)</span>
        <span class="n">segment_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">masked_segment_sequence</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e8</span>
        <span class="n">segment_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">segment_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">segment_encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">segment_context</span><span class="p">,</span>
                                               <span class="n">segment_mask</span><span class="p">,</span>
                                               <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># take the last position hidden as the context</span>
        <span class="n">segment_context</span> <span class="o">=</span> <span class="n">segment_encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="c1"># [B H]</span>
        <span class="c1"># pos_segment</span>
        <span class="n">pos_segment_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_embedding</span><span class="p">(</span><span class="n">pos_segment</span><span class="p">)</span>
        <span class="n">pos_segment_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_segment</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e8</span>
        <span class="n">pos_segment_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">pos_segment_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">pos_segment_encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">pos_segment_emb</span><span class="p">,</span>
                                                   <span class="n">pos_segment_mask</span><span class="p">,</span>
                                                   <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pos_segment_emb</span> <span class="o">=</span> <span class="n">pos_segment_encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># neg_segment</span>
        <span class="n">neg_segment_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_embedding</span><span class="p">(</span><span class="n">neg_segment</span><span class="p">)</span>
        <span class="n">neg_segment_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">neg_segment</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e8</span>
        <span class="n">neg_segment_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">neg_segment_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">neg_segment_encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">neg_segment_emb</span><span class="p">,</span>
                                                       <span class="n">neg_segment_mask</span><span class="p">,</span>
                                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">neg_segment_emb</span> <span class="o">=</span> <span class="n">neg_segment_encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># [B H]</span>

        <span class="n">pos_segment_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_prediction</span><span class="p">(</span><span class="n">segment_context</span><span class="p">,</span> <span class="n">pos_segment_emb</span><span class="p">)</span>
        <span class="n">neg_segment_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_prediction</span><span class="p">(</span><span class="n">segment_context</span><span class="p">,</span> <span class="n">neg_segment_emb</span><span class="p">)</span>

        <span class="n">sp_distance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pos_segment_score</span> <span class="o">-</span> <span class="n">neg_segment_score</span><span class="p">)</span>

        <span class="n">sp_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">sp_distance</span><span class="p">,</span>
                                           <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">sp_distance</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">aap_loss</span><span class="p">,</span> <span class="n">mip_loss</span><span class="p">,</span> <span class="n">map_loss</span><span class="p">,</span> <span class="n">sp_loss</span>

    <span class="c1"># Fine tune</span>
    <span class="c1"># same as SASRec</span>
    <span class="k">def</span> <span class="nf">finetune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">):</span>

        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># torch.int64</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">attn_shape</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># torch.uint8</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">subsequent_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">cuda_condition</span><span class="p">:</span>
            <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span> <span class="o">*</span> <span class="n">subsequent_mask</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>

        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_embedding</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">item_encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">,</span>
                                                <span class="n">extended_attention_mask</span><span class="p">,</span>
                                                <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">item_encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sequence_output</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize the weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Seq-Models">Seq Models<a class="anchor-link" href="#Seq-Models"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="c1"># from modules import Encoder, LayerNorm, DistSAEncoder, DistMeanSAEncoder</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">SASRecModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SASRecModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_position_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">):</span>

        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="n">item_embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sequence_emb</span>


    <span class="k">def</span> <span class="nf">finetune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">):</span>

        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># torch.int64</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">attn_shape</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># torch.uint8</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">subsequent_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">cuda_condition</span><span class="p">:</span>
            <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span> <span class="o">*</span> <span class="n">subsequent_mask</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>

        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_embedding</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">item_encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">,</span>
                                                <span class="n">extended_attention_mask</span><span class="p">,</span>
                                                <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">item_encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">attention_scores</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize the weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
            <span class="c1"># cf https://github.com/pytorch/pytorch/pull/5617</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">DistSAModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistSAModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_mean_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_cov_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_mean_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_cov_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_margins</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span> <span class="o">=</span> <span class="n">DistSAEncoder</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_position_mean_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">):</span>

        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_mean_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="n">item_embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>
        <span class="n">elu_act</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="n">elu_act</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sequence_emb</span>

    <span class="k">def</span> <span class="nf">add_position_cov_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">):</span>

        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">sequence</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_cov_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="n">item_embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">)</span>
        <span class="n">elu_act</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">sequence_emb</span> <span class="o">=</span> <span class="n">elu_act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_emb</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">sequence_emb</span>

    <span class="k">def</span> <span class="nf">finetune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">user_ids</span><span class="p">):</span>

        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># torch.int64</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">attn_shape</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># torch.uint8</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">subsequent_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">cuda_condition</span><span class="p">:</span>
            <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">subsequent_mask</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span> <span class="o">*</span> <span class="n">subsequent_mask</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">mean_sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_mean_embedding</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">cov_sequence_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_position_cov_embedding</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">item_encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span><span class="p">(</span><span class="n">mean_sequence_emb</span><span class="p">,</span>
                                                <span class="n">cov_sequence_emb</span><span class="p">,</span>
                                                <span class="n">extended_attention_mask</span><span class="p">,</span>
                                                <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">mean_sequence_output</span><span class="p">,</span> <span class="n">cov_sequence_output</span><span class="p">,</span> <span class="n">att_scores</span> <span class="o">=</span> <span class="n">item_encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">margins</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_margins</span><span class="p">(</span><span class="n">user_ids</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean_sequence_output</span><span class="p">,</span> <span class="n">cov_sequence_output</span><span class="p">,</span> <span class="n">att_scores</span><span class="p">,</span> <span class="n">margins</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize the weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">DistMeanSAModel</span><span class="p">(</span><span class="n">DistSAModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistMeanSAModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_encoder</span> <span class="o">=</span> <span class="n">DistMeanSAEncoder</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Trainers">Trainers<a class="anchor-link" href="#Trainers"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="c1"># from utils import recall_at_k, ndcg_at_k, get_eval_metrics_v2, cal_mrr, get_user_performance_perpopularity, get_item_performance_perpopularity</span>
<span class="c1"># from modules import wasserstein_distance, kl_distance, wasserstein_distance_matmul, d2s_gaussiannormal, d2s_1overx, kl_distance_matmul</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span>
                 <span class="n">eval_dataloader</span><span class="p">,</span>
                 <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cuda_condition</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">no_cuda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda_condition</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda_condition</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="c1"># Setting the train and test data loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">eval_dataloader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">test_dataloader</span>

        <span class="c1"># self.data_name = self.args.data_name</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">adam_beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">adam_beta2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Parameters:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataloader</span><span class="p">,</span> <span class="n">full_sort</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">full_sort</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">get_sample_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">):</span>
        <span class="n">pred_list</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">pred_list</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">HIT_1</span><span class="p">,</span> <span class="n">NDCG_1</span><span class="p">,</span> <span class="n">MRR</span> <span class="o">=</span> <span class="n">get_eval_metrics_v2</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">HIT_5</span><span class="p">,</span> <span class="n">NDCG_5</span><span class="p">,</span> <span class="n">MRR</span> <span class="o">=</span> <span class="n">get_eval_metrics_v2</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">HIT_10</span><span class="p">,</span> <span class="n">NDCG_10</span><span class="p">,</span> <span class="n">MRR</span> <span class="o">=</span> <span class="n">get_eval_metrics_v2</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;Epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;HIT@1&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">HIT_1</span><span class="p">),</span> <span class="s2">&quot;NDCG@1&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NDCG_1</span><span class="p">),</span>
            <span class="s2">&quot;HIT@5&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">HIT_5</span><span class="p">),</span> <span class="s2">&quot;NDCG@5&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NDCG_5</span><span class="p">),</span>
            <span class="s2">&quot;HIT@10&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">HIT_10</span><span class="p">),</span> <span class="s2">&quot;NDCG@10&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NDCG_10</span><span class="p">),</span>
            <span class="s2">&quot;MRR&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">MRR</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">post_fix</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">HIT_1</span><span class="p">,</span> <span class="n">NDCG_1</span><span class="p">,</span> <span class="n">HIT_5</span><span class="p">,</span> <span class="n">NDCG_5</span><span class="p">,</span> <span class="n">HIT_10</span><span class="p">,</span> <span class="n">NDCG_10</span><span class="p">,</span> <span class="n">MRR</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">),</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">get_full_sort_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">answers</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">):</span>
        <span class="n">recall</span><span class="p">,</span> <span class="n">ndcg</span><span class="p">,</span> <span class="n">mrr</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="mi">0</span>
        <span class="n">recall_dict_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ndcg_dict_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">]:</span>
            <span class="n">recall_result</span><span class="p">,</span> <span class="n">recall_dict_k</span> <span class="o">=</span> <span class="n">recall_at_k</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_result</span><span class="p">)</span>
            <span class="n">recall_dict_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_dict_k</span><span class="p">)</span>
            <span class="n">ndcg_result</span><span class="p">,</span> <span class="n">ndcg_dict_k</span> <span class="o">=</span> <span class="n">ndcg_at_k</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">ndcg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ndcg_result</span><span class="p">)</span>
            <span class="n">ndcg_dict_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ndcg_dict_k</span><span class="p">)</span>
        <span class="n">mrr</span><span class="p">,</span> <span class="n">mrr_dict</span> <span class="o">=</span> <span class="n">cal_mrr</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">)</span>
        <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;Epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;HIT@1&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s2">&quot;NDCG@1&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndcg</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="s2">&quot;HIT@5&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="s2">&quot;NDCG@5&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndcg</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
            <span class="s2">&quot;HIT@10&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s2">&quot;NDCG@10&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndcg</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
            <span class="s2">&quot;HIT@15&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="s2">&quot;NDCG@15&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndcg</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span>
            <span class="s2">&quot;HIT@20&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">4</span><span class="p">]),</span> <span class="s2">&quot;NDCG@20&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndcg</span><span class="p">[</span><span class="mi">4</span><span class="p">]),</span>
            <span class="s2">&quot;HIT@40&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="mi">5</span><span class="p">]),</span> <span class="s2">&quot;NDCG@40&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndcg</span><span class="p">[</span><span class="mi">5</span><span class="p">]),</span>
            <span class="s2">&quot;MRR&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mrr</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">post_fix</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">recall</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ndcg</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ndcg</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">ndcg</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">ndcg</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">ndcg</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">ndcg</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">mrr</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">),</span> <span class="p">[</span><span class="n">recall_dict_list</span><span class="p">,</span> <span class="n">ndcg_dict_list</span><span class="p">,</span> <span class="n">mrr_dict</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_pos_items_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_pred_lists</span><span class="p">,</span> <span class="n">answers</span><span class="p">):</span>
        <span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_pred_lists</span><span class="p">)</span>
        <span class="n">batch_pos_ranks</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_users</span><span class="p">):</span>
            <span class="n">pred_list</span> <span class="o">=</span> <span class="n">batch_pred_lists</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">true_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">pred_item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pred_list</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">pred_item</span> <span class="ow">in</span> <span class="n">true_set</span><span class="p">:</span>
                    <span class="n">batch_pos_ranks</span><span class="p">[</span><span class="n">pred_item</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">batch_pos_ranks</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_out</span><span class="p">,</span> <span class="n">pos_ids</span><span class="p">,</span> <span class="n">neg_ids</span><span class="p">):</span>
        <span class="c1"># [batch seq_len hidden_size]</span>
        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">)</span>
        <span class="n">neg_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">)</span>
        <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">pos_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg</span> <span class="o">=</span> <span class="n">neg_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">seq_emb</span> <span class="o">=</span> <span class="n">seq_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">pos_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pos</span> <span class="o">*</span> <span class="n">seq_emb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [batch*seq_len]</span>
        <span class="n">neg_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">neg</span> <span class="o">*</span> <span class="n">seq_emb</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">istarget</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">pos_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># [batch*seq_len]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pos_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-24</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span> <span class="o">-</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">neg_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-24</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>

        <span class="n">auc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">pos_logits</span> <span class="o">-</span> <span class="n">neg_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">auc</span>

    <span class="k">def</span> <span class="nf">predict_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_out</span><span class="p">,</span> <span class="n">test_neg_sample</span><span class="p">):</span>
        <span class="c1"># [batch 100 hidden_size]</span>
        <span class="n">test_item_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">test_neg_sample</span><span class="p">)</span>
        <span class="c1"># [batch hidden_size]</span>
        <span class="n">test_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">test_item_emb</span><span class="p">,</span> <span class="n">seq_out</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B 100]</span>
        <span class="k">return</span> <span class="n">test_logits</span>

    <span class="k">def</span> <span class="nf">predict_full</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_out</span><span class="p">):</span>
        <span class="c1"># [item_num hidden_size]</span>
        <span class="n">test_item_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_embeddings</span><span class="o">.</span><span class="n">weight</span>
        <span class="c1"># [batch hidden_size ]</span>
        <span class="n">rating_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">seq_out</span><span class="p">,</span> <span class="n">test_item_emb</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">rating_pred</span>

<span class="k">class</span> <span class="nc">PretrainTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
                 <span class="n">train_dataloader</span><span class="p">,</span>
                 <span class="n">eval_dataloader</span><span class="p">,</span>
                 <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PretrainTrainer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">train_dataloader</span><span class="p">,</span>
            <span class="n">eval_dataloader</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">pretrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">pretrain_dataloader</span><span class="p">):</span>

        <span class="n">desc</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;AAP-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">aap_weight</span><span class="si">}</span><span class="s1">-&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;MIP-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mip_weight</span><span class="si">}</span><span class="s1">-&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;MAP-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">map_weight</span><span class="si">}</span><span class="s1">-&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;SP-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">sp_weight</span><span class="si">}</span><span class="s1">&#39;</span>

        <span class="n">pretrain_data_iter</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">pretrain_dataloader</span><span class="p">),</span>
                                       <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">data_name</span><span class="si">}</span><span class="s2"> Epoch:</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                                       <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">pretrain_dataloader</span><span class="p">),</span>
                                       <span class="n">bar_format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{l_bar}{r_bar}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">aap_loss_avg</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">mip_loss_avg</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">map_loss_avg</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">sp_loss_avg</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">pretrain_data_iter</span><span class="p">:</span>
            <span class="c1"># 0. batch_data will be sent into the device(GPU or CPU)</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">attributes</span><span class="p">,</span> <span class="n">masked_item_sequence</span><span class="p">,</span> <span class="n">pos_items</span><span class="p">,</span> <span class="n">neg_items</span><span class="p">,</span> \
            <span class="n">masked_segment_sequence</span><span class="p">,</span> <span class="n">pos_segment</span><span class="p">,</span> <span class="n">neg_segment</span> <span class="o">=</span> <span class="n">batch</span>

            <span class="n">aap_loss</span><span class="p">,</span> <span class="n">mip_loss</span><span class="p">,</span> <span class="n">map_loss</span><span class="p">,</span> <span class="n">sp_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pretrain</span><span class="p">(</span><span class="n">attributes</span><span class="p">,</span>
                                            <span class="n">masked_item_sequence</span><span class="p">,</span> <span class="n">pos_items</span><span class="p">,</span> <span class="n">neg_items</span><span class="p">,</span>
                                            <span class="n">masked_segment_sequence</span><span class="p">,</span> <span class="n">pos_segment</span><span class="p">,</span> <span class="n">neg_segment</span><span class="p">)</span>

            <span class="n">joint_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">aap_weight</span> <span class="o">*</span> <span class="n">aap_loss</span> <span class="o">+</span> \
                         <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mip_weight</span> <span class="o">*</span> <span class="n">mip_loss</span> <span class="o">+</span> \
                         <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">map_weight</span> <span class="o">*</span> <span class="n">map_loss</span> <span class="o">+</span> \
                         <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">sp_weight</span> <span class="o">*</span> <span class="n">sp_loss</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">joint_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">aap_loss_avg</span> <span class="o">+=</span> <span class="n">aap_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">mip_loss_avg</span> <span class="o">+=</span> <span class="n">mip_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">map_loss_avg</span> <span class="o">+=</span> <span class="n">map_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">sp_loss_avg</span> <span class="o">+=</span> <span class="n">sp_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pretrain_data_iter</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">pre_batch_size</span>
        <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;aap_loss_avg&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">aap_loss_avg</span> <span class="o">/</span><span class="n">num</span><span class="p">),</span>
            <span class="s2">&quot;mip_loss_avg&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mip_loss_avg</span> <span class="o">/</span><span class="n">num</span><span class="p">),</span>
            <span class="s2">&quot;map_loss_avg&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">map_loss_avg</span> <span class="o">/</span> <span class="n">num</span><span class="p">),</span>
            <span class="s2">&quot;sp_loss_avg&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sp_loss_avg</span> <span class="o">/</span> <span class="n">num</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">desc</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">))</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">desc</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">FinetuneTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
                 <span class="n">train_dataloader</span><span class="p">,</span>
                 <span class="n">eval_dataloader</span><span class="p">,</span>
                 <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FinetuneTrainer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">train_dataloader</span><span class="p">,</span>
            <span class="n">eval_dataloader</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="n">str_code</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="s2">&quot;test&quot;</span>

        <span class="c1"># Setting the tqdm progress bar</span>

        <span class="c1">#rec_data_iter = tqdm.tqdm(enumerate(dataloader),</span>
        <span class="c1">#                          desc=&quot;Recommendation EP_%s:%d&quot; % (str_code, epoch),</span>
        <span class="c1">#                          total=len(dataloader),</span>
        <span class="c1">#                          bar_format=&quot;{l_bar}{r_bar}&quot;)</span>
        <span class="n">rec_data_iter</span> <span class="o">=</span> <span class="n">dataloader</span>
        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">rec_avg_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">rec_cur_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">rec_avg_auc</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c1">#for i, batch in rec_data_iter:</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">rec_data_iter</span><span class="p">:</span>
                <span class="c1"># 0. batch_data will be sent into the device(GPU or CPU)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>
                <span class="c1"># Binary cross_entropy</span>
                <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">finetune</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">batch_auc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">rec_avg_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">rec_cur_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">rec_avg_auc</span> <span class="o">+=</span> <span class="n">batch_auc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s2">&quot;rec_avg_loss&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_avg_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rec_data_iter</span><span class="p">)),</span>
                <span class="s2">&quot;rec_cur_loss&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_cur_loss</span><span class="p">),</span>
                <span class="s2">&quot;rec_avg_auc&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_avg_auc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rec_data_iter</span><span class="p">)),</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="n">pred_list</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">full_sort</span><span class="p">:</span>
                <span class="n">answer_list</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="c1">#for i, batch in rec_data_iter:</span>
                <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">rec_data_iter</span><span class="p">:</span>
                    <span class="c1"># 0. batch_data will be sent into the device(GPU or cpu)</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
                    <span class="n">user_ids</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">,</span> <span class="n">answers</span> <span class="o">=</span> <span class="n">batch</span>
                    <span class="n">recommend_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">finetune</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

                    <span class="n">recommend_output</span> <span class="o">=</span> <span class="n">recommend_output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="n">rating_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_full</span><span class="p">(</span><span class="n">recommend_output</span><span class="p">)</span>

                    <span class="n">rating_pred</span> <span class="o">=</span> <span class="n">rating_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="n">batch_user_index</span> <span class="o">=</span> <span class="n">user_ids</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="n">rating_pred</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">train_matrix</span><span class="p">[</span><span class="n">batch_user_index</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">,</span> <span class="o">-</span><span class="mi">40</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">40</span><span class="p">:]</span>
                    <span class="n">arr_ind</span> <span class="o">=</span> <span class="n">rating_pred</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">ind</span><span class="p">]</span>
                    <span class="n">arr_ind_argsort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">arr_ind</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">)),</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">batch_pred_list</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">arr_ind_argsort</span><span class="p">]</span>

                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">pred_list</span> <span class="o">=</span> <span class="n">batch_pred_list</span>
                        <span class="n">answer_list</span> <span class="o">=</span> <span class="n">answers</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">pred_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="n">batch_pred_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">answer_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">answer_list</span><span class="p">,</span> <span class="n">answers</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_full_sort_score</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">answer_list</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#for i, batch in rec_data_iter:</span>
                <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">rec_data_iter</span><span class="p">:</span>
                    <span class="c1"># 0. batch_data will be sent into the device(GPU or cpu)</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
                    <span class="n">user_ids</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">,</span> <span class="n">answers</span><span class="p">,</span> <span class="n">sample_negs</span> <span class="o">=</span> <span class="n">batch</span>
                    <span class="n">recommend_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">finetune</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
                    <span class="n">test_neg_items</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">answers</span><span class="p">,</span> <span class="n">sample_negs</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">recommend_output</span> <span class="o">=</span> <span class="n">recommend_output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="n">test_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_sample</span><span class="p">(</span><span class="n">recommend_output</span><span class="p">,</span> <span class="n">test_neg_items</span><span class="p">)</span>
                    <span class="n">test_logits</span> <span class="o">=</span> <span class="n">test_logits</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">pred_list</span> <span class="o">=</span> <span class="n">test_logits</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">pred_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="n">test_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_sample_scores</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DistSAModelTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
                 <span class="n">train_dataloader</span><span class="p">,</span>
                 <span class="n">eval_dataloader</span><span class="p">,</span>
                 <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistSAModelTrainer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">train_dataloader</span><span class="p">,</span>
            <span class="n">eval_dataloader</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">bpr_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">,</span> <span class="n">pos_ids</span><span class="p">,</span> <span class="n">neg_ids</span><span class="p">):</span>
        <span class="c1"># [batch seq_len hidden_size]</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">pos_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">)</span>
        <span class="n">pos_cov_emb</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">neg_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">)</span>
        <span class="n">neg_cov_emb</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">pos_mean</span> <span class="o">=</span> <span class="n">pos_mean_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_mean_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">pos_cov</span> <span class="o">=</span> <span class="n">pos_cov_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_cov_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg_mean</span> <span class="o">=</span> <span class="n">neg_mean_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_mean_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg_cov</span> <span class="o">=</span> <span class="n">neg_cov_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_cov_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">seq_mean_emb</span> <span class="o">=</span> <span class="n">seq_mean_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">seq_cov_emb</span> <span class="o">=</span> <span class="n">seq_cov_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">distance_metric</span> <span class="o">==</span> <span class="s1">&#39;wasserstein&#39;</span><span class="p">:</span>
            <span class="n">pos_logits</span> <span class="o">=</span> <span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">)</span>
            <span class="n">neg_logits</span> <span class="o">=</span> <span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>
            <span class="n">pos_vs_neg</span> <span class="o">=</span> <span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pos_logits</span> <span class="o">=</span> <span class="n">kl_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">)</span>
            <span class="n">neg_logits</span> <span class="o">=</span> <span class="n">kl_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>
            <span class="n">pos_vs_neg</span> <span class="o">=</span> <span class="n">kl_distance</span><span class="p">(</span><span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>

        <span class="n">istarget</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">pos_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># [batch*seq_len]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">neg_logits</span> <span class="o">-</span> <span class="n">pos_logits</span> <span class="o">+</span> <span class="mf">1e-24</span><span class="p">))</span> <span class="o">*</span> <span class="n">istarget</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>

        <span class="n">pvn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">pvn_weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">pos_logits</span> <span class="o">-</span> <span class="n">pos_vs_neg</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>
        <span class="n">auc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">neg_logits</span> <span class="o">-</span> <span class="n">pos_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">pvn_loss</span>

    <span class="k">def</span> <span class="nf">ce_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">,</span> <span class="n">pos_ids</span><span class="p">,</span> <span class="n">neg_ids</span><span class="p">):</span>
        <span class="c1"># [batch seq_len hidden_size]</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">pos_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">)</span>
        <span class="n">pos_cov_emb</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">neg_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">)</span>
        <span class="n">neg_cov_emb</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">pos_mean</span> <span class="o">=</span> <span class="n">pos_mean_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_mean_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">pos_cov</span> <span class="o">=</span> <span class="n">pos_cov_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_cov_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg_mean</span> <span class="o">=</span> <span class="n">neg_mean_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_mean_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg_cov</span> <span class="o">=</span> <span class="n">neg_cov_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_cov_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">seq_mean_emb</span> <span class="o">=</span> <span class="n">seq_mean_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">seq_cov_emb</span> <span class="o">=</span> <span class="n">seq_cov_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>


        <span class="c1">#pos_logits = d2s_gaussiannormal(wasserstein_distance(seq_mean_emb, seq_cov_emb, pos_mean, pos_cov), self.args.kernel_param)</span>
        <span class="n">pos_logits</span> <span class="o">=</span> <span class="o">-</span><span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">)</span>
        <span class="c1">#neg_logits = d2s_gaussiannormal(wasserstein_distance(seq_mean_emb, seq_cov_emb, neg_mean, neg_cov), self.args.kernel_param)</span>
        <span class="n">neg_logits</span> <span class="o">=</span> <span class="o">-</span><span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>

        <span class="n">istarget</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">pos_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># [batch*seq_len]</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">neg_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-24</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span> <span class="o">-</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pos_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-24</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>

        <span class="n">auc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">neg_logits</span> <span class="o">-</span> <span class="n">pos_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>


        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">auc</span>

    <span class="k">def</span> <span class="nf">margin_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">,</span> <span class="n">pos_ids</span><span class="p">,</span> <span class="n">neg_ids</span><span class="p">,</span> <span class="n">margins</span><span class="p">):</span>
        <span class="c1"># [batch seq_len hidden_size]</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">pos_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">)</span>
        <span class="n">pos_cov_emb</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">neg_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">)</span>
        <span class="n">neg_cov_emb</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">pos_mean</span> <span class="o">=</span> <span class="n">pos_mean_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_mean_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">pos_cov</span> <span class="o">=</span> <span class="n">pos_cov_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pos_cov_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg_mean</span> <span class="o">=</span> <span class="n">neg_mean_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_mean_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">neg_cov</span> <span class="o">=</span> <span class="n">neg_cov_emb</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">neg_cov_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">seq_mean_emb</span> <span class="o">=</span> <span class="n">seq_mean_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>
        <span class="n">seq_cov_emb</span> <span class="o">=</span> <span class="n">seq_cov_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># [batch*seq_len hidden_size]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">distance_metric</span> <span class="o">==</span> <span class="s1">&#39;wasserstein&#39;</span><span class="p">:</span>
            <span class="n">pos_logits</span> <span class="o">=</span> <span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">)</span>
            <span class="n">neg_logits</span> <span class="o">=</span> <span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>
            <span class="n">pos_vs_neg</span> <span class="o">=</span> <span class="n">wasserstein_distance</span><span class="p">(</span><span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pos_logits</span> <span class="o">=</span> <span class="n">kl_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">)</span>
            <span class="n">neg_logits</span> <span class="o">=</span> <span class="n">kl_distance</span><span class="p">(</span><span class="n">seq_mean_emb</span><span class="p">,</span> <span class="n">seq_cov_emb</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>
            <span class="n">pos_vs_neg</span> <span class="o">=</span> <span class="n">kl_distance</span><span class="p">(</span><span class="n">pos_mean</span><span class="p">,</span> <span class="n">pos_cov</span><span class="p">,</span> <span class="n">neg_mean</span><span class="p">,</span> <span class="n">neg_cov</span><span class="p">)</span>

        <span class="n">istarget</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_ids</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">pos_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># [batch*seq_len]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">pos_logits</span> <span class="o">-</span> <span class="n">neg_logits</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>
        <span class="n">pvn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">pvn_weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">pos_logits</span> <span class="o">-</span> <span class="n">pos_vs_neg</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>
        <span class="n">auc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">neg_logits</span> <span class="o">-</span> <span class="n">pos_logits</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">istarget</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">istarget</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">pvn_loss</span>

    
    <span class="k">def</span> <span class="nf">dist_predict_full</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">):</span>
        <span class="n">elu_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">test_item_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">test_item_cov_emb</span> <span class="o">=</span> <span class="n">elu_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1">#num_items, emb_size = test_item_cov_emb.shape</span>

        <span class="c1">#seq_mean_out = seq_mean_out.unsqueeze(1).expand(-1, num_items, -1).reshape(-1, emb_size)</span>
        <span class="c1">#seq_cov_out = seq_cov_out.unsqueeze(1).expand(-1, num_items, -1).reshape(-1, emb_size)</span>

        <span class="c1">#if args.distance_metric == &#39;wasserstein&#39;:</span>
        <span class="c1">#    return wasserstein_distance(seq_mean_out, seq_cov_out, test_item_mean_emb, test_item_cov_emb)</span>
        <span class="c1">#else:</span>
        <span class="c1">#    return kl_distance(seq_mean_out, seq_cov_out, test_item_mean_emb, test_item_cov_emb)</span>
        <span class="c1">#return d2s_1overx(wasserstein_distance_matmul(seq_mean_out, seq_cov_out, test_item_mean_emb, test_item_cov_emb))</span>
        <span class="k">return</span> <span class="n">wasserstein_distance_matmul</span><span class="p">(</span><span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">,</span> <span class="n">test_item_mean_emb</span><span class="p">,</span> <span class="n">test_item_cov_emb</span><span class="p">)</span>
        <span class="c1">#return d2s_gaussiannormal(wasserstein_distance_matmul(seq_mean_out, seq_cov_out, test_item_mean_emb, test_item_cov_emb))</span>

    <span class="k">def</span> <span class="nf">kl_predict_full</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">):</span>
        <span class="n">elu_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
        <span class="n">test_item_mean_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_mean_embeddings</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">test_item_cov_emb</span> <span class="o">=</span> <span class="n">elu_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">item_cov_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">num_items</span> <span class="o">=</span> <span class="n">test_item_mean_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="n">seq_mean_out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">moded_num_items</span> <span class="o">=</span> <span class="n">eval_batch_size</span> <span class="o">-</span> <span class="n">num_items</span> <span class="o">%</span> <span class="n">eval_batch_size</span>
        <span class="n">fake_mean_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">moded_num_items</span><span class="p">,</span> <span class="n">test_item_mean_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">fake_cov_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">moded_num_items</span><span class="p">,</span> <span class="n">test_item_mean_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">concated_mean_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">test_item_mean_emb</span><span class="p">,</span> <span class="n">fake_mean_emb</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">concated_cov_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">test_item_cov_emb</span><span class="p">,</span> <span class="n">fake_cov_emb</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">concated_mean_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_item_mean_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">moded_num_items</span>

        <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_items</span> <span class="o">/</span> <span class="n">eval_batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">moded_num_items</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">seq_mean_out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">concated_mean_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i_batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="n">end_i</span> <span class="o">=</span> <span class="n">start_i</span> <span class="o">+</span> <span class="n">eval_batch_size</span>

            <span class="n">results</span><span class="p">[:,</span> <span class="n">start_i</span><span class="p">:</span><span class="n">end_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">kl_distance_matmul</span><span class="p">(</span><span class="n">seq_mean_out</span><span class="p">,</span> <span class="n">seq_cov_out</span><span class="p">,</span> <span class="n">concated_mean_emb</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">end_i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">concated_cov_emb</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">end_i</span><span class="p">,</span> <span class="p">:])</span>
            <span class="c1">#results[:, start_i:end_i] = d2s_gaussiannormal(kl_distance_matmul(seq_mean_out, seq_cov_out, concated_mean_emb[start_i:end_i, :], concated_cov_emb[start_i:end_i, :]))</span>
            <span class="n">start_i</span> <span class="o">+=</span> <span class="n">eval_batch_size</span>

        <span class="c1">#print(results[:, :5])</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">[:,</span> <span class="p">:</span><span class="n">num_items</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="n">str_code</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="s2">&quot;test&quot;</span>

        <span class="c1">#rec_data_iter = tqdm.tqdm(enumerate(dataloader),</span>
        <span class="c1">#                          desc=f&quot;Recommendation EP_{str_code}:{epoch}&quot;,</span>
        <span class="c1">#                          total=len(dataloader),</span>
        <span class="c1">#                          bar_format=&quot;{l_bar}{r_bar}&quot;)</span>
        <span class="n">rec_data_iter</span> <span class="o">=</span> <span class="n">dataloader</span>

        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">rec_avg_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">rec_cur_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">rec_avg_pvn_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">rec_avg_auc</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c1">#for i, batch in rec_data_iter:</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">rec_data_iter</span><span class="p">:</span>
                <span class="c1"># 0. batch_data will be sent into the device(GPU or CPU)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
                <span class="n">user_ids</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>
                <span class="c1"># bpr optimization</span>
                <span class="n">sequence_mean_output</span><span class="p">,</span> <span class="n">sequence_cov_output</span><span class="p">,</span> <span class="n">att_scores</span><span class="p">,</span> <span class="n">margins</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">finetune</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">user_ids</span><span class="p">)</span>
                <span class="c1">#print(att_scores[0, 0, :, :])</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">batch_auc</span><span class="p">,</span> <span class="n">pvn_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_optimization</span><span class="p">(</span><span class="n">sequence_mean_output</span><span class="p">,</span> <span class="n">sequence_cov_output</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">)</span>
                <span class="c1">#loss, batch_auc, pvn_loss = self.margin_optimization(sequence_mean_output, sequence_cov_output, target_pos, target_neg, margins)</span>
                <span class="c1">#loss, batch_auc = self.ce_optimization(sequence_mean_output, sequence_cov_output, target_pos, target_neg)</span>

                <span class="n">loss</span> <span class="o">+=</span> <span class="n">pvn_loss</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">rec_avg_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">rec_cur_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">rec_avg_auc</span> <span class="o">+=</span> <span class="n">batch_auc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">rec_avg_pvn_loss</span> <span class="o">+=</span> <span class="n">pvn_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s2">&quot;rec_avg_loss&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_avg_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rec_data_iter</span><span class="p">)),</span>
                <span class="s2">&quot;rec_cur_loss&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_cur_loss</span><span class="p">),</span>
                <span class="s2">&quot;rec_avg_auc&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_avg_auc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rec_data_iter</span><span class="p">)),</span>
                <span class="s2">&quot;rec_avg_pvn_loss&quot;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rec_avg_pvn_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rec_data_iter</span><span class="p">)),</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="n">pred_list</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">full_sort</span><span class="p">:</span>
                <span class="n">answer_list</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="c1">#for i, batch in rec_data_iter:</span>
                    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">rec_data_iter</span><span class="p">:</span>
                        <span class="c1"># 0. batch_data will be sent into the device(GPU or cpu)</span>
                        <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
                        <span class="n">user_ids</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">target_pos</span><span class="p">,</span> <span class="n">target_neg</span><span class="p">,</span> <span class="n">answers</span> <span class="o">=</span> <span class="n">batch</span>
                        <span class="n">recommend_mean_output</span><span class="p">,</span> <span class="n">recommend_cov_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">finetune</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">user_ids</span><span class="p">)</span>

                        <span class="n">recommend_mean_output</span> <span class="o">=</span> <span class="n">recommend_mean_output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
                        <span class="n">recommend_cov_output</span> <span class="o">=</span> <span class="n">recommend_cov_output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">distance_metric</span> <span class="o">==</span> <span class="s1">&#39;kl&#39;</span><span class="p">:</span>
                            <span class="n">rating_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kl_predict_full</span><span class="p">(</span><span class="n">recommend_mean_output</span><span class="p">,</span> <span class="n">recommend_cov_output</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">rating_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_predict_full</span><span class="p">(</span><span class="n">recommend_mean_output</span><span class="p">,</span> <span class="n">recommend_cov_output</span><span class="p">)</span>
<span class="n">train_matrix</span>
                        <span class="n">rating_pred</span> <span class="o">=</span> <span class="n">rating_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                        <span class="n">batch_user_index</span> <span class="o">=</span> <span class="n">user_ids</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                        <span class="n">rating_pred</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">train_matrix</span><span class="p">[</span><span class="n">batch_user_index</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e+24</span>
                        <span class="c1"># reference: https://stackoverflow.com/a/23734295, https://stackoverflow.com/a/20104162</span>
                        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">,</span> <span class="mi">40</span><span class="p">)[:,</span> <span class="p">:</span><span class="mi">40</span><span class="p">]</span>
                        <span class="c1">#ind = np.argpartition(rating_pred, -40)[:, -40:]</span>
                        <span class="n">arr_ind</span> <span class="o">=</span> <span class="n">rating_pred</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">ind</span><span class="p">]</span>
                        <span class="c1"># ascending order</span>
                        <span class="n">arr_ind_argsort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">arr_ind</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">)),</span> <span class="p">::]</span>
                        <span class="c1">#arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]</span>
                        <span class="n">batch_pred_list</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rating_pred</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">arr_ind_argsort</span><span class="p">]</span>

                        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">pred_list</span> <span class="o">=</span> <span class="n">batch_pred_list</span>
                            <span class="n">answer_list</span> <span class="o">=</span> <span class="n">answers</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">pred_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_list</span><span class="p">,</span> <span class="n">batch_pred_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                            <span class="n">answer_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">answer_list</span><span class="p">,</span> <span class="n">answers</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_full_sort_score</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">answer_list</span><span class="p">,</span> <span class="n">pred_list</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Main">Main<a class="anchor-link" href="#Main"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>

<span class="c1"># from datasets import SASRecDataset</span>
<span class="c1"># from trainers import FinetuneTrainer, DistSAModelTrainer</span>
<span class="c1"># from models import S3RecModel</span>
<span class="c1"># from seqmodels import SASRecModel, DistSAModel, DistMeanSAModel</span>
<span class="c1"># from utils import EarlyStopping, get_user_seqs, get_item2attribute_json, check_path, set_seed</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--data_dir&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../data/&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--output_dir&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;output/&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--data_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;Beauty&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--do_eval&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--ckp&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;pretrain epochs 10, 20, 30...&quot;</span><span class="p">)</span>

<span class="c1"># model args</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--model_name&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;Finetune_full&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--hidden_size&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;hidden size of transformer model&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--num_hidden_layers&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of layers&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--num_attention_heads&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--hidden_act&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;GELU&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span> <span class="c1"># GELU relu</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--attention_probs_dropout_prob&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;attention dropout p&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--hidden_dropout_prob&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;hidden dropout p&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--initializer_range&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--distance_metric&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;wasserstein&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--pvn_weight&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--kernel_param&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># train args</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--lr&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;learning rate of adam&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--batch_size&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of batch_size&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--epochs&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of epochs&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--no_cuda&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--log_freq&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;per epoch print res&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--seed&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--weight_decay&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;weight_decay of adam&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--adam_beta1&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;adam first beta value&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--adam_beta2&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;adam second beta value&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--gpu_id&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;gpu_id&quot;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">([])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">seed_everything</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>output/ created
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">gpu_id</span>
<span class="n">args</span><span class="o">.</span><span class="n">cuda_condition</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">no_cuda</span>
<span class="n">args</span><span class="o">.</span><span class="n">cuda_condition</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">qq</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">RecoHut</span><span class="o">-</span><span class="n">Projects</span><span class="o">/</span><span class="n">recohut</span><span class="o">.</span><span class="n">git</span><span class="nd">@US632593</span>
<span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">q</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">RecoHut</span><span class="o">-</span><span class="n">Datasets</span><span class="o">/</span><span class="n">amazon_beauty</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">amazon</span><span class="o">-</span><span class="n">ratings</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">qq</span> <span class="n">amazon</span><span class="o">-</span><span class="n">ratings</span><span class="o">.</span><span class="n">zip</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">recohut.transforms.user_grouping</span> <span class="kn">import</span> <span class="n">create_user_sequences</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;ratings_Beauty.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">,</span><span class="s1">&#39;RATING&#39;</span><span class="p">,</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">]</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;USERID&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">USERID</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="n">seq_len</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)]</span>
<span class="n">create_user_sequences</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;./beautydata.txt&#39;</span><span class="p">)</span>

<span class="err">!</span><span class="n">wc</span> <span class="o">-</span><span class="n">l</span> <span class="n">beautydata</span><span class="o">.</span><span class="n">txt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>467 beautydata.txt
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">args</span><span class="o">.</span><span class="n">data_file</span> <span class="o">=</span> <span class="s1">&#39;./beautydata.txt&#39;</span>
<span class="c1"># args.data_file = args.data_dir + args.data_name + &#39;.txt&#39;</span>
<span class="c1">#item2attribute_file = args.data_dir + args.data_name + &#39;_item2attributes.json&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">user_seq</span><span class="p">,</span> <span class="n">max_item</span><span class="p">,</span> <span class="n">valid_rating_matrix</span><span class="p">,</span> <span class="n">test_rating_matrix</span><span class="p">,</span> <span class="n">num_users</span> <span class="o">=</span> \
    <span class="n">get_user_seqs</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_file</span><span class="p">)</span>

<span class="c1">#item2attribute, attribute_size = get_item2attribute_json(item2attribute_file)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">args</span><span class="o">.</span><span class="n">item_size</span> <span class="o">=</span> <span class="n">max_item</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">args</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>
<span class="n">args</span><span class="o">.</span><span class="n">mask_id</span> <span class="o">=</span> <span class="n">max_item</span> <span class="o">+</span> <span class="mi">1</span>
<span class="c1">#args.attribute_size = attribute_size + 1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">args_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">data_name</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_act</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">ckp</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">kernel_param</span><span class="si">}</span><span class="s1">-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">pvn_weight</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="n">args</span><span class="o">.</span><span class="n">log_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">args_str</span> <span class="o">+</span> <span class="s1">&#39;.txt&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#args.item2attribute = item2attribute</span>
<span class="c1"># set item score in train set to `0` in validation</span>
<span class="n">args</span><span class="o">.</span><span class="n">train_matrix</span> <span class="o">=</span> <span class="n">valid_rating_matrix</span>

<span class="c1"># save model</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">args_str</span> <span class="o">+</span> <span class="s1">&#39;.pt&#39;</span>
<span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Namespace(adam_beta1=0.9, adam_beta2=0.999, attention_probs_dropout_prob=0.5, batch_size=256, checkpoint_path=&#39;output/Finetune_full-Beauty-64-2-2-gelu-0.5-0.5-50-0.001-0.0-10-1.0-0.1.pt&#39;, ckp=10, cuda_condition=False, data_dir=&#39;../data/&#39;, data_file=&#39;./beautydata.txt&#39;, data_name=&#39;Beauty&#39;, distance_metric=&#39;wasserstein&#39;, do_eval=False, epochs=400, gpu_id=&#39;0&#39;, hidden_act=&#39;gelu&#39;, hidden_dropout_prob=0.5, hidden_size=64, initializer_range=0.02, item_size=5416, kernel_param=1.0, log_file=&#39;output/Finetune_full-Beauty-64-2-2-gelu-0.5-0.5-50-0.001-0.0-10-1.0-0.1.txt&#39;, log_freq=1, lr=0.001, mask_id=5415, max_seq_length=50, model_name=&#39;Finetune_full&#39;, no_cuda=False, num_attention_heads=2, num_hidden_layers=2, num_users=467, output_dir=&#39;output/&#39;, pvn_weight=0.1, seed=42, train_matrix=&lt;19898x14724 sparse matrix of type &#39;&lt;class &#39;numpy.longlong&#39;&gt;&#39;
	with 40 stored elements in Compressed Sparse Row format&gt;, weight_decay=0.0)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">SASRecDataset</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">SASRecDataset</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="n">eval_sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="c1">#eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=200)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">SASRecDataset</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">user_seq</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">test_sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
<span class="c1">#test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=200)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;DistSAModel&#39;</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DistSAModel</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
    <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">eval_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">test_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">DistSAModelTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span>
                                <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;DistMeanSAModel&#39;</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DistMeanSAModel</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
    <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">eval_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">test_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">DistSAModelTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span>
                                <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SASRecModel</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
    <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">eval_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">test_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">FinetuneTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span>
                            <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total Parameters: 449920
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_eval</span><span class="p">:</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Load model from </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s1"> for test!&#39;</span><span class="p">)</span>
    <span class="n">scores</span><span class="p">,</span> <span class="n">result_info</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="c1">#pretrained_path = os.path.join(args.output_dir, f&#39;{args.data_name}-epochs-{args.ckp}.pt&#39;)</span>
    <span class="c1">#try:</span>
    <span class="c1">#    trainer.load(pretrained_path)</span>
    <span class="c1">#    print(f&#39;Load Checkpoint From {pretrained_path}!&#39;)</span>

    <span class="c1">#except FileNotFoundError:</span>
    <span class="c1">#    print(f&#39;{pretrained_path} Not Found! The Model is same as SASRec&#39;)</span>
    
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;DistSAModel&#39;</span><span class="p">:</span>
        <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="c1"># evaluate on MRR</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">valid</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">early_stopping</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">early_stopping</span><span class="o">.</span><span class="n">early_stop</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Early stopping&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---------------Change to test_rating_matrix!-------------------&#39;</span><span class="p">)</span>
    <span class="c1"># load the best model</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">))</span>
    <span class="n">valid_scores</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">valid</span><span class="p">(</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">train_matrix</span> <span class="o">=</span> <span class="n">test_rating_matrix</span>
    <span class="n">scores</span><span class="p">,</span> <span class="n">result_info</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">full_sort</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;epoch&#39;: 0, &#39;rec_avg_loss&#39;: &#39;1.3923&#39;, &#39;rec_cur_loss&#39;: &#39;1.3926&#39;, &#39;rec_avg_auc&#39;: &#39;0.4950&#39;}
{&#39;Epoch&#39;: 0, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00370815&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00483491&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00583594&#39;, &#39;HIT@40&#39;: &#39;0.02355460&#39;, &#39;NDCG@40&#39;: &#39;0.00763461&#39;, &#39;MRR&#39;: &#39;0.00381115&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 1, &#39;rec_avg_loss&#39;: &#39;1.3777&#39;, &#39;rec_cur_loss&#39;: &#39;1.3777&#39;, &#39;rec_avg_auc&#39;: &#39;0.5489&#39;}
{&#39;Epoch&#39;: 1, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00296971&#39;, &#39;HIT@10&#39;: &#39;0.00428266&#39;, &#39;NDCG@10&#39;: &#39;0.00296971&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00465888&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00570664&#39;, &#39;HIT@40&#39;: &#39;0.02141328&#39;, &#39;NDCG@40&#39;: &#39;0.00707709&#39;, &#39;MRR&#39;: &#39;0.00359341&#39;}
EarlyStopping counter: 1 out of 50
{&#39;epoch&#39;: 2, &#39;rec_avg_loss&#39;: &#39;1.3624&#39;, &#39;rec_cur_loss&#39;: &#39;1.3576&#39;, &#39;rec_avg_auc&#39;: &#39;0.6090&#39;}
{&#39;Epoch&#39;: 2, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00343582&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00509599&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00558351&#39;, &#39;HIT@40&#39;: &#39;0.02141328&#39;, &#39;NDCG@40&#39;: &#39;0.00691520&#39;, &#39;MRR&#39;: &#39;0.00343840&#39;}
EarlyStopping counter: 2 out of 50
{&#39;epoch&#39;: 3, &#39;rec_avg_loss&#39;: &#39;1.3463&#39;, &#39;rec_cur_loss&#39;: &#39;1.3406&#39;, &#39;rec_avg_auc&#39;: &#39;0.6669&#39;}
{&#39;Epoch&#39;: 3, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00346145&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00519984&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00519984&#39;, &#39;HIT@40&#39;: &#39;0.02141328&#39;, &#39;NDCG@40&#39;: &#39;0.00699116&#39;, &#39;MRR&#39;: &#39;0.00351183&#39;}
EarlyStopping counter: 3 out of 50
{&#39;epoch&#39;: 4, &#39;rec_avg_loss&#39;: &#39;1.3318&#39;, &#39;rec_cur_loss&#39;: &#39;1.3292&#39;, &#39;rec_avg_auc&#39;: &#39;0.7117&#39;}
{&#39;Epoch&#39;: 4, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00408043&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00519443&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00519443&#39;, &#39;HIT@40&#39;: &#39;0.01927195&#39;, &#39;NDCG@40&#39;: &#39;0.00656656&#39;, &#39;MRR&#39;: &#39;0.00344371&#39;}
EarlyStopping counter: 4 out of 50
{&#39;epoch&#39;: 5, &#39;rec_avg_loss&#39;: &#39;1.3175&#39;, &#39;rec_cur_loss&#39;: &#39;1.3121&#39;, &#39;rec_avg_auc&#39;: &#39;0.7544&#39;}
{&#39;Epoch&#39;: 5, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00422420&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00480287&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00529833&#39;, &#39;HIT@40&#39;: &#39;0.01927195&#39;, &#39;NDCG@40&#39;: &#39;0.00658064&#39;, &#39;MRR&#39;: &#39;0.00350162&#39;}
EarlyStopping counter: 5 out of 50
{&#39;epoch&#39;: 6, &#39;rec_avg_loss&#39;: &#39;1.3034&#39;, &#39;rec_cur_loss&#39;: &#39;1.2993&#39;, &#39;rec_avg_auc&#39;: &#39;0.7899&#39;}
{&#39;Epoch&#39;: 6, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00414205&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00414205&#39;, &#39;HIT@20&#39;: &#39;0.01070664&#39;, &#39;NDCG@20&#39;: &#39;0.00466593&#39;, &#39;HIT@40&#39;: &#39;0.01498929&#39;, &#39;NDCG@40&#39;: &#39;0.00554166&#39;, &#39;MRR&#39;: &#39;0.00321255&#39;}
EarlyStopping counter: 6 out of 50
{&#39;epoch&#39;: 7, &#39;rec_avg_loss&#39;: &#39;1.2908&#39;, &#39;rec_cur_loss&#39;: &#39;1.2872&#39;, &#39;rec_avg_auc&#39;: &#39;0.8248&#39;}
{&#39;Epoch&#39;: 7, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00296971&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00358869&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00358869&#39;, &#39;HIT@20&#39;: &#39;0.01070664&#39;, &#39;NDCG@20&#39;: &#39;0.00458029&#39;, &#39;HIT@40&#39;: &#39;0.01284797&#39;, &#39;NDCG@40&#39;: &#39;0.00500120&#39;, &#39;MRR&#39;: &#39;0.00307464&#39;}
EarlyStopping counter: 7 out of 50
{&#39;epoch&#39;: 8, &#39;rec_avg_loss&#39;: &#39;1.2765&#39;, &#39;rec_cur_loss&#39;: &#39;1.2767&#39;, &#39;rec_avg_auc&#39;: &#39;0.8554&#39;}
{&#39;Epoch&#39;: 8, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00428266&#39;, &#39;NDCG@10&#39;: &#39;0.00290408&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00346650&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00399038&#39;, &#39;HIT@40&#39;: &#39;0.01284797&#39;, &#39;NDCG@40&#39;: &#39;0.00489628&#39;, &#39;MRR&#39;: &#39;0.00296478&#39;}
EarlyStopping counter: 8 out of 50
{&#39;epoch&#39;: 9, &#39;rec_avg_loss&#39;: &#39;1.2647&#39;, &#39;rec_cur_loss&#39;: &#39;1.2628&#39;, &#39;rec_avg_auc&#39;: &#39;0.8749&#39;}
{&#39;Epoch&#39;: 9, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00214133&#39;, &#39;NDCG@5&#39;: &#39;0.00214133&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00347409&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00347409&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00399796&#39;, &#39;HIT@40&#39;: &#39;0.01284797&#39;, &#39;NDCG@40&#39;: &#39;0.00486789&#39;, &#39;MRR&#39;: &#39;0.00294142&#39;}
EarlyStopping counter: 9 out of 50
{&#39;epoch&#39;: 10, &#39;rec_avg_loss&#39;: &#39;1.2502&#39;, &#39;rec_cur_loss&#39;: &#39;1.2483&#39;, &#39;rec_avg_auc&#39;: &#39;0.8932&#39;}
{&#39;Epoch&#39;: 10, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00296971&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00364522&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00364522&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00414068&#39;, &#39;HIT@40&#39;: &#39;0.01498929&#39;, &#39;NDCG@40&#39;: &#39;0.00539349&#39;, &#39;MRR&#39;: &#39;0.00313976&#39;}
EarlyStopping counter: 10 out of 50
{&#39;epoch&#39;: 11, &#39;rec_avg_loss&#39;: &#39;1.2365&#39;, &#39;rec_cur_loss&#39;: &#39;1.2320&#39;, &#39;rec_avg_auc&#39;: &#39;0.9196&#39;}
{&#39;Epoch&#39;: 11, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00428266&#39;, &#39;NDCG@10&#39;: &#39;0.00306355&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00359888&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00409434&#39;, &#39;HIT@40&#39;: &#39;0.01498929&#39;, &#39;NDCG@40&#39;: &#39;0.00545153&#39;, &#39;MRR&#39;: &#39;0.00318418&#39;}
EarlyStopping counter: 11 out of 50
{&#39;epoch&#39;: 12, &#39;rec_avg_loss&#39;: &#39;1.2240&#39;, &#39;rec_cur_loss&#39;: &#39;1.2209&#39;, &#39;rec_avg_auc&#39;: &#39;0.9329&#39;}
{&#39;Epoch&#39;: 12, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00428266&#39;, &#39;NDCG@10&#39;: &#39;0.00349235&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00405477&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00456829&#39;, &#39;HIT@40&#39;: &#39;0.01498929&#39;, &#39;NDCG@40&#39;: &#39;0.00591884&#39;, &#39;MRR&#39;: &#39;0.00375032&#39;}
EarlyStopping counter: 12 out of 50
{&#39;epoch&#39;: 13, &#39;rec_avg_loss&#39;: &#39;1.2132&#39;, &#39;rec_cur_loss&#39;: &#39;1.2094&#39;, &#39;rec_avg_auc&#39;: &#39;0.9416&#39;}
{&#39;Epoch&#39;: 13, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00392577&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00447386&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00447386&#39;, &#39;HIT@40&#39;: &#39;0.02355460&#39;, &#39;NDCG@40&#39;: &#39;0.00736749&#39;, &#39;MRR&#39;: &#39;0.00374039&#39;}
EarlyStopping counter: 13 out of 50
{&#39;epoch&#39;: 14, &#39;rec_avg_loss&#39;: &#39;1.2000&#39;, &#39;rec_cur_loss&#39;: &#39;1.1962&#39;, &#39;rec_avg_auc&#39;: &#39;0.9547&#39;}
{&#39;Epoch&#39;: 14, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00428266&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00428266&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00487996&#39;, &#39;HIT@20&#39;: &#39;0.00856531&#39;, &#39;NDCG@20&#39;: &#39;0.00487996&#39;, &#39;HIT@40&#39;: &#39;0.02141328&#39;, &#39;NDCG@40&#39;: &#39;0.00746445&#39;, &#39;MRR&#39;: &#39;0.00419008&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 15, &#39;rec_avg_loss&#39;: &#39;1.1861&#39;, &#39;rec_cur_loss&#39;: &#39;1.1829&#39;, &#39;rec_avg_auc&#39;: &#39;0.9641&#39;}
{&#39;Epoch&#39;: 15, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00441457&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00505918&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00505918&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00609657&#39;, &#39;HIT@40&#39;: &#39;0.02141328&#39;, &#39;NDCG@40&#39;: &#39;0.00781558&#39;, &#39;MRR&#39;: &#39;0.00452814&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 16, &#39;rec_avg_loss&#39;: &#39;1.1739&#39;, &#39;rec_cur_loss&#39;: &#39;1.1714&#39;, &#39;rec_avg_auc&#39;: &#39;0.9698&#39;}
{&#39;Epoch&#39;: 16, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00432073&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00496534&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00612267&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00662676&#39;, &#39;HIT@40&#39;: &#39;0.02783726&#39;, &#39;NDCG@40&#39;: &#39;0.00913927&#39;, &#39;MRR&#39;: &#39;0.00474053&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 17, &#39;rec_avg_loss&#39;: &#39;1.1627&#39;, &#39;rec_cur_loss&#39;: &#39;1.1610&#39;, &#39;rec_avg_auc&#39;: &#39;0.9753&#39;}
{&#39;Epoch&#39;: 17, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00432073&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00567911&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00735984&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00735984&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01030250&#39;, &#39;MRR&#39;: &#39;0.00512781&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 18, &#39;rec_avg_loss&#39;: &#39;1.1506&#39;, &#39;rec_cur_loss&#39;: &#39;1.1476&#39;, &#39;rec_avg_auc&#39;: &#39;0.9792&#39;}
{&#39;Epoch&#39;: 18, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00432073&#39;, &#39;HIT@10&#39;: &#39;0.01498929&#39;, &#39;NDCG@10&#39;: &#39;0.00694270&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00752137&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00800888&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.01020593&#39;, &#39;MRR&#39;: &#39;0.00530025&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 19, &#39;rec_avg_loss&#39;: &#39;1.1418&#39;, &#39;rec_cur_loss&#39;: &#39;1.1391&#39;, &#39;rec_avg_auc&#39;: &#39;0.9795&#39;}
{&#39;Epoch&#39;: 19, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.01498929&#39;, &#39;NDCG@10&#39;: &#39;0.00696452&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00754319&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00804727&#39;, &#39;HIT@40&#39;: &#39;0.03640257&#39;, &#39;NDCG@40&#39;: &#39;0.01154242&#39;, &#39;MRR&#39;: &#39;0.00554160&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 20, &#39;rec_avg_loss&#39;: &#39;1.1276&#39;, &#39;rec_cur_loss&#39;: &#39;1.1216&#39;, &#39;rec_avg_auc&#39;: &#39;0.9857&#39;}
{&#39;Epoch&#39;: 20, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00432073&#39;, &#39;HIT@10&#39;: &#39;0.01713062&#39;, &#39;NDCG@10&#39;: &#39;0.00774901&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00774901&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00874061&#39;, &#39;HIT@40&#39;: &#39;0.03854390&#39;, &#39;NDCG@40&#39;: &#39;0.01224029&#39;, &#39;MRR&#39;: &#39;0.00586285&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 21, &#39;rec_avg_loss&#39;: &#39;1.1171&#39;, &#39;rec_cur_loss&#39;: &#39;1.1186&#39;, &#39;rec_avg_auc&#39;: &#39;0.9856&#39;}
{&#39;Epoch&#39;: 21, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00432073&#39;, &#39;HIT@10&#39;: &#39;0.01284797&#39;, &#39;NDCG@10&#39;: &#39;0.00644187&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00760160&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00861057&#39;, &#39;HIT@40&#39;: &#39;0.04068522&#39;, &#39;NDCG@40&#39;: &#39;0.01256960&#39;, &#39;MRR&#39;: &#39;0.00582511&#39;}
EarlyStopping counter: 1 out of 50
{&#39;epoch&#39;: 22, &#39;rec_avg_loss&#39;: &#39;1.1057&#39;, &#39;rec_cur_loss&#39;: &#39;1.1089&#39;, &#39;rec_avg_auc&#39;: &#39;0.9885&#39;}
{&#39;Epoch&#39;: 22, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00856531&#39;, &#39;NDCG@5&#39;: &#39;0.00593941&#39;, &#39;HIT@10&#39;: &#39;0.01284797&#39;, &#39;NDCG@10&#39;: &#39;0.00727217&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00843190&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00943144&#39;, &#39;HIT@40&#39;: &#39;0.04068522&#39;, &#39;NDCG@40&#39;: &#39;0.01346229&#39;, &#39;MRR&#39;: &#39;0.00697899&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 23, &#39;rec_avg_loss&#39;: &#39;1.0948&#39;, &#39;rec_cur_loss&#39;: &#39;1.0907&#39;, &#39;rec_avg_auc&#39;: &#39;0.9892&#39;}
{&#39;Epoch&#39;: 23, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00856531&#39;, &#39;NDCG@5&#39;: &#39;0.00603325&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00674703&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00844209&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00894618&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01384973&#39;, &#39;MRR&#39;: &#39;0.00705293&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 24, &#39;rec_avg_loss&#39;: &#39;1.0859&#39;, &#39;rec_cur_loss&#39;: &#39;1.0875&#39;, &#39;rec_avg_auc&#39;: &#39;0.9904&#39;}
{&#39;Epoch&#39;: 24, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00511103&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00658757&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00774729&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00878469&#39;, &#39;HIT@40&#39;: &#39;0.04496788&#39;, &#39;NDCG@40&#39;: &#39;0.01409598&#39;, &#39;MRR&#39;: &#39;0.00693024&#39;}
EarlyStopping counter: 1 out of 50
{&#39;epoch&#39;: 25, &#39;rec_avg_loss&#39;: &#39;1.0767&#39;, &#39;rec_cur_loss&#39;: &#39;1.0788&#39;, &#39;rec_avg_auc&#39;: &#39;0.9895&#39;}
{&#39;Epoch&#39;: 25, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00511103&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00653859&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00768398&#39;, &#39;HIT@20&#39;: &#39;0.02355460&#39;, &#39;NDCG@20&#39;: &#39;0.00967513&#39;, &#39;HIT@40&#39;: &#39;0.04925054&#39;, &#39;NDCG@40&#39;: &#39;0.01488293&#39;, &#39;MRR&#39;: &#39;0.00700291&#39;}
EarlyStopping counter: 2 out of 50
{&#39;epoch&#39;: 26, &#39;rec_avg_loss&#39;: &#39;1.0655&#39;, &#39;rec_cur_loss&#39;: &#39;1.0641&#39;, &#39;rec_avg_auc&#39;: &#39;0.9896&#39;}
{&#39;Epoch&#39;: 26, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00535332&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00668608&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00783148&#39;, &#39;HIT@20&#39;: &#39;0.02355460&#39;, &#39;NDCG@20&#39;: &#39;0.00984862&#39;, &#39;HIT@40&#39;: &#39;0.04925054&#39;, &#39;NDCG@40&#39;: &#39;0.01510945&#39;, &#39;MRR&#39;: &#39;0.00724777&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 27, &#39;rec_avg_loss&#39;: &#39;1.0598&#39;, &#39;rec_cur_loss&#39;: &#39;1.0582&#39;, &#39;rec_avg_auc&#39;: &#39;0.9918&#39;}
{&#39;Epoch&#39;: 27, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00535332&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00668608&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00782716&#39;, &#39;HIT@20&#39;: &#39;0.02355460&#39;, &#39;NDCG@20&#39;: &#39;0.00985467&#39;, &#39;HIT@40&#39;: &#39;0.04925054&#39;, &#39;NDCG@40&#39;: &#39;0.01513960&#39;, &#39;MRR&#39;: &#39;0.00726614&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 28, &#39;rec_avg_loss&#39;: &#39;1.0470&#39;, &#39;rec_cur_loss&#39;: &#39;1.0463&#39;, &#39;rec_avg_auc&#39;: &#39;0.9913&#39;}
{&#39;Epoch&#39;: 28, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00535332&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00674261&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00788370&#39;, &#39;HIT@20&#39;: &#39;0.02569593&#39;, &#39;NDCG@20&#39;: &#39;0.01036236&#39;, &#39;HIT@40&#39;: &#39;0.04925054&#39;, &#39;NDCG@40&#39;: &#39;0.01518074&#39;, &#39;MRR&#39;: &#39;0.00730709&#39;}
Validation score increased.  Saving model ...
{&#39;epoch&#39;: 29, &#39;rec_avg_loss&#39;: &#39;1.0382&#39;, &#39;rec_cur_loss&#39;: &#39;1.0399&#39;, &#39;rec_avg_auc&#39;: &#39;0.9905&#39;}
{&#39;Epoch&#39;: 29, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00428266&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00567194&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00674261&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00827373&#39;, &#39;HIT@40&#39;: &#39;0.04925054&#39;, &#39;NDCG@40&#39;: &#39;0.01401761&#39;, &#39;MRR&#39;: &#39;0.00581048&#39;}
EarlyStopping counter: 1 out of 50
{&#39;epoch&#39;: 30, &#39;rec_avg_loss&#39;: &#39;1.0275&#39;, &#39;rec_cur_loss&#39;: &#39;1.0242&#39;, &#39;rec_avg_auc&#39;: &#39;0.9922&#39;}
{&#39;Epoch&#39;: 30, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00413421&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00546697&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00546697&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00799764&#39;, &#39;HIT@40&#39;: &#39;0.04710921&#39;, &#39;NDCG@40&#39;: &#39;0.01337040&#39;, &#39;MRR&#39;: &#39;0.00549288&#39;}
EarlyStopping counter: 2 out of 50
{&#39;epoch&#39;: 31, &#39;rec_avg_loss&#39;: &#39;1.0234&#39;, &#39;rec_cur_loss&#39;: &#39;1.0224&#39;, &#39;rec_avg_auc&#39;: &#39;0.9939&#39;}
{&#39;Epoch&#39;: 31, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00454008&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00567272&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00764879&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01215482&#39;, &#39;MRR&#39;: &#39;0.00495561&#39;}
EarlyStopping counter: 3 out of 50
{&#39;epoch&#39;: 32, &#39;rec_avg_loss&#39;: &#39;1.0113&#39;, &#39;rec_cur_loss&#39;: &#39;1.0111&#39;, &#39;rec_avg_auc&#39;: &#39;0.9920&#39;}
{&#39;Epoch&#39;: 32, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00449110&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00563650&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00713299&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01203953&#39;, &#39;MRR&#39;: &#39;0.00486666&#39;}
EarlyStopping counter: 4 out of 50
{&#39;epoch&#39;: 33, &#39;rec_avg_loss&#39;: &#39;1.0051&#39;, &#39;rec_cur_loss&#39;: &#39;1.0012&#39;, &#39;rec_avg_auc&#39;: &#39;0.9909&#39;}
{&#39;Epoch&#39;: 33, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00449110&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00560161&#39;, &#39;HIT@20&#39;: &#39;0.02355460&#39;, &#39;NDCG@20&#39;: &#39;0.00809119&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01204195&#39;, &#39;MRR&#39;: &#39;0.00486397&#39;}
EarlyStopping counter: 5 out of 50
{&#39;epoch&#39;: 34, &#39;rec_avg_loss&#39;: &#39;0.9948&#39;, &#39;rec_cur_loss&#39;: &#39;0.9933&#39;, &#39;rec_avg_auc&#39;: &#39;0.9905&#39;}
{&#39;Epoch&#39;: 34, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00296971&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00439726&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00550777&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00753676&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01197258&#39;, &#39;MRR&#39;: &#39;0.00477461&#39;}
EarlyStopping counter: 6 out of 50
{&#39;epoch&#39;: 35, &#39;rec_avg_loss&#39;: &#39;0.9872&#39;, &#39;rec_cur_loss&#39;: &#39;0.9848&#39;, &#39;rec_avg_auc&#39;: &#39;0.9927&#39;}
{&#39;Epoch&#39;: 35, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00449110&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00560161&#39;, &#39;HIT@20&#39;: &#39;0.02569593&#39;, &#39;NDCG@20&#39;: &#39;0.00862922&#39;, &#39;HIT@40&#39;: &#39;0.04496788&#39;, &#39;NDCG@40&#39;: &#39;0.01254311&#39;, &#39;MRR&#39;: &#39;0.00498567&#39;}
EarlyStopping counter: 7 out of 50
{&#39;epoch&#39;: 36, &#39;rec_avg_loss&#39;: &#39;0.9805&#39;, &#39;rec_cur_loss&#39;: &#39;0.9748&#39;, &#39;rec_avg_auc&#39;: &#39;0.9941&#39;}
{&#39;Epoch&#39;: 36, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00449110&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00560161&#39;, &#39;HIT@20&#39;: &#39;0.02783726&#39;, &#39;NDCG@20&#39;: &#39;0.00917289&#39;, &#39;HIT@40&#39;: &#39;0.04496788&#39;, &#39;NDCG@40&#39;: &#39;0.01263526&#39;, &#39;MRR&#39;: &#39;0.00504968&#39;}
EarlyStopping counter: 8 out of 50
{&#39;epoch&#39;: 37, &#39;rec_avg_loss&#39;: &#39;0.9688&#39;, &#39;rec_cur_loss&#39;: &#39;0.9660&#39;, &#39;rec_avg_auc&#39;: &#39;0.9944&#39;}
{&#39;Epoch&#39;: 37, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00445284&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00663401&#39;, &#39;HIT@20&#39;: &#39;0.02783726&#39;, &#39;NDCG@20&#39;: &#39;0.00915777&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01222348&#39;, &#39;MRR&#39;: &#39;0.00497816&#39;}
EarlyStopping counter: 9 out of 50
{&#39;epoch&#39;: 38, &#39;rec_avg_loss&#39;: &#39;0.9684&#39;, &#39;rec_cur_loss&#39;: &#39;0.9722&#39;, &#39;rec_avg_auc&#39;: &#39;0.9917&#39;}
{&#39;Epoch&#39;: 38, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00377732&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00655580&#39;, &#39;HIT@20&#39;: &#39;0.02569593&#39;, &#39;NDCG@20&#39;: &#39;0.00858411&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01214591&#39;, &#39;MRR&#39;: &#39;0.00490377&#39;}
EarlyStopping counter: 10 out of 50
{&#39;epoch&#39;: 39, &#39;rec_avg_loss&#39;: &#39;0.9601&#39;, &#39;rec_cur_loss&#39;: &#39;0.9646&#39;, &#39;rec_avg_auc&#39;: &#39;0.9916&#39;}
{&#39;Epoch&#39;: 39, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00377732&#39;, &#39;HIT@15&#39;: &#39;0.01927195&#39;, &#39;NDCG@15&#39;: &#39;0.00701483&#39;, &#39;HIT@20&#39;: &#39;0.02569593&#39;, &#39;NDCG@20&#39;: &#39;0.00852789&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01209009&#39;, &#39;MRR&#39;: &#39;0.00485634&#39;}
EarlyStopping counter: 11 out of 50
{&#39;epoch&#39;: 40, &#39;rec_avg_loss&#39;: &#39;0.9572&#39;, &#39;rec_cur_loss&#39;: &#39;0.9615&#39;, &#39;rec_avg_auc&#39;: &#39;0.9916&#39;}
{&#39;Epoch&#39;: 40, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00377732&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00646674&#39;, &#39;HIT@20&#39;: &#39;0.02569593&#39;, &#39;NDCG@20&#39;: &#39;0.00849332&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01202577&#39;, &#39;MRR&#39;: &#39;0.00481054&#39;}
EarlyStopping counter: 12 out of 50
{&#39;epoch&#39;: 41, &#39;rec_avg_loss&#39;: &#39;0.9441&#39;, &#39;rec_cur_loss&#39;: &#39;0.9385&#39;, &#39;rec_avg_auc&#39;: &#39;0.9917&#39;}
{&#39;Epoch&#39;: 41, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00377732&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00538332&#39;, &#39;HIT@20&#39;: &#39;0.02355460&#39;, &#39;NDCG@20&#39;: &#39;0.00791720&#39;, &#39;HIT@40&#39;: &#39;0.04282655&#39;, &#39;NDCG@40&#39;: &#39;0.01189013&#39;, &#39;MRR&#39;: &#39;0.00471382&#39;}
EarlyStopping counter: 13 out of 50
{&#39;epoch&#39;: 42, &#39;rec_avg_loss&#39;: &#39;0.9431&#39;, &#39;rec_cur_loss&#39;: &#39;0.9434&#39;, &#39;rec_avg_auc&#39;: &#39;0.9908&#39;}
{&#39;Epoch&#39;: 42, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00373906&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00427439&#39;, &#39;HIT@20&#39;: &#39;0.02141328&#39;, &#39;NDCG@20&#39;: &#39;0.00732179&#39;, &#39;HIT@40&#39;: &#39;0.04068522&#39;, &#39;NDCG@40&#39;: &#39;0.01131117&#39;, &#39;MRR&#39;: &#39;0.00452524&#39;}
EarlyStopping counter: 14 out of 50
{&#39;epoch&#39;: 43, &#39;rec_avg_loss&#39;: &#39;0.9339&#39;, &#39;rec_cur_loss&#39;: &#39;0.9311&#39;, &#39;rec_avg_auc&#39;: &#39;0.9917&#39;}
{&#39;Epoch&#39;: 43, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00373906&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00480972&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00631415&#39;, &#39;HIT@40&#39;: &#39;0.04068522&#39;, &#39;NDCG@40&#39;: &#39;0.01121695&#39;, &#39;MRR&#39;: &#39;0.00446290&#39;}
EarlyStopping counter: 15 out of 50
{&#39;epoch&#39;: 44, &#39;rec_avg_loss&#39;: &#39;0.9274&#39;, &#39;rec_cur_loss&#39;: &#39;0.9290&#39;, &#39;rec_avg_auc&#39;: &#39;0.9906&#39;}
{&#39;Epoch&#39;: 44, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00373906&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00484957&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00585854&#39;, &#39;HIT@40&#39;: &#39;0.04068522&#39;, &#39;NDCG@40&#39;: &#39;0.01119913&#39;, &#39;MRR&#39;: &#39;0.00445866&#39;}
EarlyStopping counter: 16 out of 50
{&#39;epoch&#39;: 45, &#39;rec_avg_loss&#39;: &#39;0.9199&#39;, &#39;rec_cur_loss&#39;: &#39;0.9328&#39;, &#39;rec_avg_auc&#39;: &#39;0.9915&#39;}
{&#39;Epoch&#39;: 45, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00388751&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00499801&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00552189&#39;, &#39;HIT@40&#39;: &#39;0.03854390&#39;, &#39;NDCG@40&#39;: &#39;0.01088243&#39;, &#39;MRR&#39;: &#39;0.00454266&#39;}
EarlyStopping counter: 17 out of 50
{&#39;epoch&#39;: 46, &#39;rec_avg_loss&#39;: &#39;0.9082&#39;, &#39;rec_cur_loss&#39;: &#39;0.9063&#39;, &#39;rec_avg_auc&#39;: &#39;0.9908&#39;}
{&#39;Epoch&#39;: 46, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00388751&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00443560&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00547299&#39;, &#39;HIT@40&#39;: &#39;0.03854390&#39;, &#39;NDCG@40&#39;: &#39;0.01076889&#39;, &#39;MRR&#39;: &#39;0.00446460&#39;}
EarlyStopping counter: 18 out of 50
{&#39;epoch&#39;: 47, &#39;rec_avg_loss&#39;: &#39;0.9040&#39;, &#39;rec_cur_loss&#39;: &#39;0.9010&#39;, &#39;rec_avg_auc&#39;: &#39;0.9901&#39;}
{&#39;Epoch&#39;: 47, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00385660&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00440469&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00543172&#39;, &#39;HIT@40&#39;: &#39;0.03854390&#39;, &#39;NDCG@40&#39;: &#39;0.01068726&#39;, &#39;MRR&#39;: &#39;0.00440277&#39;}
EarlyStopping counter: 19 out of 50
{&#39;epoch&#39;: 48, &#39;rec_avg_loss&#39;: &#39;0.9040&#39;, &#39;rec_cur_loss&#39;: &#39;0.8955&#39;, &#39;rec_avg_auc&#39;: &#39;0.9915&#39;}
{&#39;Epoch&#39;: 48, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00428266&#39;, &#39;NDCG@10&#39;: &#39;0.00321199&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00434463&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00537260&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.00982588&#39;, &#39;MRR&#39;: &#39;0.00424239&#39;}
EarlyStopping counter: 20 out of 50
{&#39;epoch&#39;: 49, &#39;rec_avg_loss&#39;: &#39;0.8965&#39;, &#39;rec_cur_loss&#39;: &#39;0.8800&#39;, &#39;rec_avg_auc&#39;: &#39;0.9906&#39;}
{&#39;Epoch&#39;: 49, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00428266&#39;, &#39;NDCG@10&#39;: &#39;0.00321199&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00434463&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00538203&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.00982265&#39;, &#39;MRR&#39;: &#39;0.00424275&#39;}
EarlyStopping counter: 21 out of 50
{&#39;epoch&#39;: 50, &#39;rec_avg_loss&#39;: &#39;0.8907&#39;, &#39;rec_cur_loss&#39;: &#39;0.8916&#39;, &#39;rec_avg_auc&#39;: &#39;0.9884&#39;}
{&#39;Epoch&#39;: 50, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00411134&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00411134&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00565282&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.00966820&#39;, &#39;MRR&#39;: &#39;0.00452724&#39;}
EarlyStopping counter: 22 out of 50
{&#39;epoch&#39;: 51, &#39;rec_avg_loss&#39;: &#39;0.8830&#39;, &#39;rec_cur_loss&#39;: &#39;0.8801&#39;, &#39;rec_avg_auc&#39;: &#39;0.9912&#39;}
{&#39;Epoch&#39;: 51, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00383097&#39;, &#39;HIT@15&#39;: &#39;0.00642398&#39;, &#39;NDCG@15&#39;: &#39;0.00383097&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00586618&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.00979756&#39;, &#39;MRR&#39;: &#39;0.00423040&#39;}
EarlyStopping counter: 23 out of 50
{&#39;epoch&#39;: 52, &#39;rec_avg_loss&#39;: &#39;0.8772&#39;, &#39;rec_cur_loss&#39;: &#39;0.8804&#39;, &#39;rec_avg_auc&#39;: &#39;0.9895&#39;}
{&#39;Epoch&#39;: 52, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00368253&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00421786&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00571435&#39;, &#39;HIT@40&#39;: &#39;0.03640257&#39;, &#39;NDCG@40&#39;: &#39;0.01002081&#39;, &#39;MRR&#39;: &#39;0.00408977&#39;}
EarlyStopping counter: 24 out of 50
{&#39;epoch&#39;: 53, &#39;rec_avg_loss&#39;: &#39;0.8758&#39;, &#39;rec_cur_loss&#39;: &#39;0.8774&#39;, &#39;rec_avg_auc&#39;: &#39;0.9913&#39;}
{&#39;Epoch&#39;: 53, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00368253&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00476595&#39;, &#39;HIT@20&#39;: &#39;0.01284797&#39;, &#39;NDCG@20&#39;: &#39;0.00525347&#39;, &#39;HIT@40&#39;: &#39;0.03640257&#39;, &#39;NDCG@40&#39;: &#39;0.01000768&#39;, &#39;MRR&#39;: &#39;0.00408682&#39;}
EarlyStopping counter: 25 out of 50
{&#39;epoch&#39;: 54, &#39;rec_avg_loss&#39;: &#39;0.8675&#39;, &#39;rec_cur_loss&#39;: &#39;0.8562&#39;, &#39;rec_avg_auc&#39;: &#39;0.9886&#39;}
{&#39;Epoch&#39;: 54, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00368253&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00477871&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00576962&#39;, &#39;HIT@40&#39;: &#39;0.03854390&#39;, &#39;NDCG@40&#39;: &#39;0.01043911&#39;, &#39;MRR&#39;: &#39;0.00416361&#39;}
EarlyStopping counter: 26 out of 50
{&#39;epoch&#39;: 55, &#39;rec_avg_loss&#39;: &#39;0.8623&#39;, &#39;rec_cur_loss&#39;: &#39;0.8703&#39;, &#39;rec_avg_auc&#39;: &#39;0.9875&#39;}
{&#39;Epoch&#39;: 55, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00306355&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00368253&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00482362&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00583259&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.00966026&#39;, &#39;MRR&#39;: &#39;0.00408289&#39;}
EarlyStopping counter: 27 out of 50
{&#39;epoch&#39;: 56, &#39;rec_avg_loss&#39;: &#39;0.8557&#39;, &#39;rec_cur_loss&#39;: &#39;0.8603&#39;, &#39;rec_avg_auc&#39;: &#39;0.9902&#39;}
{&#39;Epoch&#39;: 56, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00383097&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00552603&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00601355&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.00943728&#39;, &#39;MRR&#39;: &#39;0.00423419&#39;}
EarlyStopping counter: 28 out of 50
{&#39;epoch&#39;: 57, &#39;rec_avg_loss&#39;: &#39;0.8496&#39;, &#39;rec_cur_loss&#39;: &#39;0.8480&#39;, &#39;rec_avg_auc&#39;: &#39;0.9895&#39;}
{&#39;Epoch&#39;: 57, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00413696&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00584478&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00633229&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.01017521&#39;, &#39;MRR&#39;: &#39;0.00468948&#39;}
EarlyStopping counter: 29 out of 50
{&#39;epoch&#39;: 58, &#39;rec_avg_loss&#39;: &#39;0.8461&#39;, &#39;rec_cur_loss&#39;: &#39;0.8400&#39;, &#39;rec_avg_auc&#39;: &#39;0.9856&#39;}
{&#39;Epoch&#39;: 58, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00416787&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00585705&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00634456&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.01022758&#39;, &#39;MRR&#39;: &#39;0.00472589&#39;}
EarlyStopping counter: 30 out of 50
{&#39;epoch&#39;: 59, &#39;rec_avg_loss&#39;: &#39;0.8464&#39;, &#39;rec_cur_loss&#39;: &#39;0.8527&#39;, &#39;rec_avg_auc&#39;: &#39;0.9890&#39;}
{&#39;Epoch&#39;: 59, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00642398&#39;, &#39;NDCG@10&#39;: &#39;0.00416787&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00588762&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00638308&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.01025735&#39;, &#39;MRR&#39;: &#39;0.00475239&#39;}
EarlyStopping counter: 31 out of 50
{&#39;epoch&#39;: 60, &#39;rec_avg_loss&#39;: &#39;0.8399&#39;, &#39;rec_cur_loss&#39;: &#39;0.8357&#39;, &#39;rec_avg_auc&#39;: &#39;0.9879&#39;}
{&#39;Epoch&#39;: 60, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00478685&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00592794&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00643203&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.00987578&#39;, &#39;MRR&#39;: &#39;0.00472419&#39;}
EarlyStopping counter: 32 out of 50
{&#39;epoch&#39;: 61, &#39;rec_avg_loss&#39;: &#39;0.8280&#39;, &#39;rec_cur_loss&#39;: &#39;0.8313&#39;, &#39;rec_avg_auc&#39;: &#39;0.9875&#39;}
{&#39;Epoch&#39;: 61, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00453211&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00509453&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00612249&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00912791&#39;, &#39;MRR&#39;: &#39;0.00427104&#39;}
EarlyStopping counter: 33 out of 50
{&#39;epoch&#39;: 62, &#39;rec_avg_loss&#39;: &#39;0.8244&#39;, &#39;rec_cur_loss&#39;: &#39;0.8345&#39;, &#39;rec_avg_auc&#39;: &#39;0.9904&#39;}
{&#39;Epoch&#39;: 62, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00321199&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00453211&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00509453&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00609407&#39;, &#39;HIT@40&#39;: &#39;0.02783726&#39;, &#39;NDCG@40&#39;: &#39;0.00871227&#39;, &#39;MRR&#39;: &#39;0.00420309&#39;}
EarlyStopping counter: 34 out of 50
{&#39;epoch&#39;: 63, &#39;rec_avg_loss&#39;: &#39;0.8205&#39;, &#39;rec_cur_loss&#39;: &#39;0.8220&#39;, &#39;rec_avg_auc&#39;: &#39;0.9903&#39;}
{&#39;Epoch&#39;: 63, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00488164&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00542973&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00642928&#39;, &#39;HIT@40&#39;: &#39;0.02783726&#39;, &#39;NDCG@40&#39;: &#39;0.00905101&#39;, &#39;MRR&#39;: &#39;0.00461821&#39;}
EarlyStopping counter: 35 out of 50
{&#39;epoch&#39;: 64, &#39;rec_avg_loss&#39;: &#39;0.8046&#39;, &#39;rec_cur_loss&#39;: &#39;0.8043&#39;, &#39;rec_avg_auc&#39;: &#39;0.9908&#39;}
{&#39;Epoch&#39;: 64, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00488164&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00541698&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00640789&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.00984720&#39;, &#39;MRR&#39;: &#39;0.00471927&#39;}
EarlyStopping counter: 36 out of 50
{&#39;epoch&#39;: 65, &#39;rec_avg_loss&#39;: &#39;0.8057&#39;, &#39;rec_cur_loss&#39;: &#39;0.8077&#39;, &#39;rec_avg_auc&#39;: &#39;0.9889&#39;}
{&#39;Epoch&#39;: 65, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00488164&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00488164&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00638677&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00944274&#39;, &#39;MRR&#39;: &#39;0.00465860&#39;}
EarlyStopping counter: 37 out of 50
{&#39;epoch&#39;: 66, &#39;rec_avg_loss&#39;: &#39;0.8014&#39;, &#39;rec_cur_loss&#39;: &#39;0.8002&#39;, &#39;rec_avg_auc&#39;: &#39;0.9898&#39;}
{&#39;Epoch&#39;: 66, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00488164&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00488164&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00638849&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00945799&#39;, &#39;MRR&#39;: &#39;0.00466848&#39;}
EarlyStopping counter: 38 out of 50
{&#39;epoch&#39;: 67, &#39;rec_avg_loss&#39;: &#39;0.7962&#39;, &#39;rec_cur_loss&#39;: &#39;0.8004&#39;, &#39;rec_avg_auc&#39;: &#39;0.9882&#39;}
{&#39;Epoch&#39;: 67, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00428266&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00496889&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00496889&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00647401&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00953063&#39;, &#39;MRR&#39;: &#39;0.00474832&#39;}
EarlyStopping counter: 39 out of 50
{&#39;epoch&#39;: 68, &#39;rec_avg_loss&#39;: &#39;0.7874&#39;, &#39;rec_cur_loss&#39;: &#39;0.7798&#39;, &#39;rec_avg_auc&#39;: &#39;0.9897&#39;}
{&#39;Epoch&#39;: 68, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00441457&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00512835&#39;, &#39;HIT@15&#39;: &#39;0.00856531&#39;, &#39;NDCG@15&#39;: &#39;0.00512835&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00666120&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01015361&#39;, &#39;MRR&#39;: &#39;0.00502377&#39;}
EarlyStopping counter: 40 out of 50
{&#39;epoch&#39;: 69, &#39;rec_avg_loss&#39;: &#39;0.7875&#39;, &#39;rec_cur_loss&#39;: &#39;0.7919&#39;, &#39;rec_avg_auc&#39;: &#39;0.9867&#39;}
{&#39;Epoch&#39;: 69, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00441457&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00512835&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00567644&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00667747&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01020426&#39;, &#39;MRR&#39;: &#39;0.00505877&#39;}
EarlyStopping counter: 41 out of 50
{&#39;epoch&#39;: 70, &#39;rec_avg_loss&#39;: &#39;0.7810&#39;, &#39;rec_cur_loss&#39;: &#39;0.7834&#39;, &#39;rec_avg_auc&#39;: &#39;0.9880&#39;}
{&#39;Epoch&#39;: 70, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00456302&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00527679&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00636022&#39;, &#39;HIT@20&#39;: &#39;0.01498929&#39;, &#39;NDCG@20&#39;: &#39;0.00686430&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01042089&#39;, &#39;MRR&#39;: &#39;0.00528440&#39;}
EarlyStopping counter: 42 out of 50
{&#39;epoch&#39;: 71, &#39;rec_avg_loss&#39;: &#39;0.7687&#39;, &#39;rec_cur_loss&#39;: &#39;0.7627&#39;, &#39;rec_avg_auc&#39;: &#39;0.9890&#39;}
{&#39;Epoch&#39;: 71, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00456302&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00527679&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00636022&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00736125&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01042765&#39;, &#39;MRR&#39;: &#39;0.00528939&#39;}
EarlyStopping counter: 43 out of 50
{&#39;epoch&#39;: 72, &#39;rec_avg_loss&#39;: &#39;0.7714&#39;, &#39;rec_cur_loss&#39;: &#39;0.7629&#39;, &#39;rec_avg_auc&#39;: &#39;0.9901&#39;}
{&#39;Epoch&#39;: 72, &#39;HIT@1&#39;: &#39;0.00000000&#39;, &#39;NDCG@1&#39;: &#39;0.00000000&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00377272&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00448649&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00503458&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00656743&#39;, &#39;HIT@40&#39;: &#39;0.03426124&#39;, &#39;NDCG@40&#39;: &#39;0.01000736&#39;, &#39;MRR&#39;: &#39;0.00425234&#39;}
EarlyStopping counter: 44 out of 50
{&#39;epoch&#39;: 73, &#39;rec_avg_loss&#39;: &#39;0.7614&#39;, &#39;rec_cur_loss&#39;: &#39;0.7654&#39;, &#39;rec_avg_auc&#39;: &#39;0.9904&#39;}
{&#39;Epoch&#39;: 73, &#39;HIT@1&#39;: &#39;0.00000000&#39;, &#39;NDCG@1&#39;: &#39;0.00000000&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00377272&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00448649&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00503458&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00654765&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00916082&#39;, &#39;MRR&#39;: &#39;0.00411467&#39;}
EarlyStopping counter: 45 out of 50
{&#39;epoch&#39;: 74, &#39;rec_avg_loss&#39;: &#39;0.7580&#39;, &#39;rec_cur_loss&#39;: &#39;0.7559&#39;, &#39;rec_avg_auc&#39;: &#39;0.9859&#39;}
{&#39;Epoch&#39;: 74, &#39;HIT@1&#39;: &#39;0.00000000&#39;, &#39;NDCG@1&#39;: &#39;0.00000000&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00349235&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00420613&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00476855&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00627367&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00886919&#39;, &#39;MRR&#39;: &#39;0.00375398&#39;}
EarlyStopping counter: 46 out of 50
{&#39;epoch&#39;: 75, &#39;rec_avg_loss&#39;: &#39;0.7578&#39;, &#39;rec_cur_loss&#39;: &#39;0.7552&#39;, &#39;rec_avg_auc&#39;: &#39;0.9878&#39;}
{&#39;Epoch&#39;: 75, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00428266&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00499643&#39;, &#39;HIT@15&#39;: &#39;0.01070664&#39;, &#39;NDCG@15&#39;: &#39;0.00557510&#39;, &#39;HIT@20&#39;: &#39;0.01713062&#39;, &#39;NDCG@20&#39;: &#39;0.00708022&#39;, &#39;HIT@40&#39;: &#39;0.02997859&#39;, &#39;NDCG@40&#39;: &#39;0.00965289&#39;, &#39;MRR&#39;: &#39;0.00482581&#39;}
EarlyStopping counter: 47 out of 50
{&#39;epoch&#39;: 76, &#39;rec_avg_loss&#39;: &#39;0.7519&#39;, &#39;rec_cur_loss&#39;: &#39;0.7546&#39;, &#39;rec_avg_auc&#39;: &#39;0.9906&#39;}
{&#39;Epoch&#39;: 76, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00428266&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00499643&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00611043&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00758955&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01008512&#39;, &#39;MRR&#39;: &#39;0.00490256&#39;}
EarlyStopping counter: 48 out of 50
{&#39;epoch&#39;: 77, &#39;rec_avg_loss&#39;: &#39;0.7374&#39;, &#39;rec_cur_loss&#39;: &#39;0.7209&#39;, &#39;rec_avg_auc&#39;: &#39;0.9889&#39;}
{&#39;Epoch&#39;: 77, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00441457&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00574733&#39;, &#39;HIT@15&#39;: &#39;0.01284797&#39;, &#39;NDCG@15&#39;: &#39;0.00629542&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00781791&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01031141&#39;, &#39;MRR&#39;: &#39;0.00515750&#39;}
EarlyStopping counter: 49 out of 50
{&#39;epoch&#39;: 78, &#39;rec_avg_loss&#39;: &#39;0.7378&#39;, &#39;rec_cur_loss&#39;: &#39;0.7239&#39;, &#39;rec_avg_auc&#39;: &#39;0.9886&#39;}
{&#39;Epoch&#39;: 78, &#39;HIT@1&#39;: &#39;0.00214133&#39;, &#39;NDCG@1&#39;: &#39;0.00214133&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00441457&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00512835&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00682341&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00783238&#39;, &#39;HIT@40&#39;: &#39;0.03211991&#39;, &#39;NDCG@40&#39;: &#39;0.01035837&#39;, &#39;MRR&#39;: &#39;0.00518570&#39;}
EarlyStopping counter: 50 out of 50
Early stopping
---------------Change to test_rating_matrix!-------------------
{&#39;Epoch&#39;: &#39;best&#39;, &#39;HIT@1&#39;: &#39;0.00428266&#39;, &#39;NDCG@1&#39;: &#39;0.00428266&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00535332&#39;, &#39;HIT@10&#39;: &#39;0.01070664&#39;, &#39;NDCG@10&#39;: &#39;0.00674261&#39;, &#39;HIT@15&#39;: &#39;0.01498929&#39;, &#39;NDCG@15&#39;: &#39;0.00788370&#39;, &#39;HIT@20&#39;: &#39;0.02569593&#39;, &#39;NDCG@20&#39;: &#39;0.01036236&#39;, &#39;HIT@40&#39;: &#39;0.04925054&#39;, &#39;NDCG@40&#39;: &#39;0.01518074&#39;, &#39;MRR&#39;: &#39;0.00730709&#39;}
{&#39;Epoch&#39;: &#39;best&#39;, &#39;HIT@1&#39;: &#39;0.00000000&#39;, &#39;NDCG@1&#39;: &#39;0.00000000&#39;, &#39;HIT@5&#39;: &#39;0.00642398&#39;, &#39;NDCG@5&#39;: &#39;0.00353043&#39;, &#39;HIT@10&#39;: &#39;0.00856531&#39;, &#39;NDCG@10&#39;: &#39;0.00414942&#39;, &#39;HIT@15&#39;: &#39;0.01713062&#39;, &#39;NDCG@15&#39;: &#39;0.00643590&#39;, &#39;HIT@20&#39;: &#39;0.01927195&#39;, &#39;NDCG@20&#39;: &#39;0.00693999&#39;, &#39;HIT@40&#39;: &#39;0.02569593&#39;, &#39;NDCG@40&#39;: &#39;0.00828610&#39;, &#39;MRR&#39;: &#39;0.00383749&#39;}
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">args_str</span><span class="p">)</span>
<span class="c1">#print(result_info)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">args_str</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">result_info</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Finetune_full-Beauty-64-2-2-gelu-0.5-0.5-50-0.001-0.0-10-1.0-0.1
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/2022/01/15/stosa.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Jupyter notebook database.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/recohut" target="_blank" title="recohut"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
